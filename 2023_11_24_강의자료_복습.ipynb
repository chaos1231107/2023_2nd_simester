{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+GmlITq3U7jtKD+7vidGq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaos1231107/2023_2nd_simester/blob/kinematics/2023_11_24_%EA%B0%95%EC%9D%98%EC%9E%90%EB%A3%8C_%EB%B3%B5%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXacgdXbo6lp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,)),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(100,activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "metadata": {
        "id": "kHP0gLTDq1Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "    x1, x2 = x[:,0:1], x[:,1:]\n",
        "    y1 = x1 + x2\n",
        "    y2 = x1 * x2\n",
        "    return np.concatenate((y1, y2),axis=-1)"
      ],
      "metadata": {
        "id": "vvBhfjl_pIVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train = np.random.uniform(-2,2,size=(100,1))\n",
        "x2_train = np.random.uniform(-2,2,size=(100,1))\n",
        "x_train = np.concatenate((x1_train, x2_train),axis=-1)\n",
        "y_train = f(x_train)"
      ],
      "metadata": {
        "id": "kJrwf9kIpVXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_test = np.random.uniform(-2,2,size=(20,1))\n",
        "x2_test = np.random.uniform(-2,2,size=(20,1))\n",
        "x_test = np.concatenate((x1_test,x2_test),axis=-1)\n",
        "y_test = f(x_test)"
      ],
      "metadata": {
        "id": "m8nbf5hMqan6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9L9WkRXqvcA",
        "outputId": "a2c2c552-0147-42fd-a8e5-67aa28d22223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               300       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10602 (41.41 KB)\n",
            "Trainable params: 10602 (41.41 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "vDkvdSK3rQ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=1000, validation_data = (x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE-r3-hurYZJ",
        "outputId": "4025870f-d728-490a-eab6-3d5fb79625e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 [==============================] - 1s 84ms/step - loss: 2.3838 - val_loss: 1.1233\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.9777 - val_loss: 0.9195\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.6681 - val_loss: 0.7434\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.3871 - val_loss: 0.5875\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.1538 - val_loss: 0.4604\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.9369 - val_loss: 0.3508\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.7500 - val_loss: 0.2655\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5936 - val_loss: 0.1997\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4563 - val_loss: 0.1489\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3487 - val_loss: 0.1146\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2835 - val_loss: 0.0943\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2273 - val_loss: 0.0770\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1823 - val_loss: 0.0624\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1428 - val_loss: 0.0499\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1146 - val_loss: 0.0428\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0899 - val_loss: 0.0362\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0721 - val_loss: 0.0303\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0609 - val_loss: 0.0310\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0540 - val_loss: 0.0343\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0500 - val_loss: 0.0378\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0466 - val_loss: 0.0420\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0464 - val_loss: 0.0468\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0462 - val_loss: 0.0484\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0451 - val_loss: 0.0481\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0448 - val_loss: 0.0472\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0450 - val_loss: 0.0463\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0442 - val_loss: 0.0458\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0433 - val_loss: 0.0448\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0431 - val_loss: 0.0430\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0428 - val_loss: 0.0416\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0420 - val_loss: 0.0410\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0422 - val_loss: 0.0404\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0419 - val_loss: 0.0398\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0415 - val_loss: 0.0383\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0410 - val_loss: 0.0373\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0406 - val_loss: 0.0368\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0402 - val_loss: 0.0368\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0403 - val_loss: 0.0367\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0401 - val_loss: 0.0364\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0399 - val_loss: 0.0360\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0393 - val_loss: 0.0374\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0392 - val_loss: 0.0392\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0400 - val_loss: 0.0402\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0391 - val_loss: 0.0446\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0400 - val_loss: 0.0461\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0397 - val_loss: 0.0443\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0388 - val_loss: 0.0414\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0406\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0385 - val_loss: 0.0380\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0378 - val_loss: 0.0355\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0372 - val_loss: 0.0346\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0368 - val_loss: 0.0335\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0372 - val_loss: 0.0336\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0370 - val_loss: 0.0321\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0310\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0373 - val_loss: 0.0317\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0325\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0337\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0361 - val_loss: 0.0344\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0355 - val_loss: 0.0344\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0355 - val_loss: 0.0336\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0360 - val_loss: 0.0341\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0352 - val_loss: 0.0340\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0343\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0354\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0355 - val_loss: 0.0375\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0354 - val_loss: 0.0392\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0344 - val_loss: 0.0379\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0351\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0342 - val_loss: 0.0330\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0350 - val_loss: 0.0320\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0336 - val_loss: 0.0327\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0327 - val_loss: 0.0350\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0327 - val_loss: 0.0354\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0325 - val_loss: 0.0347\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0327 - val_loss: 0.0327\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0328 - val_loss: 0.0301\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0320 - val_loss: 0.0305\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0328 - val_loss: 0.0305\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0305 - val_loss: 0.0325\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0315 - val_loss: 0.0332\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0313 - val_loss: 0.0312\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0298 - val_loss: 0.0302\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0300 - val_loss: 0.0288\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0308 - val_loss: 0.0269\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0302 - val_loss: 0.0262\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0299 - val_loss: 0.0273\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0293 - val_loss: 0.0281\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0297 - val_loss: 0.0286\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0293 - val_loss: 0.0289\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0287 - val_loss: 0.0281\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0286 - val_loss: 0.0265\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0284 - val_loss: 0.0258\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0284 - val_loss: 0.0263\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0279 - val_loss: 0.0265\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0275 - val_loss: 0.0277\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0278 - val_loss: 0.0278\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0276 - val_loss: 0.0267\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0273 - val_loss: 0.0256\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0278 - val_loss: 0.0250\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0271 - val_loss: 0.0256\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0276 - val_loss: 0.0280\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0272 - val_loss: 0.0297\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.0303\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0261 - val_loss: 0.0296\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0255 - val_loss: 0.0297\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0255 - val_loss: 0.0281\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0252 - val_loss: 0.0292\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0253 - val_loss: 0.0282\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0247 - val_loss: 0.0260\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0241 - val_loss: 0.0240\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0266 - val_loss: 0.0294\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0280 - val_loss: 0.0352\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.0320\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0242 - val_loss: 0.0265\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0243 - val_loss: 0.0245\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0247 - val_loss: 0.0225\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0198\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0231 - val_loss: 0.0211\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0233 - val_loss: 0.0253\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0251 - val_loss: 0.0243\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.0233\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0221 - val_loss: 0.0246\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 0.0231\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0215 - val_loss: 0.0226\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0242 - val_loss: 0.0232\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0231\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0251\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0207 - val_loss: 0.0284\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0234 - val_loss: 0.0298\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0209 - val_loss: 0.0266\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0237\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0215 - val_loss: 0.0216\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0215 - val_loss: 0.0238\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0228 - val_loss: 0.0205\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0193 - val_loss: 0.0213\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0227\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0197 - val_loss: 0.0202\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0193 - val_loss: 0.0204\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0198\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0176 - val_loss: 0.0198\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0176 - val_loss: 0.0214\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0175 - val_loss: 0.0274\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0199 - val_loss: 0.0326\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0200 - val_loss: 0.0279\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0178 - val_loss: 0.0221\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 0.0172\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0168 - val_loss: 0.0144\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0144\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0166 - val_loss: 0.0159\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.0174\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0158 - val_loss: 0.0163\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0173\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0154 - val_loss: 0.0154\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0145\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0151\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 0.0148\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0144 - val_loss: 0.0139\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0138 - val_loss: 0.0141\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0161\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0142 - val_loss: 0.0177\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0137 - val_loss: 0.0169\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0135 - val_loss: 0.0175\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0132 - val_loss: 0.0153\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0127 - val_loss: 0.0131\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0137 - val_loss: 0.0117\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0139 - val_loss: 0.0126\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0121 - val_loss: 0.0227\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0148 - val_loss: 0.0236\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0138 - val_loss: 0.0198\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0136 - val_loss: 0.0181\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0128 - val_loss: 0.0186\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0121 - val_loss: 0.0181\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0130 - val_loss: 0.0152\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0127\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0107 - val_loss: 0.0114\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0106 - val_loss: 0.0118\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0113\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0129\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0104 - val_loss: 0.0127\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0098 - val_loss: 0.0155\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0108 - val_loss: 0.0141\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0095 - val_loss: 0.0119\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0108\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0102\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0112\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0099\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0080\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0085\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0085 - val_loss: 0.0113\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0086 - val_loss: 0.0135\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0088 - val_loss: 0.0113\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0103\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0079 - val_loss: 0.0100\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0075 - val_loss: 0.0096\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0074 - val_loss: 0.0101\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0078 - val_loss: 0.0078\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0069 - val_loss: 0.0075\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0068 - val_loss: 0.0089\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0091\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0096\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0092\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0063 - val_loss: 0.0074\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0072\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0120\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0076 - val_loss: 0.0111\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0103\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0093\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0072\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0061\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0057 - val_loss: 0.0059\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0060 - val_loss: 0.0074\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0053 - val_loss: 0.0089\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0054 - val_loss: 0.0096\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0052 - val_loss: 0.0085\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0049 - val_loss: 0.0071\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0069\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0078\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0075\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0057\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0046 - val_loss: 0.0050\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0055\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0073\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0075\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.0056\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0046\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.0046\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0051\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0052\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0055\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0034 - val_loss: 0.0063\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0043 - val_loss: 0.0076\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0069\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0071\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0039 - val_loss: 0.0066\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0037 - val_loss: 0.0043\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0034 - val_loss: 0.0035\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0031 - val_loss: 0.0056\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0033 - val_loss: 0.0055\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0030 - val_loss: 0.0051\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.0032\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0034\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.0033\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0030 - val_loss: 0.0031\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0026 - val_loss: 0.0032\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0029 - val_loss: 0.0034\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0031\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0026 - val_loss: 0.0050\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0030 - val_loss: 0.0046\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0043\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0028 - val_loss: 0.0038\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0024 - val_loss: 0.0033\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0022 - val_loss: 0.0029\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0020 - val_loss: 0.0037\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0041\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0020 - val_loss: 0.0034\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0022 - val_loss: 0.0030\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.0020 - val_loss: 0.0033\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0021 - val_loss: 0.0032\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0021 - val_loss: 0.0034\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0019 - val_loss: 0.0037\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0030\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0018 - val_loss: 0.0031\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0017 - val_loss: 0.0026\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0025\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0023\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0023\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0015 - val_loss: 0.0028\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0021 - val_loss: 0.0045\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0024 - val_loss: 0.0041\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0037\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0016 - val_loss: 0.0032\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0014 - val_loss: 0.0021\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0015 - val_loss: 0.0021\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0013 - val_loss: 0.0026\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0015 - val_loss: 0.0024\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0013 - val_loss: 0.0024\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0019\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0017\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0020 - val_loss: 0.0021\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0049\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0024\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0040\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0017\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.9399e-04 - val_loss: 0.0018\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.8923e-04 - val_loss: 0.0015\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0020\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 8.4907e-04 - val_loss: 0.0020\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0019\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 9.0429e-04 - val_loss: 0.0016\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.9644e-04 - val_loss: 0.0018\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0018\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.9409e-04 - val_loss: 0.0014\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0016\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0018\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.6137e-04 - val_loss: 0.0019\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 9.4336e-04 - val_loss: 0.0016\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0025\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0022\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.5486e-04 - val_loss: 0.0013\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.6929e-04 - val_loss: 0.0014\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0032\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0025\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0024\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0012\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.8066e-04 - val_loss: 0.0015\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0015\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.0076e-04 - val_loss: 0.0017\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8.5721e-04 - val_loss: 0.0013\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.8680e-04 - val_loss: 0.0015\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.9884e-04 - val_loss: 0.0018\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0020\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.9246e-04 - val_loss: 0.0016\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.9175e-04 - val_loss: 0.0014\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.9014e-04 - val_loss: 0.0011\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 9.6950e-04 - val_loss: 0.0013\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.7874e-04 - val_loss: 0.0014\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.7389e-04 - val_loss: 0.0016\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0022\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0027\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0015\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 8.7484e-04 - val_loss: 0.0012\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.5427e-04 - val_loss: 0.0016\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.8034e-04 - val_loss: 0.0013\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.9897e-04 - val_loss: 0.0014\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.6231e-04 - val_loss: 0.0013\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.4247e-04 - val_loss: 0.0010\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.5795e-04 - val_loss: 0.0011\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.4284e-04 - val_loss: 0.0013\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.5738e-04 - val_loss: 0.0013\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 6.7182e-04 - val_loss: 0.0011\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.5306e-04 - val_loss: 0.0011\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.1487e-04 - val_loss: 0.0010\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.0510e-04 - val_loss: 0.0013\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 9.5732e-04 - val_loss: 0.0015\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.8963e-04 - val_loss: 0.0013\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.6814e-04 - val_loss: 0.0012\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.7586e-04 - val_loss: 8.1925e-04\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.6194e-04 - val_loss: 7.9068e-04\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.1108e-04 - val_loss: 0.0011\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.9384e-04 - val_loss: 0.0013\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.3768e-04 - val_loss: 0.0013\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.6884e-04 - val_loss: 0.0011\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.6213e-04 - val_loss: 9.9826e-04\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.7934e-04 - val_loss: 8.3962e-04\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.5081e-04 - val_loss: 9.8677e-04\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.8236e-04 - val_loss: 0.0014\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.0314e-04 - val_loss: 0.0010\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 8.4724e-04 - val_loss: 0.0011\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.8094e-04 - val_loss: 0.0012\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.7046e-04 - val_loss: 0.0012\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0021\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0017\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.9408e-04 - val_loss: 9.4686e-04\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.1146e-04 - val_loss: 8.4726e-04\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.1640e-04 - val_loss: 0.0014\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.8098e-04 - val_loss: 0.0016\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 9.3266e-04\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.9216e-04 - val_loss: 0.0011\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.2207e-04 - val_loss: 9.2620e-04\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.7221e-04 - val_loss: 0.0012\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.0364e-04 - val_loss: 0.0011\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.4227e-04 - val_loss: 9.2731e-04\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.1765e-04 - val_loss: 8.8700e-04\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.0525e-04 - val_loss: 0.0012\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.8510e-04 - val_loss: 0.0011\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.3022e-04 - val_loss: 8.8074e-04\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.6540e-04 - val_loss: 9.0728e-04\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.7054e-04 - val_loss: 9.0315e-04\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.6236e-04 - val_loss: 8.4998e-04\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 6.2822e-04 - val_loss: 0.0010\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.4932e-04 - val_loss: 0.0013\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.2091e-04 - val_loss: 0.0010\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 6.1583e-04 - val_loss: 0.0011\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.9587e-04 - val_loss: 7.6335e-04\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.8622e-04 - val_loss: 7.5753e-04\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.0598e-04 - val_loss: 0.0011\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.2069e-04 - val_loss: 0.0011\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.8979e-04 - val_loss: 8.8425e-04\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.7561e-04 - val_loss: 8.1720e-04\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.3854e-04 - val_loss: 9.2928e-04\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.9731e-04 - val_loss: 8.9336e-04\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.3341e-04 - val_loss: 9.3573e-04\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.1528e-04 - val_loss: 0.0011\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.4685e-04 - val_loss: 7.5719e-04\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.5440e-04 - val_loss: 8.2931e-04\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.7747e-04 - val_loss: 6.4719e-04\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.8408e-04 - val_loss: 9.3024e-04\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 7.4746e-04 - val_loss: 9.5207e-04\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.5279e-04 - val_loss: 7.4244e-04\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.9748e-04 - val_loss: 9.4260e-04\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.0940e-04 - val_loss: 0.0011\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.3652e-04 - val_loss: 0.0012\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.6161e-04 - val_loss: 9.2768e-04\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.8470e-04 - val_loss: 8.7000e-04\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.0138e-04 - val_loss: 8.1184e-04\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.5848e-04 - val_loss: 9.2466e-04\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.7723e-04 - val_loss: 0.0012\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.2856e-04 - val_loss: 9.3614e-04\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.2123e-04 - val_loss: 0.0011\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.6183e-04 - val_loss: 0.0011\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.2893e-04 - val_loss: 6.7064e-04\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.1603e-04 - val_loss: 7.6089e-04\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.4587e-04 - val_loss: 0.0012\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.3718e-04 - val_loss: 8.1172e-04\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.5309e-04 - val_loss: 9.3227e-04\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.4922e-04 - val_loss: 7.3651e-04\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 6.9616e-04 - val_loss: 8.1692e-04\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.8340e-04 - val_loss: 0.0017\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.0298e-04 - val_loss: 8.3861e-04\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.5555e-04 - val_loss: 5.9058e-04\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.1409e-04 - val_loss: 7.5651e-04\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.3401e-04 - val_loss: 7.3170e-04\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.5227e-04 - val_loss: 8.9344e-04\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.3337e-04 - val_loss: 8.8067e-04\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.2389e-04 - val_loss: 6.2521e-04\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.8755e-04 - val_loss: 6.7488e-04\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.8909e-04 - val_loss: 7.7329e-04\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.0336e-04 - val_loss: 9.7603e-04\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.9100e-04 - val_loss: 7.8259e-04\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.2359e-04 - val_loss: 6.9578e-04\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.5242e-04 - val_loss: 0.0010\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.2541e-04 - val_loss: 6.0054e-04\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.8252e-04 - val_loss: 9.5666e-04\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.6318e-04 - val_loss: 8.3583e-04\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.9573e-04 - val_loss: 9.6467e-04\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 8.1702e-04 - val_loss: 0.0015\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.9583e-04 - val_loss: 0.0014\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 9.1367e-04 - val_loss: 9.1521e-04\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.2508e-04 - val_loss: 8.5924e-04\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.3075e-04 - val_loss: 7.2219e-04\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.0445e-04 - val_loss: 0.0013\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.8235e-04 - val_loss: 0.0011\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8.5054e-04 - val_loss: 7.3990e-04\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 7.5551e-04 - val_loss: 0.0010\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.9501e-04 - val_loss: 0.0013\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.9065e-04 - val_loss: 7.9909e-04\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.8948e-04 - val_loss: 0.0012\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 6.0213e-04\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 9.4749e-04 - val_loss: 0.0012\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.4981e-04 - val_loss: 0.0010\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8.4436e-04 - val_loss: 7.5462e-04\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 7.1271e-04 - val_loss: 7.9806e-04\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.7122e-04 - val_loss: 9.4567e-04\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.6818e-04 - val_loss: 7.6004e-04\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.7169e-04 - val_loss: 6.3340e-04\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 4.0707e-04 - val_loss: 7.3156e-04\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.9975e-04 - val_loss: 7.0169e-04\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.0195e-04 - val_loss: 5.8293e-04\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.1828e-04 - val_loss: 5.9961e-04\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 8.7913e-04 - val_loss: 0.0011\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5.2778e-04 - val_loss: 0.0012\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 8.4482e-04 - val_loss: 7.5715e-04\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 6.2552e-04 - val_loss: 0.0010\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.8806e-04 - val_loss: 9.1206e-04\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 4.5363e-04 - val_loss: 5.1430e-04\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.9624e-04 - val_loss: 7.0975e-04\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.7645e-04 - val_loss: 0.0010\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.4241e-04 - val_loss: 5.8609e-04\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.6203e-04 - val_loss: 7.2829e-04\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.4115e-04 - val_loss: 9.2791e-04\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 3.4252e-04 - val_loss: 8.0503e-04\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.1228e-04 - val_loss: 5.5060e-04\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 3.2927e-04 - val_loss: 4.9310e-04\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.7784e-04 - val_loss: 6.2414e-04\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 3.2469e-04 - val_loss: 6.4821e-04\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.1251e-04 - val_loss: 6.1811e-04\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.9005e-04 - val_loss: 5.4900e-04\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 4.0323e-04 - val_loss: 4.5330e-04\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 3.6315e-04 - val_loss: 4.6200e-04\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.2573e-04 - val_loss: 4.7269e-04\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.4543e-04 - val_loss: 8.1069e-04\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.4718e-04 - val_loss: 6.3264e-04\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 5.0650e-04 - val_loss: 6.3227e-04\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.5977e-04 - val_loss: 6.3321e-04\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.3169e-04 - val_loss: 5.5095e-04\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.3203e-04 - val_loss: 8.2081e-04\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.7762e-04 - val_loss: 6.1342e-04\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.2211e-04 - val_loss: 0.0010\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 5.4829e-04 - val_loss: 7.1957e-04\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.9593e-04 - val_loss: 0.0011\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.8647e-04 - val_loss: 6.8317e-04\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.0237e-04 - val_loss: 5.3466e-04\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.9819e-04 - val_loss: 0.0011\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.6847e-04 - val_loss: 6.4457e-04\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.6893e-04 - val_loss: 4.8392e-04\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.9498e-04 - val_loss: 7.0591e-04\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 4.0774e-04 - val_loss: 5.2669e-04\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 3.5437e-04 - val_loss: 5.9106e-04\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.3028e-04 - val_loss: 7.3534e-04\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.8927e-04 - val_loss: 9.0638e-04\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.5523e-04 - val_loss: 6.1688e-04\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.6183e-04 - val_loss: 8.3296e-04\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.2623e-04 - val_loss: 6.6965e-04\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 3.4742e-04 - val_loss: 4.8523e-04\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.2063e-04 - val_loss: 6.7839e-04\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.0744e-04 - val_loss: 7.1409e-04\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.4428e-04 - val_loss: 6.5261e-04\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.8963e-04 - val_loss: 5.4411e-04\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.8728e-04 - val_loss: 6.1807e-04\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.2221e-04 - val_loss: 6.4028e-04\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.4961e-04 - val_loss: 5.5623e-04\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.5905e-04 - val_loss: 7.8331e-04\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 4.8224e-04 - val_loss: 9.0492e-04\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.9939e-04 - val_loss: 5.6011e-04\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.0797e-04 - val_loss: 5.9655e-04\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.6592e-04 - val_loss: 7.3812e-04\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.2554e-04 - val_loss: 6.5136e-04\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.7955e-04 - val_loss: 5.7567e-04\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.0643e-04 - val_loss: 7.0938e-04\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.7428e-04 - val_loss: 5.6215e-04\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.9104e-04 - val_loss: 5.0221e-04\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.5478e-04 - val_loss: 6.8208e-04\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.9434e-04 - val_loss: 8.4535e-04\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.3999e-04 - val_loss: 7.6552e-04\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.9875e-04 - val_loss: 5.4001e-04\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.5899e-04 - val_loss: 8.1952e-04\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.0959e-04 - val_loss: 7.2503e-04\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.5408e-04 - val_loss: 4.3619e-04\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.1531e-04 - val_loss: 5.1644e-04\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9016e-04 - val_loss: 6.7742e-04\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.5286e-04 - val_loss: 7.6862e-04\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.0428e-04 - val_loss: 5.1089e-04\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.6544e-04 - val_loss: 5.4060e-04\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.5813e-04 - val_loss: 4.8489e-04\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.2831e-04 - val_loss: 4.7553e-04\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.1287e-04 - val_loss: 5.9425e-04\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4632e-04 - val_loss: 6.7426e-04\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.9815e-04 - val_loss: 5.1238e-04\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.0489e-04 - val_loss: 3.9448e-04\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.8898e-04 - val_loss: 4.4990e-04\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.6196e-04 - val_loss: 5.9473e-04\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4970e-04 - val_loss: 7.6913e-04\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.0725e-04 - val_loss: 4.4442e-04\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.1118e-04 - val_loss: 5.0566e-04\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9812e-04 - val_loss: 5.9470e-04\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.9880e-04 - val_loss: 5.0209e-04\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7051e-04 - val_loss: 6.3930e-04\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.3611e-04 - val_loss: 5.0369e-04\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.7269e-04 - val_loss: 7.1331e-04\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.2801e-04 - val_loss: 9.8691e-04\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.7234e-04 - val_loss: 6.5449e-04\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.7426e-04 - val_loss: 5.0237e-04\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.3026e-04 - val_loss: 5.7365e-04\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.4418e-04 - val_loss: 3.9315e-04\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.2022e-04 - val_loss: 4.9151e-04\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.5217e-04 - val_loss: 7.4728e-04\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.4811e-04 - val_loss: 4.7545e-04\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.3003e-04 - val_loss: 4.8973e-04\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.3222e-04 - val_loss: 5.6284e-04\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.4387e-04 - val_loss: 5.5879e-04\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.7426e-04 - val_loss: 4.9738e-04\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.3919e-04 - val_loss: 4.1903e-04\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.3736e-04 - val_loss: 4.5268e-04\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.8668e-04 - val_loss: 4.8445e-04\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.5323e-04 - val_loss: 5.9099e-04\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 5.6363e-04 - val_loss: 7.6951e-04\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.1215e-04 - val_loss: 5.4660e-04\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.9570e-04 - val_loss: 6.7129e-04\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.1764e-04 - val_loss: 8.7039e-04\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.7112e-04 - val_loss: 4.2154e-04\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.7579e-04 - val_loss: 4.1378e-04\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.4413e-04 - val_loss: 7.9172e-04\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.4278e-04 - val_loss: 5.8356e-04\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.3673e-04 - val_loss: 3.7163e-04\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.2185e-04 - val_loss: 4.1806e-04\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.2797e-04 - val_loss: 5.0081e-04\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.3714e-04 - val_loss: 5.1373e-04\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.3103e-04 - val_loss: 5.4768e-04\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.0920e-04 - val_loss: 5.9599e-04\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.9770e-04 - val_loss: 4.8785e-04\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.2070e-04 - val_loss: 4.1052e-04\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.7252e-04 - val_loss: 5.6884e-04\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.6400e-04 - val_loss: 5.1956e-04\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.1032e-04 - val_loss: 3.3719e-04\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.5996e-04 - val_loss: 4.8925e-04\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 5.3445e-04 - val_loss: 7.9092e-04\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.5090e-04 - val_loss: 7.6227e-04\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.5738e-04 - val_loss: 6.2233e-04\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.3338e-04 - val_loss: 4.0490e-04\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.0061e-04 - val_loss: 4.9096e-04\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.2780e-04 - val_loss: 8.7098e-04\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.6018e-04 - val_loss: 3.9243e-04\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.4547e-04 - val_loss: 4.3158e-04\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.5405e-04 - val_loss: 4.2935e-04\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.2239e-04 - val_loss: 5.2533e-04\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.0121e-04 - val_loss: 4.7945e-04\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.9305e-04 - val_loss: 4.5875e-04\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.0208e-04 - val_loss: 3.9654e-04\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.2922e-04 - val_loss: 3.5760e-04\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.7962e-04 - val_loss: 4.5433e-04\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.9504e-04 - val_loss: 5.0247e-04\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.5751e-04 - val_loss: 4.7608e-04\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.0340e-04 - val_loss: 5.5936e-04\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.5969e-04 - val_loss: 6.3838e-04\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.0846e-04 - val_loss: 4.0194e-04\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.5597e-04 - val_loss: 5.0725e-04\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.8568e-04 - val_loss: 4.6490e-04\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.5389e-04 - val_loss: 5.9099e-04\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.3413e-04 - val_loss: 5.1275e-04\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.6732e-04 - val_loss: 6.6950e-04\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4245e-04 - val_loss: 5.1888e-04\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.0664e-04 - val_loss: 3.7015e-04\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.8780e-04 - val_loss: 4.5460e-04\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.4306e-04 - val_loss: 5.1108e-04\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.0619e-04 - val_loss: 4.6067e-04\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.8118e-04 - val_loss: 4.9850e-04\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.1710e-04 - val_loss: 4.7710e-04\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.7631e-04 - val_loss: 3.4241e-04\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.6788e-04 - val_loss: 4.1978e-04\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.3560e-04 - val_loss: 4.5520e-04\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.8564e-04 - val_loss: 5.2541e-04\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.6811e-04 - val_loss: 7.8628e-04\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.0158e-04 - val_loss: 4.3620e-04\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.6124e-04 - val_loss: 3.6087e-04\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.0895e-04 - val_loss: 4.7630e-04\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.8266e-04 - val_loss: 4.4796e-04\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.1799e-04 - val_loss: 6.0087e-04\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.6017e-04 - val_loss: 5.6384e-04\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.1156e-04 - val_loss: 3.8580e-04\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.2069e-04 - val_loss: 3.7984e-04\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.5801e-04 - val_loss: 3.7872e-04\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.6480e-04 - val_loss: 5.3366e-04\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.6784e-04 - val_loss: 5.9238e-04\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.6909e-04 - val_loss: 3.9219e-04\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.9259e-04 - val_loss: 3.9604e-04\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.8312e-04 - val_loss: 3.6244e-04\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.6131e-04 - val_loss: 4.4107e-04\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.7645e-04 - val_loss: 5.2039e-04\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5863e-04 - val_loss: 3.5019e-04\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.5804e-04 - val_loss: 4.4467e-04\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.1668e-04 - val_loss: 4.4226e-04\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.2064e-04 - val_loss: 5.0016e-04\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.3903e-04 - val_loss: 3.8720e-04\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4615e-04 - val_loss: 3.4715e-04\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.5819e-04 - val_loss: 3.6394e-04\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.3174e-04 - val_loss: 7.1278e-04\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.7746e-04 - val_loss: 5.1496e-04\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.9456e-04 - val_loss: 0.0011\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.5099e-04 - val_loss: 7.5747e-04\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.0061e-04 - val_loss: 4.2825e-04\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.0976e-04 - val_loss: 4.7890e-04\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.2494e-04 - val_loss: 3.8984e-04\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.6530e-04 - val_loss: 4.1868e-04\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.0715e-04 - val_loss: 4.0071e-04\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.5727e-04 - val_loss: 3.7379e-04\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.9979e-04 - val_loss: 3.9275e-04\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.1888e-04 - val_loss: 3.3944e-04\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.4153e-04 - val_loss: 4.5548e-04\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.7972e-04 - val_loss: 4.6561e-04\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.4244e-04 - val_loss: 3.4872e-04\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.6173e-04 - val_loss: 3.4348e-04\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.1741e-04 - val_loss: 6.7684e-04\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.4347e-04 - val_loss: 4.3176e-04\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 3.1048e-04 - val_loss: 4.2320e-04\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.8473e-04 - val_loss: 6.0361e-04\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.8111e-04 - val_loss: 3.9923e-04\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.8424e-04 - val_loss: 3.4846e-04\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.9559e-04 - val_loss: 5.5060e-04\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.0486e-04 - val_loss: 5.3997e-04\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.1750e-04 - val_loss: 4.7927e-04\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 3.9489e-04 - val_loss: 4.6396e-04\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.1719e-04 - val_loss: 3.6245e-04\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.7650e-04 - val_loss: 4.3486e-04\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.6864e-04 - val_loss: 4.9480e-04\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.2538e-04 - val_loss: 4.0656e-04\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.9761e-04 - val_loss: 4.6026e-04\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.8658e-04 - val_loss: 3.8372e-04\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.6072e-04 - val_loss: 4.1298e-04\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9459e-04 - val_loss: 3.9915e-04\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.1370e-04 - val_loss: 4.3145e-04\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.7765e-04 - val_loss: 3.4819e-04\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.7081e-04 - val_loss: 3.8128e-04\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.6988e-04 - val_loss: 3.4489e-04\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.3737e-04 - val_loss: 3.4574e-04\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.1612e-04 - val_loss: 3.5371e-04\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.5942e-04 - val_loss: 3.8127e-04\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.6324e-04 - val_loss: 3.3720e-04\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.5023e-04 - val_loss: 3.8317e-04\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.2344e-04 - val_loss: 6.3402e-04\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.1436e-04 - val_loss: 2.5929e-04\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.8629e-04 - val_loss: 2.5324e-04\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.3765e-04 - val_loss: 4.1924e-04\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.5217e-04 - val_loss: 3.7161e-04\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.6480e-04 - val_loss: 3.7793e-04\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.4004e-04 - val_loss: 4.1257e-04\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.4970e-04 - val_loss: 3.5160e-04\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 2.1995e-04 - val_loss: 3.9512e-04\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.0620e-04 - val_loss: 2.8477e-04\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.3133e-04 - val_loss: 2.7708e-04\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.1774e-04 - val_loss: 4.5907e-04\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.6396e-04 - val_loss: 3.5633e-04\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.7564e-04 - val_loss: 4.0534e-04\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.8691e-04 - val_loss: 5.7731e-04\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 3.2916e-04 - val_loss: 4.5881e-04\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.2563e-04 - val_loss: 4.9109e-04\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.7626e-04 - val_loss: 4.6132e-04\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.3805e-04 - val_loss: 4.7342e-04\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.0879e-04 - val_loss: 4.4993e-04\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.3472e-04 - val_loss: 6.6172e-04\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.9956e-04 - val_loss: 3.9723e-04\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.7950e-04 - val_loss: 5.2295e-04\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.4328e-04 - val_loss: 5.8876e-04\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.2612e-04 - val_loss: 5.5785e-04\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.8556e-04 - val_loss: 4.8557e-04\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.0300e-04 - val_loss: 4.5088e-04\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.3518e-04 - val_loss: 5.0013e-04\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.3290e-04 - val_loss: 5.4168e-04\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.5218e-04 - val_loss: 3.7660e-04\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.9840e-04 - val_loss: 5.7963e-04\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.5926e-04 - val_loss: 5.2749e-04\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 3.3635e-04 - val_loss: 5.1266e-04\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.6575e-04 - val_loss: 3.7210e-04\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.2696e-04 - val_loss: 2.9454e-04\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.5514e-04 - val_loss: 4.3317e-04\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 2.0693e-04 - val_loss: 2.8989e-04\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.6790e-04 - val_loss: 2.6357e-04\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.5008e-04 - val_loss: 4.3934e-04\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 3.9831e-04 - val_loss: 7.0267e-04\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.8413e-04 - val_loss: 4.0887e-04\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.1050e-04 - val_loss: 6.1466e-04\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 6.0668e-04 - val_loss: 0.0013\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.0010 - val_loss: 7.8454e-04\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 5.7162e-04 - val_loss: 5.1709e-04\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 3.6865e-04 - val_loss: 3.4363e-04\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.5311e-04 - val_loss: 5.7030e-04\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.7451e-04 - val_loss: 7.9288e-04\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.3577e-04 - val_loss: 4.0515e-04\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.9338e-04 - val_loss: 4.8444e-04\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.1849e-04 - val_loss: 5.2435e-04\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 3.3967e-04 - val_loss: 3.6167e-04\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.1055e-04 - val_loss: 3.8615e-04\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1.5591e-04 - val_loss: 3.2937e-04\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.3067e-04 - val_loss: 2.7848e-04\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.3527e-04 - val_loss: 2.8773e-04\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.8683e-04 - val_loss: 2.7198e-04\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.8237e-04 - val_loss: 3.7680e-04\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.3710e-04 - val_loss: 5.1182e-04\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.0954e-04 - val_loss: 3.3559e-04\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.7111e-04 - val_loss: 3.3588e-04\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 2.2186e-04 - val_loss: 5.0211e-04\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.3326e-04 - val_loss: 5.8855e-04\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 6.1688e-04 - val_loss: 6.2928e-04\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 3.4737e-04 - val_loss: 4.1511e-04\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 4.2687e-04 - val_loss: 6.5252e-04\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.1234e-04 - val_loss: 5.6674e-04\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 3.4124e-04 - val_loss: 5.8224e-04\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.7699e-04 - val_loss: 4.5642e-04\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 3.2893e-04 - val_loss: 6.1555e-04\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.2187e-04 - val_loss: 4.4173e-04\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.1307e-04 - val_loss: 3.3591e-04\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.0416e-04 - val_loss: 0.0012\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 8.2382e-04\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0022\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0017 - val_loss: 9.8423e-04\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 7.7937e-04\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.7475e-04 - val_loss: 4.6005e-04\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.3747e-04 - val_loss: 0.0010\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 8.1082e-04 - val_loss: 9.4696e-04\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 7.1995e-04 - val_loss: 7.6593e-04\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.5474e-04 - val_loss: 5.9628e-04\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.9018e-04 - val_loss: 4.8154e-04\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.1342e-04 - val_loss: 4.9240e-04\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.1896e-04 - val_loss: 4.7780e-04\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.3635e-04 - val_loss: 3.7300e-04\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.2654e-04 - val_loss: 4.7761e-04\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7919e-04 - val_loss: 6.5700e-04\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.9547e-04 - val_loss: 3.8903e-04\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.7627e-04 - val_loss: 6.1484e-04\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.1236e-04 - val_loss: 6.9108e-04\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.5973e-04 - val_loss: 6.2932e-04\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.4434e-04 - val_loss: 4.1048e-04\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.5685e-04 - val_loss: 6.0684e-04\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.2988e-04 - val_loss: 6.1745e-04\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.6130e-04 - val_loss: 5.3670e-04\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.8537e-04 - val_loss: 6.3481e-04\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.1568e-04 - val_loss: 3.0550e-04\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.0750e-04 - val_loss: 3.1196e-04\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.7793e-04 - val_loss: 3.6953e-04\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.6963e-04 - val_loss: 3.4480e-04\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.7950e-04 - val_loss: 4.5443e-04\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.7539e-04 - val_loss: 3.2590e-04\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.5754e-04 - val_loss: 3.6706e-04\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.2997e-04 - val_loss: 3.7851e-04\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.5293e-04 - val_loss: 3.3107e-04\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.2779e-04 - val_loss: 4.1578e-04\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.2583e-04 - val_loss: 3.9284e-04\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.7982e-04 - val_loss: 3.8079e-04\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.9638e-04 - val_loss: 4.3116e-04\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7834e-04 - val_loss: 4.2391e-04\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.6983e-04 - val_loss: 7.1849e-04\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.4541e-04 - val_loss: 4.2747e-04\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.0129e-04 - val_loss: 6.5939e-04\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.5288e-04 - val_loss: 4.4157e-04\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.8715e-04 - val_loss: 5.1472e-04\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.3668e-04 - val_loss: 4.2440e-04\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.8630e-04 - val_loss: 4.9641e-04\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.8184e-04 - val_loss: 5.2919e-04\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8673e-04 - val_loss: 6.4542e-04\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.3909e-04 - val_loss: 4.8024e-04\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 3.7379e-04 - val_loss: 3.4502e-04\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.0074e-04 - val_loss: 4.3438e-04\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 2.0449e-04 - val_loss: 3.4023e-04\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.2703e-04 - val_loss: 3.6191e-04\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.4865e-04 - val_loss: 3.6295e-04\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5609e-04 - val_loss: 3.6155e-04\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.1850e-04 - val_loss: 4.2405e-04\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.2022e-04 - val_loss: 2.7378e-04\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.4341e-04 - val_loss: 2.9048e-04\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.1598e-04 - val_loss: 3.7641e-04\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.4540e-04 - val_loss: 3.2145e-04\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.8942e-04 - val_loss: 4.5867e-04\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.5204e-04 - val_loss: 2.8705e-04\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1642e-04 - val_loss: 3.2617e-04\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.8854e-05 - val_loss: 4.0679e-04\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 8.9277e-05 - val_loss: 4.0218e-04\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.4133e-04 - val_loss: 2.7527e-04\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.3620e-04 - val_loss: 3.4150e-04\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.2337e-04 - val_loss: 3.1515e-04\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.1222e-04 - val_loss: 4.9122e-04\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.9110e-04 - val_loss: 4.5718e-04\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.4834e-04 - val_loss: 3.6878e-04\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.6466e-04 - val_loss: 5.7813e-04\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4970e-04 - val_loss: 4.3773e-04\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.1562e-04 - val_loss: 2.7795e-04\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.7036e-04 - val_loss: 3.2721e-04\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.1346e-04 - val_loss: 7.5555e-04\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.5761e-04 - val_loss: 8.5466e-04\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.7575e-04 - val_loss: 6.7498e-04\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 6.1065e-04 - val_loss: 6.3785e-04\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.1712e-04 - val_loss: 4.8771e-04\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7691e-04 - val_loss: 7.2015e-04\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.6464e-04 - val_loss: 7.1465e-04\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.7543e-04 - val_loss: 7.2744e-04\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.3544e-04 - val_loss: 7.1284e-04\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.3354e-04 - val_loss: 6.6062e-04\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.5192e-04 - val_loss: 7.4854e-04\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.5985e-04 - val_loss: 4.4389e-04\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5475e-04 - val_loss: 5.5320e-04\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.3548e-04 - val_loss: 4.4720e-04\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.8328e-04 - val_loss: 4.4174e-04\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.3051e-04 - val_loss: 3.8467e-04\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.9879e-04 - val_loss: 6.0115e-04\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.6774e-04 - val_loss: 5.4466e-04\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.4708e-04 - val_loss: 7.4554e-04\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.2245e-04 - val_loss: 9.9350e-04\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.1402e-04 - val_loss: 3.5939e-04\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.9870e-04 - val_loss: 3.5737e-04\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.4860e-04 - val_loss: 5.8221e-04\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.3720e-04 - val_loss: 6.3266e-04\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 4.2134e-04 - val_loss: 5.2962e-04\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.3630e-04 - val_loss: 3.2010e-04\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.8642e-04 - val_loss: 7.9968e-04\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.2129e-04 - val_loss: 0.0013\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.7389e-04 - val_loss: 3.8685e-04\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 5.3675e-04 - val_loss: 3.6156e-04\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 3.7942e-04 - val_loss: 4.6611e-04\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.1417e-04 - val_loss: 4.7623e-04\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.7366e-04 - val_loss: 6.3566e-04\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.0968e-04 - val_loss: 6.7414e-04\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.2724e-04 - val_loss: 5.7445e-04\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 3.9708e-04 - val_loss: 8.0275e-04\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.7591e-04 - val_loss: 3.6199e-04\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.0610e-04 - val_loss: 6.2764e-04\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 8.1654e-04 - val_loss: 0.0015\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0011 - val_loss: 6.7893e-04\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.4268e-04 - val_loss: 8.0624e-04\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 5.5711e-04 - val_loss: 4.3462e-04\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.4692e-04 - val_loss: 4.7686e-04\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8521e-04 - val_loss: 5.0403e-04\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.0656e-04 - val_loss: 2.9100e-04\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.3784e-04 - val_loss: 4.6033e-04\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.1780e-04 - val_loss: 4.4587e-04\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.9836e-04 - val_loss: 3.9637e-04\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5119e-04 - val_loss: 4.3056e-04\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.4125e-04 - val_loss: 3.4399e-04\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.4991e-04 - val_loss: 4.0790e-04\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.2745e-04 - val_loss: 4.0097e-04\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.0963e-04 - val_loss: 4.2705e-04\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.1075e-04 - val_loss: 3.3967e-04\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 8.6516e-05 - val_loss: 3.5411e-04\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.1477e-04 - val_loss: 3.4173e-04\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1286e-04 - val_loss: 3.1391e-04\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 9.0013e-05 - val_loss: 3.2437e-04\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.0377e-05 - val_loss: 3.0560e-04\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 7.5814e-05 - val_loss: 2.9644e-04\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1.2840e-04 - val_loss: 3.1121e-04\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.7606e-04 - val_loss: 5.5706e-04\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.6439e-04 - val_loss: 9.1810e-04\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.5402e-04 - val_loss: 8.0024e-04\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.3841e-04 - val_loss: 5.3200e-04\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.7807e-04 - val_loss: 3.6445e-04\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.7363e-04 - val_loss: 4.3152e-04\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.4969e-04 - val_loss: 7.2957e-04\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.6406e-04 - val_loss: 3.7324e-04\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 2.2973e-04 - val_loss: 3.3334e-04\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2.6129e-04 - val_loss: 5.3339e-04\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.1532e-04 - val_loss: 4.8133e-04\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 3.8564e-04 - val_loss: 4.6975e-04\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.2288e-04 - val_loss: 6.3359e-04\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 5.4195e-04 - val_loss: 5.6632e-04\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.5584e-04 - val_loss: 3.3508e-04\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.1420e-04 - val_loss: 2.7137e-04\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.9826e-04 - val_loss: 5.9766e-04\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 3.3228e-04 - val_loss: 4.5356e-04\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 3.5295e-04 - val_loss: 6.1645e-04\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.7188e-04 - val_loss: 3.3208e-04\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.4050e-04 - val_loss: 3.2408e-04\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.9791e-04 - val_loss: 7.1823e-04\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.6684e-04 - val_loss: 6.8671e-04\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2.4303e-04 - val_loss: 2.8884e-04\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.4633e-04 - val_loss: 5.5806e-04\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 2.1471e-04 - val_loss: 3.8566e-04\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1.9275e-04 - val_loss: 4.0279e-04\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1.5736e-04 - val_loss: 4.0798e-04\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.1527e-04 - val_loss: 7.3655e-04\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 7.3061e-04 - val_loss: 0.0013\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 8.2111e-04 - val_loss: 6.2518e-04\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.4249e-04 - val_loss: 9.6124e-04\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.9380e-04 - val_loss: 7.0410e-04\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.3912e-04 - val_loss: 7.0387e-04\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.1629e-04 - val_loss: 5.0886e-04\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.8152e-04 - val_loss: 4.7123e-04\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.1321e-04 - val_loss: 3.2410e-04\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.3992e-04 - val_loss: 7.4770e-04\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.1515e-04 - val_loss: 4.3178e-04\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2.7243e-04 - val_loss: 3.8663e-04\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.8246e-04 - val_loss: 4.0036e-04\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.5795e-04 - val_loss: 3.7751e-04\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.7469e-04 - val_loss: 3.3249e-04\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.5011e-04 - val_loss: 3.1341e-04\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3452e-04 - val_loss: 4.3438e-04\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.2148e-04 - val_loss: 3.5048e-04\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.8872e-04 - val_loss: 3.8991e-04\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.6775e-04 - val_loss: 4.2373e-04\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.6303e-04 - val_loss: 4.4556e-04\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.6582e-04 - val_loss: 2.5530e-04\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.4035e-04 - val_loss: 4.9349e-04\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.3098e-04 - val_loss: 3.7439e-04\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 4.5157e-04 - val_loss: 3.5459e-04\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 3.7350e-04 - val_loss: 8.9110e-04\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.1504e-04 - val_loss: 6.1767e-04\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 2.4252e-04 - val_loss: 5.3179e-04\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.9760e-04 - val_loss: 3.3865e-04\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.3598e-04 - val_loss: 6.7070e-04\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 7.4369e-04 - val_loss: 6.9586e-04\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.6637e-04 - val_loss: 8.2926e-04\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.1949e-04 - val_loss: 7.5935e-04\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.8451e-04 - val_loss: 4.2378e-04\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.8429e-04 - val_loss: 3.9618e-04\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.2713e-04 - val_loss: 6.0296e-04\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.2704e-04 - val_loss: 3.8059e-04\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.2330e-04 - val_loss: 5.5515e-04\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 5.4452e-04 - val_loss: 6.8665e-04\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.7966e-04 - val_loss: 5.3998e-04\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.2138e-04 - val_loss: 9.1625e-04\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.9951e-04 - val_loss: 4.8291e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a3177dd58d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0nv-_uOrzxC",
        "outputId": "3b6e51f2-b7e2-496d-e1ff-4f391921b440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y_pred[:,0], y_pred[:,1], 'ko')\n",
        "plt.plot(y_pred[:,0], y_pred[:,1],'*r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "hMA5tBw0r5PF",
        "outputId": "48bb9af7-142d-48ae-8caa-9e8cf8288f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,)),\n",
        "    tf.keras.layers.Dense(10,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "metadata": {
        "id": "LUJbdbCxsvno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-2)"
      ],
      "metadata": {
        "id": "BHkGaCeytKZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_true, y_pred):\n",
        "    loss = tf.math.square(y_true - y_pred)\n",
        "    return tf.math.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "y-5WxuTGtQQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for num_epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(x_train)\n",
        "        loss = loss_fn(y_train, y_pred)\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    print('Epoch %s: Loss %.4f' %(num_epoch, loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ArXW1u6tbsE",
        "outputId": "f3139b54-3ff4-46be-a19f-801b82bfad92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 2.4240\n",
            "Epoch 1: Loss 2.2604\n",
            "Epoch 2: Loss 2.1116\n",
            "Epoch 3: Loss 1.9757\n",
            "Epoch 4: Loss 1.8515\n",
            "Epoch 5: Loss 1.7371\n",
            "Epoch 6: Loss 1.6331\n",
            "Epoch 7: Loss 1.5439\n",
            "Epoch 8: Loss 1.4626\n",
            "Epoch 9: Loss 1.3872\n",
            "Epoch 10: Loss 1.3174\n",
            "Epoch 11: Loss 1.2528\n",
            "Epoch 12: Loss 1.1936\n",
            "Epoch 13: Loss 1.1392\n",
            "Epoch 14: Loss 1.0878\n",
            "Epoch 15: Loss 1.0376\n",
            "Epoch 16: Loss 0.9875\n",
            "Epoch 17: Loss 0.9379\n",
            "Epoch 18: Loss 0.8894\n",
            "Epoch 19: Loss 0.8433\n",
            "Epoch 20: Loss 0.8004\n",
            "Epoch 21: Loss 0.7612\n",
            "Epoch 22: Loss 0.7253\n",
            "Epoch 23: Loss 0.6917\n",
            "Epoch 24: Loss 0.6596\n",
            "Epoch 25: Loss 0.6285\n",
            "Epoch 26: Loss 0.5979\n",
            "Epoch 27: Loss 0.5676\n",
            "Epoch 28: Loss 0.5384\n",
            "Epoch 29: Loss 0.5110\n",
            "Epoch 30: Loss 0.4849\n",
            "Epoch 31: Loss 0.4604\n",
            "Epoch 32: Loss 0.4376\n",
            "Epoch 33: Loss 0.4168\n",
            "Epoch 34: Loss 0.3978\n",
            "Epoch 35: Loss 0.3802\n",
            "Epoch 36: Loss 0.3638\n",
            "Epoch 37: Loss 0.3482\n",
            "Epoch 38: Loss 0.3334\n",
            "Epoch 39: Loss 0.3197\n",
            "Epoch 40: Loss 0.3071\n",
            "Epoch 41: Loss 0.2960\n",
            "Epoch 42: Loss 0.2861\n",
            "Epoch 43: Loss 0.2771\n",
            "Epoch 44: Loss 0.2686\n",
            "Epoch 45: Loss 0.2601\n",
            "Epoch 46: Loss 0.2514\n",
            "Epoch 47: Loss 0.2426\n",
            "Epoch 48: Loss 0.2337\n",
            "Epoch 49: Loss 0.2251\n",
            "Epoch 50: Loss 0.2173\n",
            "Epoch 51: Loss 0.2103\n",
            "Epoch 52: Loss 0.2038\n",
            "Epoch 53: Loss 0.1976\n",
            "Epoch 54: Loss 0.1916\n",
            "Epoch 55: Loss 0.1858\n",
            "Epoch 56: Loss 0.1802\n",
            "Epoch 57: Loss 0.1749\n",
            "Epoch 58: Loss 0.1700\n",
            "Epoch 59: Loss 0.1657\n",
            "Epoch 60: Loss 0.1618\n",
            "Epoch 61: Loss 0.1582\n",
            "Epoch 62: Loss 0.1549\n",
            "Epoch 63: Loss 0.1518\n",
            "Epoch 64: Loss 0.1489\n",
            "Epoch 65: Loss 0.1461\n",
            "Epoch 66: Loss 0.1434\n",
            "Epoch 67: Loss 0.1408\n",
            "Epoch 68: Loss 0.1384\n",
            "Epoch 69: Loss 0.1362\n",
            "Epoch 70: Loss 0.1339\n",
            "Epoch 71: Loss 0.1317\n",
            "Epoch 72: Loss 0.1295\n",
            "Epoch 73: Loss 0.1273\n",
            "Epoch 74: Loss 0.1252\n",
            "Epoch 75: Loss 0.1230\n",
            "Epoch 76: Loss 0.1210\n",
            "Epoch 77: Loss 0.1188\n",
            "Epoch 78: Loss 0.1166\n",
            "Epoch 79: Loss 0.1142\n",
            "Epoch 80: Loss 0.1119\n",
            "Epoch 81: Loss 0.1096\n",
            "Epoch 82: Loss 0.1072\n",
            "Epoch 83: Loss 0.1048\n",
            "Epoch 84: Loss 0.1025\n",
            "Epoch 85: Loss 0.1003\n",
            "Epoch 86: Loss 0.0981\n",
            "Epoch 87: Loss 0.0959\n",
            "Epoch 88: Loss 0.0938\n",
            "Epoch 89: Loss 0.0915\n",
            "Epoch 90: Loss 0.0893\n",
            "Epoch 91: Loss 0.0869\n",
            "Epoch 92: Loss 0.0844\n",
            "Epoch 93: Loss 0.0819\n",
            "Epoch 94: Loss 0.0794\n",
            "Epoch 95: Loss 0.0769\n",
            "Epoch 96: Loss 0.0745\n",
            "Epoch 97: Loss 0.0721\n",
            "Epoch 98: Loss 0.0697\n",
            "Epoch 99: Loss 0.0673\n",
            "Epoch 100: Loss 0.0648\n",
            "Epoch 101: Loss 0.0625\n",
            "Epoch 102: Loss 0.0604\n",
            "Epoch 103: Loss 0.0583\n",
            "Epoch 104: Loss 0.0562\n",
            "Epoch 105: Loss 0.0543\n",
            "Epoch 106: Loss 0.0524\n",
            "Epoch 107: Loss 0.0508\n",
            "Epoch 108: Loss 0.0494\n",
            "Epoch 109: Loss 0.0482\n",
            "Epoch 110: Loss 0.0469\n",
            "Epoch 111: Loss 0.0457\n",
            "Epoch 112: Loss 0.0446\n",
            "Epoch 113: Loss 0.0435\n",
            "Epoch 114: Loss 0.0425\n",
            "Epoch 115: Loss 0.0417\n",
            "Epoch 116: Loss 0.0410\n",
            "Epoch 117: Loss 0.0404\n",
            "Epoch 118: Loss 0.0397\n",
            "Epoch 119: Loss 0.0391\n",
            "Epoch 120: Loss 0.0385\n",
            "Epoch 121: Loss 0.0380\n",
            "Epoch 122: Loss 0.0374\n",
            "Epoch 123: Loss 0.0370\n",
            "Epoch 124: Loss 0.0365\n",
            "Epoch 125: Loss 0.0361\n",
            "Epoch 126: Loss 0.0357\n",
            "Epoch 127: Loss 0.0354\n",
            "Epoch 128: Loss 0.0350\n",
            "Epoch 129: Loss 0.0346\n",
            "Epoch 130: Loss 0.0343\n",
            "Epoch 131: Loss 0.0339\n",
            "Epoch 132: Loss 0.0336\n",
            "Epoch 133: Loss 0.0332\n",
            "Epoch 134: Loss 0.0329\n",
            "Epoch 135: Loss 0.0326\n",
            "Epoch 136: Loss 0.0324\n",
            "Epoch 137: Loss 0.0321\n",
            "Epoch 138: Loss 0.0318\n",
            "Epoch 139: Loss 0.0315\n",
            "Epoch 140: Loss 0.0313\n",
            "Epoch 141: Loss 0.0310\n",
            "Epoch 142: Loss 0.0308\n",
            "Epoch 143: Loss 0.0305\n",
            "Epoch 144: Loss 0.0303\n",
            "Epoch 145: Loss 0.0300\n",
            "Epoch 146: Loss 0.0298\n",
            "Epoch 147: Loss 0.0295\n",
            "Epoch 148: Loss 0.0293\n",
            "Epoch 149: Loss 0.0291\n",
            "Epoch 150: Loss 0.0288\n",
            "Epoch 151: Loss 0.0286\n",
            "Epoch 152: Loss 0.0284\n",
            "Epoch 153: Loss 0.0282\n",
            "Epoch 154: Loss 0.0279\n",
            "Epoch 155: Loss 0.0277\n",
            "Epoch 156: Loss 0.0275\n",
            "Epoch 157: Loss 0.0273\n",
            "Epoch 158: Loss 0.0271\n",
            "Epoch 159: Loss 0.0269\n",
            "Epoch 160: Loss 0.0266\n",
            "Epoch 161: Loss 0.0264\n",
            "Epoch 162: Loss 0.0262\n",
            "Epoch 163: Loss 0.0259\n",
            "Epoch 164: Loss 0.0257\n",
            "Epoch 165: Loss 0.0254\n",
            "Epoch 166: Loss 0.0251\n",
            "Epoch 167: Loss 0.0248\n",
            "Epoch 168: Loss 0.0245\n",
            "Epoch 169: Loss 0.0242\n",
            "Epoch 170: Loss 0.0239\n",
            "Epoch 171: Loss 0.0235\n",
            "Epoch 172: Loss 0.0232\n",
            "Epoch 173: Loss 0.0229\n",
            "Epoch 174: Loss 0.0225\n",
            "Epoch 175: Loss 0.0221\n",
            "Epoch 176: Loss 0.0217\n",
            "Epoch 177: Loss 0.0214\n",
            "Epoch 178: Loss 0.0210\n",
            "Epoch 179: Loss 0.0207\n",
            "Epoch 180: Loss 0.0205\n",
            "Epoch 181: Loss 0.0203\n",
            "Epoch 182: Loss 0.0200\n",
            "Epoch 183: Loss 0.0198\n",
            "Epoch 184: Loss 0.0194\n",
            "Epoch 185: Loss 0.0191\n",
            "Epoch 186: Loss 0.0188\n",
            "Epoch 187: Loss 0.0186\n",
            "Epoch 188: Loss 0.0183\n",
            "Epoch 189: Loss 0.0181\n",
            "Epoch 190: Loss 0.0179\n",
            "Epoch 191: Loss 0.0177\n",
            "Epoch 192: Loss 0.0175\n",
            "Epoch 193: Loss 0.0173\n",
            "Epoch 194: Loss 0.0171\n",
            "Epoch 195: Loss 0.0169\n",
            "Epoch 196: Loss 0.0168\n",
            "Epoch 197: Loss 0.0166\n",
            "Epoch 198: Loss 0.0165\n",
            "Epoch 199: Loss 0.0163\n",
            "Epoch 200: Loss 0.0161\n",
            "Epoch 201: Loss 0.0160\n",
            "Epoch 202: Loss 0.0158\n",
            "Epoch 203: Loss 0.0156\n",
            "Epoch 204: Loss 0.0154\n",
            "Epoch 205: Loss 0.0153\n",
            "Epoch 206: Loss 0.0151\n",
            "Epoch 207: Loss 0.0149\n",
            "Epoch 208: Loss 0.0148\n",
            "Epoch 209: Loss 0.0147\n",
            "Epoch 210: Loss 0.0145\n",
            "Epoch 211: Loss 0.0144\n",
            "Epoch 212: Loss 0.0142\n",
            "Epoch 213: Loss 0.0141\n",
            "Epoch 214: Loss 0.0140\n",
            "Epoch 215: Loss 0.0138\n",
            "Epoch 216: Loss 0.0137\n",
            "Epoch 217: Loss 0.0136\n",
            "Epoch 218: Loss 0.0134\n",
            "Epoch 219: Loss 0.0133\n",
            "Epoch 220: Loss 0.0132\n",
            "Epoch 221: Loss 0.0131\n",
            "Epoch 222: Loss 0.0130\n",
            "Epoch 223: Loss 0.0129\n",
            "Epoch 224: Loss 0.0128\n",
            "Epoch 225: Loss 0.0127\n",
            "Epoch 226: Loss 0.0126\n",
            "Epoch 227: Loss 0.0125\n",
            "Epoch 228: Loss 0.0124\n",
            "Epoch 229: Loss 0.0123\n",
            "Epoch 230: Loss 0.0122\n",
            "Epoch 231: Loss 0.0121\n",
            "Epoch 232: Loss 0.0120\n",
            "Epoch 233: Loss 0.0119\n",
            "Epoch 234: Loss 0.0119\n",
            "Epoch 235: Loss 0.0118\n",
            "Epoch 236: Loss 0.0117\n",
            "Epoch 237: Loss 0.0116\n",
            "Epoch 238: Loss 0.0116\n",
            "Epoch 239: Loss 0.0115\n",
            "Epoch 240: Loss 0.0114\n",
            "Epoch 241: Loss 0.0114\n",
            "Epoch 242: Loss 0.0113\n",
            "Epoch 243: Loss 0.0112\n",
            "Epoch 244: Loss 0.0112\n",
            "Epoch 245: Loss 0.0111\n",
            "Epoch 246: Loss 0.0110\n",
            "Epoch 247: Loss 0.0110\n",
            "Epoch 248: Loss 0.0109\n",
            "Epoch 249: Loss 0.0109\n",
            "Epoch 250: Loss 0.0108\n",
            "Epoch 251: Loss 0.0108\n",
            "Epoch 252: Loss 0.0107\n",
            "Epoch 253: Loss 0.0106\n",
            "Epoch 254: Loss 0.0106\n",
            "Epoch 255: Loss 0.0105\n",
            "Epoch 256: Loss 0.0105\n",
            "Epoch 257: Loss 0.0104\n",
            "Epoch 258: Loss 0.0104\n",
            "Epoch 259: Loss 0.0103\n",
            "Epoch 260: Loss 0.0103\n",
            "Epoch 261: Loss 0.0103\n",
            "Epoch 262: Loss 0.0102\n",
            "Epoch 263: Loss 0.0102\n",
            "Epoch 264: Loss 0.0101\n",
            "Epoch 265: Loss 0.0101\n",
            "Epoch 266: Loss 0.0100\n",
            "Epoch 267: Loss 0.0100\n",
            "Epoch 268: Loss 0.0099\n",
            "Epoch 269: Loss 0.0099\n",
            "Epoch 270: Loss 0.0099\n",
            "Epoch 271: Loss 0.0098\n",
            "Epoch 272: Loss 0.0098\n",
            "Epoch 273: Loss 0.0097\n",
            "Epoch 274: Loss 0.0097\n",
            "Epoch 275: Loss 0.0096\n",
            "Epoch 276: Loss 0.0096\n",
            "Epoch 277: Loss 0.0096\n",
            "Epoch 278: Loss 0.0095\n",
            "Epoch 279: Loss 0.0095\n",
            "Epoch 280: Loss 0.0094\n",
            "Epoch 281: Loss 0.0094\n",
            "Epoch 282: Loss 0.0094\n",
            "Epoch 283: Loss 0.0093\n",
            "Epoch 284: Loss 0.0093\n",
            "Epoch 285: Loss 0.0092\n",
            "Epoch 286: Loss 0.0092\n",
            "Epoch 287: Loss 0.0092\n",
            "Epoch 288: Loss 0.0091\n",
            "Epoch 289: Loss 0.0091\n",
            "Epoch 290: Loss 0.0090\n",
            "Epoch 291: Loss 0.0090\n",
            "Epoch 292: Loss 0.0090\n",
            "Epoch 293: Loss 0.0089\n",
            "Epoch 294: Loss 0.0089\n",
            "Epoch 295: Loss 0.0089\n",
            "Epoch 296: Loss 0.0088\n",
            "Epoch 297: Loss 0.0088\n",
            "Epoch 298: Loss 0.0088\n",
            "Epoch 299: Loss 0.0087\n",
            "Epoch 300: Loss 0.0087\n",
            "Epoch 301: Loss 0.0086\n",
            "Epoch 302: Loss 0.0086\n",
            "Epoch 303: Loss 0.0086\n",
            "Epoch 304: Loss 0.0085\n",
            "Epoch 305: Loss 0.0085\n",
            "Epoch 306: Loss 0.0085\n",
            "Epoch 307: Loss 0.0084\n",
            "Epoch 308: Loss 0.0084\n",
            "Epoch 309: Loss 0.0084\n",
            "Epoch 310: Loss 0.0083\n",
            "Epoch 311: Loss 0.0083\n",
            "Epoch 312: Loss 0.0083\n",
            "Epoch 313: Loss 0.0082\n",
            "Epoch 314: Loss 0.0082\n",
            "Epoch 315: Loss 0.0082\n",
            "Epoch 316: Loss 0.0081\n",
            "Epoch 317: Loss 0.0081\n",
            "Epoch 318: Loss 0.0081\n",
            "Epoch 319: Loss 0.0080\n",
            "Epoch 320: Loss 0.0080\n",
            "Epoch 321: Loss 0.0080\n",
            "Epoch 322: Loss 0.0080\n",
            "Epoch 323: Loss 0.0079\n",
            "Epoch 324: Loss 0.0079\n",
            "Epoch 325: Loss 0.0079\n",
            "Epoch 326: Loss 0.0079\n",
            "Epoch 327: Loss 0.0078\n",
            "Epoch 328: Loss 0.0078\n",
            "Epoch 329: Loss 0.0078\n",
            "Epoch 330: Loss 0.0077\n",
            "Epoch 331: Loss 0.0077\n",
            "Epoch 332: Loss 0.0077\n",
            "Epoch 333: Loss 0.0077\n",
            "Epoch 334: Loss 0.0076\n",
            "Epoch 335: Loss 0.0076\n",
            "Epoch 336: Loss 0.0076\n",
            "Epoch 337: Loss 0.0076\n",
            "Epoch 338: Loss 0.0075\n",
            "Epoch 339: Loss 0.0075\n",
            "Epoch 340: Loss 0.0075\n",
            "Epoch 341: Loss 0.0075\n",
            "Epoch 342: Loss 0.0074\n",
            "Epoch 343: Loss 0.0074\n",
            "Epoch 344: Loss 0.0074\n",
            "Epoch 345: Loss 0.0074\n",
            "Epoch 346: Loss 0.0073\n",
            "Epoch 347: Loss 0.0073\n",
            "Epoch 348: Loss 0.0073\n",
            "Epoch 349: Loss 0.0073\n",
            "Epoch 350: Loss 0.0073\n",
            "Epoch 351: Loss 0.0072\n",
            "Epoch 352: Loss 0.0072\n",
            "Epoch 353: Loss 0.0072\n",
            "Epoch 354: Loss 0.0072\n",
            "Epoch 355: Loss 0.0071\n",
            "Epoch 356: Loss 0.0071\n",
            "Epoch 357: Loss 0.0071\n",
            "Epoch 358: Loss 0.0071\n",
            "Epoch 359: Loss 0.0070\n",
            "Epoch 360: Loss 0.0070\n",
            "Epoch 361: Loss 0.0070\n",
            "Epoch 362: Loss 0.0070\n",
            "Epoch 363: Loss 0.0070\n",
            "Epoch 364: Loss 0.0069\n",
            "Epoch 365: Loss 0.0069\n",
            "Epoch 366: Loss 0.0069\n",
            "Epoch 367: Loss 0.0069\n",
            "Epoch 368: Loss 0.0068\n",
            "Epoch 369: Loss 0.0068\n",
            "Epoch 370: Loss 0.0068\n",
            "Epoch 371: Loss 0.0068\n",
            "Epoch 372: Loss 0.0068\n",
            "Epoch 373: Loss 0.0067\n",
            "Epoch 374: Loss 0.0067\n",
            "Epoch 375: Loss 0.0067\n",
            "Epoch 376: Loss 0.0067\n",
            "Epoch 377: Loss 0.0067\n",
            "Epoch 378: Loss 0.0066\n",
            "Epoch 379: Loss 0.0066\n",
            "Epoch 380: Loss 0.0066\n",
            "Epoch 381: Loss 0.0066\n",
            "Epoch 382: Loss 0.0066\n",
            "Epoch 383: Loss 0.0065\n",
            "Epoch 384: Loss 0.0065\n",
            "Epoch 385: Loss 0.0065\n",
            "Epoch 386: Loss 0.0065\n",
            "Epoch 387: Loss 0.0065\n",
            "Epoch 388: Loss 0.0064\n",
            "Epoch 389: Loss 0.0064\n",
            "Epoch 390: Loss 0.0064\n",
            "Epoch 391: Loss 0.0064\n",
            "Epoch 392: Loss 0.0064\n",
            "Epoch 393: Loss 0.0063\n",
            "Epoch 394: Loss 0.0063\n",
            "Epoch 395: Loss 0.0063\n",
            "Epoch 396: Loss 0.0063\n",
            "Epoch 397: Loss 0.0063\n",
            "Epoch 398: Loss 0.0063\n",
            "Epoch 399: Loss 0.0062\n",
            "Epoch 400: Loss 0.0062\n",
            "Epoch 401: Loss 0.0062\n",
            "Epoch 402: Loss 0.0062\n",
            "Epoch 403: Loss 0.0061\n",
            "Epoch 404: Loss 0.0061\n",
            "Epoch 405: Loss 0.0061\n",
            "Epoch 406: Loss 0.0061\n",
            "Epoch 407: Loss 0.0061\n",
            "Epoch 408: Loss 0.0060\n",
            "Epoch 409: Loss 0.0060\n",
            "Epoch 410: Loss 0.0060\n",
            "Epoch 411: Loss 0.0060\n",
            "Epoch 412: Loss 0.0060\n",
            "Epoch 413: Loss 0.0059\n",
            "Epoch 414: Loss 0.0059\n",
            "Epoch 415: Loss 0.0059\n",
            "Epoch 416: Loss 0.0059\n",
            "Epoch 417: Loss 0.0058\n",
            "Epoch 418: Loss 0.0058\n",
            "Epoch 419: Loss 0.0058\n",
            "Epoch 420: Loss 0.0058\n",
            "Epoch 421: Loss 0.0057\n",
            "Epoch 422: Loss 0.0057\n",
            "Epoch 423: Loss 0.0057\n",
            "Epoch 424: Loss 0.0057\n",
            "Epoch 425: Loss 0.0057\n",
            "Epoch 426: Loss 0.0056\n",
            "Epoch 427: Loss 0.0056\n",
            "Epoch 428: Loss 0.0056\n",
            "Epoch 429: Loss 0.0056\n",
            "Epoch 430: Loss 0.0056\n",
            "Epoch 431: Loss 0.0055\n",
            "Epoch 432: Loss 0.0055\n",
            "Epoch 433: Loss 0.0055\n",
            "Epoch 434: Loss 0.0055\n",
            "Epoch 435: Loss 0.0054\n",
            "Epoch 436: Loss 0.0054\n",
            "Epoch 437: Loss 0.0054\n",
            "Epoch 438: Loss 0.0054\n",
            "Epoch 439: Loss 0.0054\n",
            "Epoch 440: Loss 0.0053\n",
            "Epoch 441: Loss 0.0053\n",
            "Epoch 442: Loss 0.0053\n",
            "Epoch 443: Loss 0.0053\n",
            "Epoch 444: Loss 0.0053\n",
            "Epoch 445: Loss 0.0052\n",
            "Epoch 446: Loss 0.0052\n",
            "Epoch 447: Loss 0.0052\n",
            "Epoch 448: Loss 0.0052\n",
            "Epoch 449: Loss 0.0052\n",
            "Epoch 450: Loss 0.0051\n",
            "Epoch 451: Loss 0.0051\n",
            "Epoch 452: Loss 0.0051\n",
            "Epoch 453: Loss 0.0051\n",
            "Epoch 454: Loss 0.0051\n",
            "Epoch 455: Loss 0.0050\n",
            "Epoch 456: Loss 0.0050\n",
            "Epoch 457: Loss 0.0050\n",
            "Epoch 458: Loss 0.0050\n",
            "Epoch 459: Loss 0.0050\n",
            "Epoch 460: Loss 0.0049\n",
            "Epoch 461: Loss 0.0049\n",
            "Epoch 462: Loss 0.0049\n",
            "Epoch 463: Loss 0.0049\n",
            "Epoch 464: Loss 0.0049\n",
            "Epoch 465: Loss 0.0048\n",
            "Epoch 466: Loss 0.0048\n",
            "Epoch 467: Loss 0.0048\n",
            "Epoch 468: Loss 0.0048\n",
            "Epoch 469: Loss 0.0048\n",
            "Epoch 470: Loss 0.0048\n",
            "Epoch 471: Loss 0.0047\n",
            "Epoch 472: Loss 0.0047\n",
            "Epoch 473: Loss 0.0047\n",
            "Epoch 474: Loss 0.0047\n",
            "Epoch 475: Loss 0.0047\n",
            "Epoch 476: Loss 0.0046\n",
            "Epoch 477: Loss 0.0046\n",
            "Epoch 478: Loss 0.0046\n",
            "Epoch 479: Loss 0.0046\n",
            "Epoch 480: Loss 0.0046\n",
            "Epoch 481: Loss 0.0045\n",
            "Epoch 482: Loss 0.0045\n",
            "Epoch 483: Loss 0.0045\n",
            "Epoch 484: Loss 0.0045\n",
            "Epoch 485: Loss 0.0045\n",
            "Epoch 486: Loss 0.0045\n",
            "Epoch 487: Loss 0.0045\n",
            "Epoch 488: Loss 0.0044\n",
            "Epoch 489: Loss 0.0044\n",
            "Epoch 490: Loss 0.0044\n",
            "Epoch 491: Loss 0.0044\n",
            "Epoch 492: Loss 0.0044\n",
            "Epoch 493: Loss 0.0044\n",
            "Epoch 494: Loss 0.0044\n",
            "Epoch 495: Loss 0.0043\n",
            "Epoch 496: Loss 0.0043\n",
            "Epoch 497: Loss 0.0043\n",
            "Epoch 498: Loss 0.0043\n",
            "Epoch 499: Loss 0.0043\n",
            "Epoch 500: Loss 0.0043\n",
            "Epoch 501: Loss 0.0043\n",
            "Epoch 502: Loss 0.0043\n",
            "Epoch 503: Loss 0.0042\n",
            "Epoch 504: Loss 0.0042\n",
            "Epoch 505: Loss 0.0042\n",
            "Epoch 506: Loss 0.0042\n",
            "Epoch 507: Loss 0.0042\n",
            "Epoch 508: Loss 0.0042\n",
            "Epoch 509: Loss 0.0042\n",
            "Epoch 510: Loss 0.0042\n",
            "Epoch 511: Loss 0.0042\n",
            "Epoch 512: Loss 0.0041\n",
            "Epoch 513: Loss 0.0041\n",
            "Epoch 514: Loss 0.0041\n",
            "Epoch 515: Loss 0.0041\n",
            "Epoch 516: Loss 0.0041\n",
            "Epoch 517: Loss 0.0041\n",
            "Epoch 518: Loss 0.0041\n",
            "Epoch 519: Loss 0.0041\n",
            "Epoch 520: Loss 0.0041\n",
            "Epoch 521: Loss 0.0041\n",
            "Epoch 522: Loss 0.0040\n",
            "Epoch 523: Loss 0.0040\n",
            "Epoch 524: Loss 0.0040\n",
            "Epoch 525: Loss 0.0040\n",
            "Epoch 526: Loss 0.0040\n",
            "Epoch 527: Loss 0.0040\n",
            "Epoch 528: Loss 0.0040\n",
            "Epoch 529: Loss 0.0039\n",
            "Epoch 530: Loss 0.0039\n",
            "Epoch 531: Loss 0.0039\n",
            "Epoch 532: Loss 0.0039\n",
            "Epoch 533: Loss 0.0039\n",
            "Epoch 534: Loss 0.0039\n",
            "Epoch 535: Loss 0.0039\n",
            "Epoch 536: Loss 0.0039\n",
            "Epoch 537: Loss 0.0039\n",
            "Epoch 538: Loss 0.0038\n",
            "Epoch 539: Loss 0.0039\n",
            "Epoch 540: Loss 0.0038\n",
            "Epoch 541: Loss 0.0038\n",
            "Epoch 542: Loss 0.0038\n",
            "Epoch 543: Loss 0.0038\n",
            "Epoch 544: Loss 0.0038\n",
            "Epoch 545: Loss 0.0038\n",
            "Epoch 546: Loss 0.0038\n",
            "Epoch 547: Loss 0.0038\n",
            "Epoch 548: Loss 0.0038\n",
            "Epoch 549: Loss 0.0037\n",
            "Epoch 550: Loss 0.0037\n",
            "Epoch 551: Loss 0.0037\n",
            "Epoch 552: Loss 0.0037\n",
            "Epoch 553: Loss 0.0037\n",
            "Epoch 554: Loss 0.0037\n",
            "Epoch 555: Loss 0.0037\n",
            "Epoch 556: Loss 0.0037\n",
            "Epoch 557: Loss 0.0037\n",
            "Epoch 558: Loss 0.0037\n",
            "Epoch 559: Loss 0.0037\n",
            "Epoch 560: Loss 0.0037\n",
            "Epoch 561: Loss 0.0037\n",
            "Epoch 562: Loss 0.0036\n",
            "Epoch 563: Loss 0.0036\n",
            "Epoch 564: Loss 0.0036\n",
            "Epoch 565: Loss 0.0036\n",
            "Epoch 566: Loss 0.0036\n",
            "Epoch 567: Loss 0.0036\n",
            "Epoch 568: Loss 0.0036\n",
            "Epoch 569: Loss 0.0036\n",
            "Epoch 570: Loss 0.0036\n",
            "Epoch 571: Loss 0.0036\n",
            "Epoch 572: Loss 0.0036\n",
            "Epoch 573: Loss 0.0036\n",
            "Epoch 574: Loss 0.0035\n",
            "Epoch 575: Loss 0.0035\n",
            "Epoch 576: Loss 0.0035\n",
            "Epoch 577: Loss 0.0035\n",
            "Epoch 578: Loss 0.0035\n",
            "Epoch 579: Loss 0.0035\n",
            "Epoch 580: Loss 0.0035\n",
            "Epoch 581: Loss 0.0035\n",
            "Epoch 582: Loss 0.0035\n",
            "Epoch 583: Loss 0.0035\n",
            "Epoch 584: Loss 0.0035\n",
            "Epoch 585: Loss 0.0035\n",
            "Epoch 586: Loss 0.0034\n",
            "Epoch 587: Loss 0.0034\n",
            "Epoch 588: Loss 0.0034\n",
            "Epoch 589: Loss 0.0034\n",
            "Epoch 590: Loss 0.0034\n",
            "Epoch 591: Loss 0.0034\n",
            "Epoch 592: Loss 0.0034\n",
            "Epoch 593: Loss 0.0034\n",
            "Epoch 594: Loss 0.0034\n",
            "Epoch 595: Loss 0.0034\n",
            "Epoch 596: Loss 0.0033\n",
            "Epoch 597: Loss 0.0033\n",
            "Epoch 598: Loss 0.0033\n",
            "Epoch 599: Loss 0.0033\n",
            "Epoch 600: Loss 0.0033\n",
            "Epoch 601: Loss 0.0033\n",
            "Epoch 602: Loss 0.0033\n",
            "Epoch 603: Loss 0.0033\n",
            "Epoch 604: Loss 0.0033\n",
            "Epoch 605: Loss 0.0033\n",
            "Epoch 606: Loss 0.0033\n",
            "Epoch 607: Loss 0.0032\n",
            "Epoch 608: Loss 0.0032\n",
            "Epoch 609: Loss 0.0032\n",
            "Epoch 610: Loss 0.0032\n",
            "Epoch 611: Loss 0.0032\n",
            "Epoch 612: Loss 0.0032\n",
            "Epoch 613: Loss 0.0032\n",
            "Epoch 614: Loss 0.0032\n",
            "Epoch 615: Loss 0.0032\n",
            "Epoch 616: Loss 0.0032\n",
            "Epoch 617: Loss 0.0032\n",
            "Epoch 618: Loss 0.0032\n",
            "Epoch 619: Loss 0.0032\n",
            "Epoch 620: Loss 0.0031\n",
            "Epoch 621: Loss 0.0031\n",
            "Epoch 622: Loss 0.0031\n",
            "Epoch 623: Loss 0.0031\n",
            "Epoch 624: Loss 0.0031\n",
            "Epoch 625: Loss 0.0031\n",
            "Epoch 626: Loss 0.0031\n",
            "Epoch 627: Loss 0.0031\n",
            "Epoch 628: Loss 0.0031\n",
            "Epoch 629: Loss 0.0031\n",
            "Epoch 630: Loss 0.0031\n",
            "Epoch 631: Loss 0.0031\n",
            "Epoch 632: Loss 0.0031\n",
            "Epoch 633: Loss 0.0030\n",
            "Epoch 634: Loss 0.0030\n",
            "Epoch 635: Loss 0.0030\n",
            "Epoch 636: Loss 0.0030\n",
            "Epoch 637: Loss 0.0030\n",
            "Epoch 638: Loss 0.0030\n",
            "Epoch 639: Loss 0.0030\n",
            "Epoch 640: Loss 0.0030\n",
            "Epoch 641: Loss 0.0030\n",
            "Epoch 642: Loss 0.0030\n",
            "Epoch 643: Loss 0.0030\n",
            "Epoch 644: Loss 0.0030\n",
            "Epoch 645: Loss 0.0030\n",
            "Epoch 646: Loss 0.0030\n",
            "Epoch 647: Loss 0.0029\n",
            "Epoch 648: Loss 0.0029\n",
            "Epoch 649: Loss 0.0029\n",
            "Epoch 650: Loss 0.0029\n",
            "Epoch 651: Loss 0.0029\n",
            "Epoch 652: Loss 0.0029\n",
            "Epoch 653: Loss 0.0029\n",
            "Epoch 654: Loss 0.0029\n",
            "Epoch 655: Loss 0.0029\n",
            "Epoch 656: Loss 0.0029\n",
            "Epoch 657: Loss 0.0029\n",
            "Epoch 658: Loss 0.0029\n",
            "Epoch 659: Loss 0.0029\n",
            "Epoch 660: Loss 0.0029\n",
            "Epoch 661: Loss 0.0029\n",
            "Epoch 662: Loss 0.0029\n",
            "Epoch 663: Loss 0.0029\n",
            "Epoch 664: Loss 0.0029\n",
            "Epoch 665: Loss 0.0029\n",
            "Epoch 666: Loss 0.0028\n",
            "Epoch 667: Loss 0.0028\n",
            "Epoch 668: Loss 0.0028\n",
            "Epoch 669: Loss 0.0028\n",
            "Epoch 670: Loss 0.0028\n",
            "Epoch 671: Loss 0.0028\n",
            "Epoch 672: Loss 0.0028\n",
            "Epoch 673: Loss 0.0028\n",
            "Epoch 674: Loss 0.0028\n",
            "Epoch 675: Loss 0.0028\n",
            "Epoch 676: Loss 0.0028\n",
            "Epoch 677: Loss 0.0028\n",
            "Epoch 678: Loss 0.0028\n",
            "Epoch 679: Loss 0.0028\n",
            "Epoch 680: Loss 0.0028\n",
            "Epoch 681: Loss 0.0028\n",
            "Epoch 682: Loss 0.0028\n",
            "Epoch 683: Loss 0.0028\n",
            "Epoch 684: Loss 0.0028\n",
            "Epoch 685: Loss 0.0028\n",
            "Epoch 686: Loss 0.0028\n",
            "Epoch 687: Loss 0.0027\n",
            "Epoch 688: Loss 0.0027\n",
            "Epoch 689: Loss 0.0027\n",
            "Epoch 690: Loss 0.0027\n",
            "Epoch 691: Loss 0.0027\n",
            "Epoch 692: Loss 0.0027\n",
            "Epoch 693: Loss 0.0027\n",
            "Epoch 694: Loss 0.0027\n",
            "Epoch 695: Loss 0.0027\n",
            "Epoch 696: Loss 0.0027\n",
            "Epoch 697: Loss 0.0027\n",
            "Epoch 698: Loss 0.0027\n",
            "Epoch 699: Loss 0.0027\n",
            "Epoch 700: Loss 0.0027\n",
            "Epoch 701: Loss 0.0027\n",
            "Epoch 702: Loss 0.0027\n",
            "Epoch 703: Loss 0.0027\n",
            "Epoch 704: Loss 0.0027\n",
            "Epoch 705: Loss 0.0027\n",
            "Epoch 706: Loss 0.0027\n",
            "Epoch 707: Loss 0.0027\n",
            "Epoch 708: Loss 0.0027\n",
            "Epoch 709: Loss 0.0027\n",
            "Epoch 710: Loss 0.0027\n",
            "Epoch 711: Loss 0.0027\n",
            "Epoch 712: Loss 0.0027\n",
            "Epoch 713: Loss 0.0026\n",
            "Epoch 714: Loss 0.0026\n",
            "Epoch 715: Loss 0.0026\n",
            "Epoch 716: Loss 0.0026\n",
            "Epoch 717: Loss 0.0026\n",
            "Epoch 718: Loss 0.0026\n",
            "Epoch 719: Loss 0.0026\n",
            "Epoch 720: Loss 0.0026\n",
            "Epoch 721: Loss 0.0026\n",
            "Epoch 722: Loss 0.0026\n",
            "Epoch 723: Loss 0.0026\n",
            "Epoch 724: Loss 0.0026\n",
            "Epoch 725: Loss 0.0026\n",
            "Epoch 726: Loss 0.0026\n",
            "Epoch 727: Loss 0.0026\n",
            "Epoch 728: Loss 0.0026\n",
            "Epoch 729: Loss 0.0026\n",
            "Epoch 730: Loss 0.0026\n",
            "Epoch 731: Loss 0.0026\n",
            "Epoch 732: Loss 0.0026\n",
            "Epoch 733: Loss 0.0026\n",
            "Epoch 734: Loss 0.0026\n",
            "Epoch 735: Loss 0.0026\n",
            "Epoch 736: Loss 0.0026\n",
            "Epoch 737: Loss 0.0026\n",
            "Epoch 738: Loss 0.0026\n",
            "Epoch 739: Loss 0.0026\n",
            "Epoch 740: Loss 0.0026\n",
            "Epoch 741: Loss 0.0026\n",
            "Epoch 742: Loss 0.0026\n",
            "Epoch 743: Loss 0.0026\n",
            "Epoch 744: Loss 0.0026\n",
            "Epoch 745: Loss 0.0026\n",
            "Epoch 746: Loss 0.0026\n",
            "Epoch 747: Loss 0.0025\n",
            "Epoch 748: Loss 0.0025\n",
            "Epoch 749: Loss 0.0025\n",
            "Epoch 750: Loss 0.0025\n",
            "Epoch 751: Loss 0.0025\n",
            "Epoch 752: Loss 0.0025\n",
            "Epoch 753: Loss 0.0025\n",
            "Epoch 754: Loss 0.0025\n",
            "Epoch 755: Loss 0.0025\n",
            "Epoch 756: Loss 0.0025\n",
            "Epoch 757: Loss 0.0025\n",
            "Epoch 758: Loss 0.0025\n",
            "Epoch 759: Loss 0.0025\n",
            "Epoch 760: Loss 0.0025\n",
            "Epoch 761: Loss 0.0025\n",
            "Epoch 762: Loss 0.0025\n",
            "Epoch 763: Loss 0.0025\n",
            "Epoch 764: Loss 0.0025\n",
            "Epoch 765: Loss 0.0025\n",
            "Epoch 766: Loss 0.0025\n",
            "Epoch 767: Loss 0.0025\n",
            "Epoch 768: Loss 0.0025\n",
            "Epoch 769: Loss 0.0025\n",
            "Epoch 770: Loss 0.0025\n",
            "Epoch 771: Loss 0.0025\n",
            "Epoch 772: Loss 0.0025\n",
            "Epoch 773: Loss 0.0025\n",
            "Epoch 774: Loss 0.0025\n",
            "Epoch 775: Loss 0.0025\n",
            "Epoch 776: Loss 0.0025\n",
            "Epoch 777: Loss 0.0025\n",
            "Epoch 778: Loss 0.0025\n",
            "Epoch 779: Loss 0.0025\n",
            "Epoch 780: Loss 0.0025\n",
            "Epoch 781: Loss 0.0025\n",
            "Epoch 782: Loss 0.0025\n",
            "Epoch 783: Loss 0.0025\n",
            "Epoch 784: Loss 0.0025\n",
            "Epoch 785: Loss 0.0025\n",
            "Epoch 786: Loss 0.0024\n",
            "Epoch 787: Loss 0.0024\n",
            "Epoch 788: Loss 0.0024\n",
            "Epoch 789: Loss 0.0024\n",
            "Epoch 790: Loss 0.0024\n",
            "Epoch 791: Loss 0.0024\n",
            "Epoch 792: Loss 0.0024\n",
            "Epoch 793: Loss 0.0024\n",
            "Epoch 794: Loss 0.0024\n",
            "Epoch 795: Loss 0.0024\n",
            "Epoch 796: Loss 0.0024\n",
            "Epoch 797: Loss 0.0024\n",
            "Epoch 798: Loss 0.0024\n",
            "Epoch 799: Loss 0.0024\n",
            "Epoch 800: Loss 0.0024\n",
            "Epoch 801: Loss 0.0024\n",
            "Epoch 802: Loss 0.0024\n",
            "Epoch 803: Loss 0.0024\n",
            "Epoch 804: Loss 0.0024\n",
            "Epoch 805: Loss 0.0024\n",
            "Epoch 806: Loss 0.0024\n",
            "Epoch 807: Loss 0.0024\n",
            "Epoch 808: Loss 0.0024\n",
            "Epoch 809: Loss 0.0024\n",
            "Epoch 810: Loss 0.0024\n",
            "Epoch 811: Loss 0.0024\n",
            "Epoch 812: Loss 0.0024\n",
            "Epoch 813: Loss 0.0024\n",
            "Epoch 814: Loss 0.0024\n",
            "Epoch 815: Loss 0.0024\n",
            "Epoch 816: Loss 0.0024\n",
            "Epoch 817: Loss 0.0024\n",
            "Epoch 818: Loss 0.0024\n",
            "Epoch 819: Loss 0.0024\n",
            "Epoch 820: Loss 0.0024\n",
            "Epoch 821: Loss 0.0024\n",
            "Epoch 822: Loss 0.0024\n",
            "Epoch 823: Loss 0.0024\n",
            "Epoch 824: Loss 0.0024\n",
            "Epoch 825: Loss 0.0024\n",
            "Epoch 826: Loss 0.0024\n",
            "Epoch 827: Loss 0.0024\n",
            "Epoch 828: Loss 0.0024\n",
            "Epoch 829: Loss 0.0024\n",
            "Epoch 830: Loss 0.0024\n",
            "Epoch 831: Loss 0.0024\n",
            "Epoch 832: Loss 0.0023\n",
            "Epoch 833: Loss 0.0023\n",
            "Epoch 834: Loss 0.0023\n",
            "Epoch 835: Loss 0.0023\n",
            "Epoch 836: Loss 0.0023\n",
            "Epoch 837: Loss 0.0023\n",
            "Epoch 838: Loss 0.0023\n",
            "Epoch 839: Loss 0.0023\n",
            "Epoch 840: Loss 0.0023\n",
            "Epoch 841: Loss 0.0023\n",
            "Epoch 842: Loss 0.0023\n",
            "Epoch 843: Loss 0.0023\n",
            "Epoch 844: Loss 0.0023\n",
            "Epoch 845: Loss 0.0023\n",
            "Epoch 846: Loss 0.0023\n",
            "Epoch 847: Loss 0.0023\n",
            "Epoch 848: Loss 0.0023\n",
            "Epoch 849: Loss 0.0023\n",
            "Epoch 850: Loss 0.0023\n",
            "Epoch 851: Loss 0.0023\n",
            "Epoch 852: Loss 0.0023\n",
            "Epoch 853: Loss 0.0023\n",
            "Epoch 854: Loss 0.0023\n",
            "Epoch 855: Loss 0.0023\n",
            "Epoch 856: Loss 0.0023\n",
            "Epoch 857: Loss 0.0023\n",
            "Epoch 858: Loss 0.0023\n",
            "Epoch 859: Loss 0.0023\n",
            "Epoch 860: Loss 0.0023\n",
            "Epoch 861: Loss 0.0023\n",
            "Epoch 862: Loss 0.0023\n",
            "Epoch 863: Loss 0.0023\n",
            "Epoch 864: Loss 0.0023\n",
            "Epoch 865: Loss 0.0023\n",
            "Epoch 866: Loss 0.0023\n",
            "Epoch 867: Loss 0.0023\n",
            "Epoch 868: Loss 0.0023\n",
            "Epoch 869: Loss 0.0023\n",
            "Epoch 870: Loss 0.0023\n",
            "Epoch 871: Loss 0.0023\n",
            "Epoch 872: Loss 0.0023\n",
            "Epoch 873: Loss 0.0023\n",
            "Epoch 874: Loss 0.0023\n",
            "Epoch 875: Loss 0.0023\n",
            "Epoch 876: Loss 0.0023\n",
            "Epoch 877: Loss 0.0023\n",
            "Epoch 878: Loss 0.0023\n",
            "Epoch 879: Loss 0.0023\n",
            "Epoch 880: Loss 0.0023\n",
            "Epoch 881: Loss 0.0023\n",
            "Epoch 882: Loss 0.0023\n",
            "Epoch 883: Loss 0.0023\n",
            "Epoch 884: Loss 0.0023\n",
            "Epoch 885: Loss 0.0023\n",
            "Epoch 886: Loss 0.0023\n",
            "Epoch 887: Loss 0.0022\n",
            "Epoch 888: Loss 0.0022\n",
            "Epoch 889: Loss 0.0022\n",
            "Epoch 890: Loss 0.0022\n",
            "Epoch 891: Loss 0.0022\n",
            "Epoch 892: Loss 0.0022\n",
            "Epoch 893: Loss 0.0022\n",
            "Epoch 894: Loss 0.0022\n",
            "Epoch 895: Loss 0.0022\n",
            "Epoch 896: Loss 0.0022\n",
            "Epoch 897: Loss 0.0022\n",
            "Epoch 898: Loss 0.0022\n",
            "Epoch 899: Loss 0.0022\n",
            "Epoch 900: Loss 0.0022\n",
            "Epoch 901: Loss 0.0022\n",
            "Epoch 902: Loss 0.0022\n",
            "Epoch 903: Loss 0.0022\n",
            "Epoch 904: Loss 0.0022\n",
            "Epoch 905: Loss 0.0022\n",
            "Epoch 906: Loss 0.0022\n",
            "Epoch 907: Loss 0.0022\n",
            "Epoch 908: Loss 0.0022\n",
            "Epoch 909: Loss 0.0022\n",
            "Epoch 910: Loss 0.0022\n",
            "Epoch 911: Loss 0.0022\n",
            "Epoch 912: Loss 0.0022\n",
            "Epoch 913: Loss 0.0022\n",
            "Epoch 914: Loss 0.0022\n",
            "Epoch 915: Loss 0.0022\n",
            "Epoch 916: Loss 0.0022\n",
            "Epoch 917: Loss 0.0022\n",
            "Epoch 918: Loss 0.0022\n",
            "Epoch 919: Loss 0.0022\n",
            "Epoch 920: Loss 0.0022\n",
            "Epoch 921: Loss 0.0022\n",
            "Epoch 922: Loss 0.0022\n",
            "Epoch 923: Loss 0.0022\n",
            "Epoch 924: Loss 0.0022\n",
            "Epoch 925: Loss 0.0022\n",
            "Epoch 926: Loss 0.0022\n",
            "Epoch 927: Loss 0.0022\n",
            "Epoch 928: Loss 0.0022\n",
            "Epoch 929: Loss 0.0022\n",
            "Epoch 930: Loss 0.0022\n",
            "Epoch 931: Loss 0.0022\n",
            "Epoch 932: Loss 0.0022\n",
            "Epoch 933: Loss 0.0022\n",
            "Epoch 934: Loss 0.0022\n",
            "Epoch 935: Loss 0.0022\n",
            "Epoch 936: Loss 0.0022\n",
            "Epoch 937: Loss 0.0022\n",
            "Epoch 938: Loss 0.0022\n",
            "Epoch 939: Loss 0.0022\n",
            "Epoch 940: Loss 0.0022\n",
            "Epoch 941: Loss 0.0022\n",
            "Epoch 942: Loss 0.0022\n",
            "Epoch 943: Loss 0.0022\n",
            "Epoch 944: Loss 0.0022\n",
            "Epoch 945: Loss 0.0022\n",
            "Epoch 946: Loss 0.0022\n",
            "Epoch 947: Loss 0.0022\n",
            "Epoch 948: Loss 0.0022\n",
            "Epoch 949: Loss 0.0022\n",
            "Epoch 950: Loss 0.0022\n",
            "Epoch 951: Loss 0.0022\n",
            "Epoch 952: Loss 0.0022\n",
            "Epoch 953: Loss 0.0022\n",
            "Epoch 954: Loss 0.0022\n",
            "Epoch 955: Loss 0.0022\n",
            "Epoch 956: Loss 0.0022\n",
            "Epoch 957: Loss 0.0021\n",
            "Epoch 958: Loss 0.0021\n",
            "Epoch 959: Loss 0.0021\n",
            "Epoch 960: Loss 0.0021\n",
            "Epoch 961: Loss 0.0021\n",
            "Epoch 962: Loss 0.0021\n",
            "Epoch 963: Loss 0.0021\n",
            "Epoch 964: Loss 0.0021\n",
            "Epoch 965: Loss 0.0021\n",
            "Epoch 966: Loss 0.0021\n",
            "Epoch 967: Loss 0.0021\n",
            "Epoch 968: Loss 0.0021\n",
            "Epoch 969: Loss 0.0021\n",
            "Epoch 970: Loss 0.0021\n",
            "Epoch 971: Loss 0.0021\n",
            "Epoch 972: Loss 0.0021\n",
            "Epoch 973: Loss 0.0021\n",
            "Epoch 974: Loss 0.0021\n",
            "Epoch 975: Loss 0.0021\n",
            "Epoch 976: Loss 0.0021\n",
            "Epoch 977: Loss 0.0021\n",
            "Epoch 978: Loss 0.0021\n",
            "Epoch 979: Loss 0.0021\n",
            "Epoch 980: Loss 0.0021\n",
            "Epoch 981: Loss 0.0021\n",
            "Epoch 982: Loss 0.0021\n",
            "Epoch 983: Loss 0.0021\n",
            "Epoch 984: Loss 0.0021\n",
            "Epoch 985: Loss 0.0021\n",
            "Epoch 986: Loss 0.0021\n",
            "Epoch 987: Loss 0.0021\n",
            "Epoch 988: Loss 0.0021\n",
            "Epoch 989: Loss 0.0021\n",
            "Epoch 990: Loss 0.0021\n",
            "Epoch 991: Loss 0.0021\n",
            "Epoch 992: Loss 0.0021\n",
            "Epoch 993: Loss 0.0021\n",
            "Epoch 994: Loss 0.0021\n",
            "Epoch 995: Loss 0.0021\n",
            "Epoch 996: Loss 0.0021\n",
            "Epoch 997: Loss 0.0021\n",
            "Epoch 998: Loss 0.0021\n",
            "Epoch 999: Loss 0.0021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "plt.plot(y_pred[:,0], y_pred[:,1],'ko')\n",
        "plt.plot(y_test[:,0], y_test[:,1], '*r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "S4D_fjdOuTaw",
        "outputId": "71fb9b73-b4ab-4de3-ec68-ad13defcfb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model predict Theta(t)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(1,)),\n",
        "    tf.keras.layers.Dense(10,activation='relu'),\n",
        "    tf.keras.layers.Dense(10,activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "TJ93zPxMuiHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-2)"
      ],
      "metadata": {
        "id": "JkGOabdlv_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(y_true, y_pred):\n",
        "    loss = tf.math.square(y_true-y_pred)\n",
        "    return tf.math.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "GbUsskgpwEEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def omega(model,t):\n",
        "    with tf.GradientTape() as tape:\n",
        "        t_tf = tf.constant(t)\n",
        "        tape.watch(t_tf)\n",
        "        theta = model(t_tf)\n",
        "    omega_cal = tape.gradient(theta, t_tf)\n",
        "    del tape\n",
        "    return omega_cal"
      ],
      "metadata": {
        "id": "y2AXrwvHwQcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.linspace(0,2,100)"
      ],
      "metadata": {
        "id": "f9-KmNo5xctA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for num_epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        omega_cal = omega(model, t)\n",
        "        loss = loss_fn(np.pi, omega_cal)\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    print('Epoch %s : Loss %.4f' % (num_epoch, loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6zS6rEywsMa",
        "outputId": "3eeda7b2-047f-49f2-a0b8-004f43dc5537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : Loss 10.4512\n",
            "Epoch 1 : Loss 10.1518\n",
            "Epoch 2 : Loss 9.8594\n",
            "Epoch 3 : Loss 9.5738\n",
            "Epoch 4 : Loss 9.3021\n",
            "Epoch 5 : Loss 9.0369\n",
            "Epoch 6 : Loss 8.7762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 : Loss 8.5198\n",
            "Epoch 8 : Loss 8.2670\n",
            "Epoch 9 : Loss 8.0174\n",
            "Epoch 10 : Loss 7.7702\n",
            "Epoch 11 : Loss 7.5246\n",
            "Epoch 12 : Loss 7.2799\n",
            "Epoch 13 : Loss 7.0351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 : Loss 6.7892\n",
            "Epoch 15 : Loss 6.5410\n",
            "Epoch 16 : Loss 6.2891\n",
            "Epoch 17 : Loss 6.0330\n",
            "Epoch 18 : Loss 5.7726\n",
            "Epoch 19 : Loss 5.5077\n",
            "Epoch 20 : Loss 5.2383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 : Loss 4.9645\n",
            "Epoch 22 : Loss 4.6865\n",
            "Epoch 23 : Loss 4.4049\n",
            "Epoch 24 : Loss 4.1202\n",
            "Epoch 25 : Loss 3.8333\n",
            "Epoch 26 : Loss 3.5453\n",
            "Epoch 27 : Loss 3.2573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 : Loss 2.9710\n",
            "Epoch 29 : Loss 2.6877\n",
            "Epoch 30 : Loss 2.4093\n",
            "Epoch 31 : Loss 2.1376\n",
            "Epoch 32 : Loss 1.8748\n",
            "Epoch 33 : Loss 1.6229\n",
            "Epoch 34 : Loss 1.3841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 : Loss 1.1607\n",
            "Epoch 36 : Loss 0.9610\n",
            "Epoch 37 : Loss 0.7803\n",
            "Epoch 38 : Loss 0.6190\n",
            "Epoch 39 : Loss 0.4786\n",
            "Epoch 40 : Loss 0.3604\n",
            "Epoch 41 : Loss 0.2648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42 : Loss 0.1919\n",
            "Epoch 43 : Loss 0.1411\n",
            "Epoch 44 : Loss 0.1109\n",
            "Epoch 45 : Loss 0.0991\n",
            "Epoch 46 : Loss 0.1028\n",
            "Epoch 47 : Loss 0.1184\n",
            "Epoch 48 : Loss 0.1423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 : Loss 0.1703\n",
            "Epoch 50 : Loss 0.1989\n",
            "Epoch 51 : Loss 0.2248\n",
            "Epoch 52 : Loss 0.2455\n",
            "Epoch 53 : Loss 0.2595\n",
            "Epoch 54 : Loss 0.2659\n",
            "Epoch 55 : Loss 0.2648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56 : Loss 0.2571\n",
            "Epoch 57 : Loss 0.2439\n",
            "Epoch 58 : Loss 0.2268\n",
            "Epoch 59 : Loss 0.2074\n",
            "Epoch 60 : Loss 0.1872\n",
            "Epoch 61 : Loss 0.1676\n",
            "Epoch 62 : Loss 0.1497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63 : Loss 0.1341\n",
            "Epoch 64 : Loss 0.1214\n",
            "Epoch 65 : Loss 0.1117\n",
            "Epoch 66 : Loss 0.1049\n",
            "Epoch 67 : Loss 0.1008\n",
            "Epoch 68 : Loss 0.0989\n",
            "Epoch 69 : Loss 0.0989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70 : Loss 0.1002\n",
            "Epoch 71 : Loss 0.1023\n",
            "Epoch 72 : Loss 0.1049\n",
            "Epoch 73 : Loss 0.1076\n",
            "Epoch 74 : Loss 0.1100\n",
            "Epoch 75 : Loss 0.1119\n",
            "Epoch 76 : Loss 0.1133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77 : Loss 0.1140\n",
            "Epoch 78 : Loss 0.1141\n",
            "Epoch 79 : Loss 0.1136\n",
            "Epoch 80 : Loss 0.1125\n",
            "Epoch 81 : Loss 0.1111\n",
            "Epoch 82 : Loss 0.1094\n",
            "Epoch 83 : Loss 0.1076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84 : Loss 0.1058\n",
            "Epoch 85 : Loss 0.1041\n",
            "Epoch 86 : Loss 0.1025\n",
            "Epoch 87 : Loss 0.1012\n",
            "Epoch 88 : Loss 0.1002\n",
            "Epoch 89 : Loss 0.0994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90 : Loss 0.0990\n",
            "Epoch 91 : Loss 0.0987\n",
            "Epoch 92 : Loss 0.0987\n",
            "Epoch 93 : Loss 0.0988\n",
            "Epoch 94 : Loss 0.0991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95 : Loss 0.0994\n",
            "Epoch 96 : Loss 0.0997\n",
            "Epoch 97 : Loss 0.0999\n",
            "Epoch 98 : Loss 0.1001\n",
            "Epoch 99 : Loss 0.1002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100 : Loss 0.1003\n",
            "Epoch 101 : Loss 0.1002\n",
            "Epoch 102 : Loss 0.1001\n",
            "Epoch 103 : Loss 0.1000\n",
            "Epoch 104 : Loss 0.0998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 105 : Loss 0.0996\n",
            "Epoch 106 : Loss 0.0994\n",
            "Epoch 107 : Loss 0.0992\n",
            "Epoch 108 : Loss 0.0990\n",
            "Epoch 109 : Loss 0.0989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 110 : Loss 0.0988\n",
            "Epoch 111 : Loss 0.0987\n",
            "Epoch 112 : Loss 0.0987\n",
            "Epoch 113 : Loss 0.0987\n",
            "Epoch 114 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 115 : Loss 0.0987\n",
            "Epoch 116 : Loss 0.0988\n",
            "Epoch 117 : Loss 0.0988\n",
            "Epoch 118 : Loss 0.0988\n",
            "Epoch 119 : Loss 0.0989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 120 : Loss 0.0989\n",
            "Epoch 121 : Loss 0.0989\n",
            "Epoch 122 : Loss 0.0989\n",
            "Epoch 123 : Loss 0.0989\n",
            "Epoch 124 : Loss 0.0988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 125 : Loss 0.0988\n",
            "Epoch 126 : Loss 0.0988\n",
            "Epoch 127 : Loss 0.0988\n",
            "Epoch 128 : Loss 0.0987\n",
            "Epoch 129 : Loss 0.0987\n",
            "Epoch 130 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 131 : Loss 0.0987\n",
            "Epoch 132 : Loss 0.0987\n",
            "Epoch 133 : Loss 0.0987\n",
            "Epoch 134 : Loss 0.0987\n",
            "Epoch 135 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 136 : Loss 0.0987\n",
            "Epoch 137 : Loss 0.0987\n",
            "Epoch 138 : Loss 0.0987\n",
            "Epoch 139 : Loss 0.0987\n",
            "Epoch 140 : Loss 0.0987\n",
            "Epoch 141 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 142 : Loss 0.0987\n",
            "Epoch 143 : Loss 0.0987\n",
            "Epoch 144 : Loss 0.0987\n",
            "Epoch 145 : Loss 0.0987\n",
            "Epoch 146 : Loss 0.0987\n",
            "Epoch 147 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 148 : Loss 0.0987\n",
            "Epoch 149 : Loss 0.0987\n",
            "Epoch 150 : Loss 0.0987\n",
            "Epoch 151 : Loss 0.0987\n",
            "Epoch 152 : Loss 0.0987\n",
            "Epoch 153 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 154 : Loss 0.0987\n",
            "Epoch 155 : Loss 0.0987\n",
            "Epoch 156 : Loss 0.0987\n",
            "Epoch 157 : Loss 0.0987\n",
            "Epoch 158 : Loss 0.0987\n",
            "Epoch 159 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 160 : Loss 0.0987\n",
            "Epoch 161 : Loss 0.0987\n",
            "Epoch 162 : Loss 0.0987\n",
            "Epoch 163 : Loss 0.0987\n",
            "Epoch 164 : Loss 0.0987\n",
            "Epoch 165 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 166 : Loss 0.0987\n",
            "Epoch 167 : Loss 0.0987\n",
            "Epoch 168 : Loss 0.0987\n",
            "Epoch 169 : Loss 0.0987\n",
            "Epoch 170 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 171 : Loss 0.0987\n",
            "Epoch 172 : Loss 0.0987\n",
            "Epoch 173 : Loss 0.0987\n",
            "Epoch 174 : Loss 0.0987\n",
            "Epoch 175 : Loss 0.0987\n",
            "Epoch 176 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 177 : Loss 0.0987\n",
            "Epoch 178 : Loss 0.0987\n",
            "Epoch 179 : Loss 0.0987\n",
            "Epoch 180 : Loss 0.0987\n",
            "Epoch 181 : Loss 0.0987\n",
            "Epoch 182 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 183 : Loss 0.0987\n",
            "Epoch 184 : Loss 0.0987\n",
            "Epoch 185 : Loss 0.0987\n",
            "Epoch 186 : Loss 0.0987\n",
            "Epoch 187 : Loss 0.0987\n",
            "Epoch 188 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 189 : Loss 0.0987\n",
            "Epoch 190 : Loss 0.0987\n",
            "Epoch 191 : Loss 0.0987\n",
            "Epoch 192 : Loss 0.0987\n",
            "Epoch 193 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 194 : Loss 0.0987\n",
            "Epoch 195 : Loss 0.0987\n",
            "Epoch 196 : Loss 0.0987\n",
            "Epoch 197 : Loss 0.0987\n",
            "Epoch 198 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 199 : Loss 0.0987\n",
            "Epoch 200 : Loss 0.0987\n",
            "Epoch 201 : Loss 0.0987\n",
            "Epoch 202 : Loss 0.0987\n",
            "Epoch 203 : Loss 0.0987\n",
            "Epoch 204 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 205 : Loss 0.0987\n",
            "Epoch 206 : Loss 0.0987\n",
            "Epoch 207 : Loss 0.0987\n",
            "Epoch 208 : Loss 0.0987\n",
            "Epoch 209 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 210 : Loss 0.0987\n",
            "Epoch 211 : Loss 0.0987\n",
            "Epoch 212 : Loss 0.0987\n",
            "Epoch 213 : Loss 0.0987\n",
            "Epoch 214 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 215 : Loss 0.0987\n",
            "Epoch 216 : Loss 0.0987\n",
            "Epoch 217 : Loss 0.0987\n",
            "Epoch 218 : Loss 0.0987\n",
            "Epoch 219 : Loss 0.0987\n",
            "Epoch 220 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 221 : Loss 0.0987\n",
            "Epoch 222 : Loss 0.0987\n",
            "Epoch 223 : Loss 0.0987\n",
            "Epoch 224 : Loss 0.0987\n",
            "Epoch 225 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 226 : Loss 0.0987\n",
            "Epoch 227 : Loss 0.0987\n",
            "Epoch 228 : Loss 0.0987\n",
            "Epoch 229 : Loss 0.0987\n",
            "Epoch 230 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 231 : Loss 0.0987\n",
            "Epoch 232 : Loss 0.0987\n",
            "Epoch 233 : Loss 0.0987\n",
            "Epoch 234 : Loss 0.0987\n",
            "Epoch 235 : Loss 0.0987\n",
            "Epoch 236 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 237 : Loss 0.0987\n",
            "Epoch 238 : Loss 0.0987\n",
            "Epoch 239 : Loss 0.0987\n",
            "Epoch 240 : Loss 0.0987\n",
            "Epoch 241 : Loss 0.0987\n",
            "Epoch 242 : Loss 0.0987\n",
            "Epoch 243 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 244 : Loss 0.0987\n",
            "Epoch 245 : Loss 0.0987\n",
            "Epoch 246 : Loss 0.0987\n",
            "Epoch 247 : Loss 0.0987\n",
            "Epoch 248 : Loss 0.0987\n",
            "Epoch 249 : Loss 0.0987\n",
            "Epoch 250 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 251 : Loss 0.0987\n",
            "Epoch 252 : Loss 0.0987\n",
            "Epoch 253 : Loss 0.0987\n",
            "Epoch 254 : Loss 0.0987\n",
            "Epoch 255 : Loss 0.0987\n",
            "Epoch 256 : Loss 0.0987\n",
            "Epoch 257 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 258 : Loss 0.0987\n",
            "Epoch 259 : Loss 0.0987\n",
            "Epoch 260 : Loss 0.0987\n",
            "Epoch 261 : Loss 0.0987\n",
            "Epoch 262 : Loss 0.0987\n",
            "Epoch 263 : Loss 0.0987\n",
            "Epoch 264 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 265 : Loss 0.0987\n",
            "Epoch 266 : Loss 0.0987\n",
            "Epoch 267 : Loss 0.0987\n",
            "Epoch 268 : Loss 0.0987\n",
            "Epoch 269 : Loss 0.0987\n",
            "Epoch 270 : Loss 0.0987\n",
            "Epoch 271 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 272 : Loss 0.0987\n",
            "Epoch 273 : Loss 0.0987\n",
            "Epoch 274 : Loss 0.0987\n",
            "Epoch 275 : Loss 0.0987\n",
            "Epoch 276 : Loss 0.0987\n",
            "Epoch 277 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 278 : Loss 0.0987\n",
            "Epoch 279 : Loss 0.0987\n",
            "Epoch 280 : Loss 0.0987\n",
            "Epoch 281 : Loss 0.0987\n",
            "Epoch 282 : Loss 0.0987\n",
            "Epoch 283 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 284 : Loss 0.0987\n",
            "Epoch 285 : Loss 0.0987\n",
            "Epoch 286 : Loss 0.0987\n",
            "Epoch 287 : Loss 0.0987\n",
            "Epoch 288 : Loss 0.0987\n",
            "Epoch 289 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 290 : Loss 0.0987\n",
            "Epoch 291 : Loss 0.0987\n",
            "Epoch 292 : Loss 0.0987\n",
            "Epoch 293 : Loss 0.0987\n",
            "Epoch 294 : Loss 0.0987\n",
            "Epoch 295 : Loss 0.0987\n",
            "Epoch 296 : Loss 0.0987"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 297 : Loss 0.0987\n",
            "Epoch 298 : Loss 0.0987\n",
            "Epoch 299 : Loss 0.0987\n",
            "Epoch 300 : Loss 0.0987\n",
            "Epoch 301 : Loss 0.0987\n",
            "Epoch 302 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 303 : Loss 0.0987\n",
            "Epoch 304 : Loss 0.0987\n",
            "Epoch 305 : Loss 0.0987\n",
            "Epoch 306 : Loss 0.0987\n",
            "Epoch 307 : Loss 0.0987\n",
            "Epoch 308 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 309 : Loss 0.0987\n",
            "Epoch 310 : Loss 0.0987\n",
            "Epoch 311 : Loss 0.0987\n",
            "Epoch 312 : Loss 0.0987\n",
            "Epoch 313 : Loss 0.0987\n",
            "Epoch 314 : Loss 0.0987\n",
            "Epoch 315 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 316 : Loss 0.0987\n",
            "Epoch 317 : Loss 0.0987\n",
            "Epoch 318 : Loss 0.0987\n",
            "Epoch 319 : Loss 0.0987\n",
            "Epoch 320 : Loss 0.0987\n",
            "Epoch 321 : Loss 0.0987\n",
            "Epoch 322 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 323 : Loss 0.0987\n",
            "Epoch 324 : Loss 0.0987\n",
            "Epoch 325 : Loss 0.0987\n",
            "Epoch 326 : Loss 0.0987\n",
            "Epoch 327 : Loss 0.0987\n",
            "Epoch 328 : Loss 0.0987\n",
            "Epoch 329 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 330 : Loss 0.0987\n",
            "Epoch 331 : Loss 0.0987\n",
            "Epoch 332 : Loss 0.0987\n",
            "Epoch 333 : Loss 0.0987\n",
            "Epoch 334 : Loss 0.0987\n",
            "Epoch 335 : Loss 0.0987\n",
            "Epoch 336 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 337 : Loss 0.0987\n",
            "Epoch 338 : Loss 0.0987\n",
            "Epoch 339 : Loss 0.0987\n",
            "Epoch 340 : Loss 0.0987\n",
            "Epoch 341 : Loss 0.0987\n",
            "Epoch 342 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 343 : Loss 0.0987\n",
            "Epoch 344 : Loss 0.0987\n",
            "Epoch 345 : Loss 0.0987\n",
            "Epoch 346 : Loss 0.0987\n",
            "Epoch 347 : Loss 0.0987\n",
            "Epoch 348 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 349 : Loss 0.0987\n",
            "Epoch 350 : Loss 0.0987\n",
            "Epoch 351 : Loss 0.0987\n",
            "Epoch 352 : Loss 0.0987\n",
            "Epoch 353 : Loss 0.0987\n",
            "Epoch 354 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 355 : Loss 0.0987\n",
            "Epoch 356 : Loss 0.0987\n",
            "Epoch 357 : Loss 0.0987\n",
            "Epoch 358 : Loss 0.0987\n",
            "Epoch 359 : Loss 0.0987\n",
            "Epoch 360 : Loss 0.0987\n",
            "Epoch 361 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 362 : Loss 0.0987\n",
            "Epoch 363 : Loss 0.0987\n",
            "Epoch 364 : Loss 0.0987\n",
            "Epoch 365 : Loss 0.0987\n",
            "Epoch 366 : Loss 0.0987\n",
            "Epoch 367 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 368 : Loss 0.0987\n",
            "Epoch 369 : Loss 0.0987\n",
            "Epoch 370 : Loss 0.0987\n",
            "Epoch 371 : Loss 0.0987\n",
            "Epoch 372 : Loss 0.0987\n",
            "Epoch 373 : Loss 0.0987\n",
            "Epoch 374 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 375 : Loss 0.0987\n",
            "Epoch 376 : Loss 0.0987\n",
            "Epoch 377 : Loss 0.0987\n",
            "Epoch 378 : Loss 0.0987\n",
            "Epoch 379 : Loss 0.0987\n",
            "Epoch 380 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 381 : Loss 0.0987\n",
            "Epoch 382 : Loss 0.0987\n",
            "Epoch 383 : Loss 0.0987\n",
            "Epoch 384 : Loss 0.0987\n",
            "Epoch 385 : Loss 0.0987\n",
            "Epoch 386 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 387 : Loss 0.0987\n",
            "Epoch 388 : Loss 0.0987\n",
            "Epoch 389 : Loss 0.0987\n",
            "Epoch 390 : Loss 0.0987\n",
            "Epoch 391 : Loss 0.0987\n",
            "Epoch 392 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 393 : Loss 0.0987\n",
            "Epoch 394 : Loss 0.0987\n",
            "Epoch 395 : Loss 0.0987\n",
            "Epoch 396 : Loss 0.0987\n",
            "Epoch 397 : Loss 0.0987\n",
            "Epoch 398 : Loss 0.0987\n",
            "Epoch 399 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 400 : Loss 0.0987\n",
            "Epoch 401 : Loss 0.0987\n",
            "Epoch 402 : Loss 0.0987\n",
            "Epoch 403 : Loss 0.0987\n",
            "Epoch 404 : Loss 0.0987\n",
            "Epoch 405 : Loss 0.0987\n",
            "Epoch 406 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 407 : Loss 0.0987\n",
            "Epoch 408 : Loss 0.0987\n",
            "Epoch 409 : Loss 0.0987\n",
            "Epoch 410 : Loss 0.0987\n",
            "Epoch 411 : Loss 0.0987\n",
            "Epoch 412 : Loss 0.0987\n",
            "Epoch 413 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 414 : Loss 0.0987\n",
            "Epoch 415 : Loss 0.0987\n",
            "Epoch 416 : Loss 0.0987\n",
            "Epoch 417 : Loss 0.0987\n",
            "Epoch 418 : Loss 0.0987\n",
            "Epoch 419 : Loss 0.0987\n",
            "Epoch 420 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 421 : Loss 0.0987\n",
            "Epoch 422 : Loss 0.0987\n",
            "Epoch 423 : Loss 0.0987\n",
            "Epoch 424 : Loss 0.0987\n",
            "Epoch 425 : Loss 0.0987\n",
            "Epoch 426 : Loss 0.0987\n",
            "Epoch 427 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 428 : Loss 0.0987\n",
            "Epoch 429 : Loss 0.0987\n",
            "Epoch 430 : Loss 0.0987\n",
            "Epoch 431 : Loss 0.0987\n",
            "Epoch 432 : Loss 0.0987\n",
            "Epoch 433 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 434 : Loss 0.0987\n",
            "Epoch 435 : Loss 0.0987\n",
            "Epoch 436 : Loss 0.0987\n",
            "Epoch 437 : Loss 0.0987\n",
            "Epoch 438 : Loss 0.0987\n",
            "Epoch 439 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 440 : Loss 0.0987\n",
            "Epoch 441 : Loss 0.0987\n",
            "Epoch 442 : Loss 0.0987\n",
            "Epoch 443 : Loss 0.0987\n",
            "Epoch 444 : Loss 0.0987\n",
            "Epoch 445 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 446 : Loss 0.0987\n",
            "Epoch 447 : Loss 0.0987\n",
            "Epoch 448 : Loss 0.0987\n",
            "Epoch 449 : Loss 0.0987\n",
            "Epoch 450 : Loss 0.0987\n",
            "Epoch 451 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 452 : Loss 0.0987\n",
            "Epoch 453 : Loss 0.0987\n",
            "Epoch 454 : Loss 0.0987\n",
            "Epoch 455 : Loss 0.0987\n",
            "Epoch 456 : Loss 0.0987\n",
            "Epoch 457 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 458 : Loss 0.0987\n",
            "Epoch 459 : Loss 0.0987\n",
            "Epoch 460 : Loss 0.0987\n",
            "Epoch 461 : Loss 0.0987\n",
            "Epoch 462 : Loss 0.0987\n",
            "Epoch 463 : Loss 0.0987\n",
            "Epoch 464 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 465 : Loss 0.0987\n",
            "Epoch 466 : Loss 0.0987\n",
            "Epoch 467 : Loss 0.0987\n",
            "Epoch 468 : Loss 0.0987\n",
            "Epoch 469 : Loss 0.0987\n",
            "Epoch 470 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 471 : Loss 0.0987\n",
            "Epoch 472 : Loss 0.0987\n",
            "Epoch 473 : Loss 0.0987\n",
            "Epoch 474 : Loss 0.0987\n",
            "Epoch 475 : Loss 0.0987\n",
            "Epoch 476 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 477 : Loss 0.0987\n",
            "Epoch 478 : Loss 0.0987\n",
            "Epoch 479 : Loss 0.0987\n",
            "Epoch 480 : Loss 0.0987\n",
            "Epoch 481 : Loss 0.0987\n",
            "Epoch 482 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 483 : Loss 0.0987\n",
            "Epoch 484 : Loss 0.0987\n",
            "Epoch 485 : Loss 0.0987\n",
            "Epoch 486 : Loss 0.0987\n",
            "Epoch 487 : Loss 0.0987\n",
            "Epoch 488 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 489 : Loss 0.0987\n",
            "Epoch 490 : Loss 0.0987\n",
            "Epoch 491 : Loss 0.0987\n",
            "Epoch 492 : Loss 0.0987\n",
            "Epoch 493 : Loss 0.0987\n",
            "Epoch 494 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 495 : Loss 0.0987\n",
            "Epoch 496 : Loss 0.0987\n",
            "Epoch 497 : Loss 0.0987\n",
            "Epoch 498 : Loss 0.0987\n",
            "Epoch 499 : Loss 0.0987\n",
            "Epoch 500 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 501 : Loss 0.0987\n",
            "Epoch 502 : Loss 0.0987\n",
            "Epoch 503 : Loss 0.0987\n",
            "Epoch 504 : Loss 0.0987\n",
            "Epoch 505 : Loss 0.0987\n",
            "Epoch 506 : Loss 0.0987\n",
            "Epoch 507 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 508 : Loss 0.0987\n",
            "Epoch 509 : Loss 0.0987\n",
            "Epoch 510 : Loss 0.0987\n",
            "Epoch 511 : Loss 0.0987\n",
            "Epoch 512 : Loss 0.0987\n",
            "Epoch 513 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 514 : Loss 0.0987\n",
            "Epoch 515 : Loss 0.0987\n",
            "Epoch 516 : Loss 0.0987\n",
            "Epoch 517 : Loss 0.0987\n",
            "Epoch 518 : Loss 0.0987\n",
            "Epoch 519 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 520 : Loss 0.0987\n",
            "Epoch 521 : Loss 0.0987\n",
            "Epoch 522 : Loss 0.0987\n",
            "Epoch 523 : Loss 0.0987\n",
            "Epoch 524 : Loss 0.0987\n",
            "Epoch 525 : Loss 0.0987\n",
            "Epoch 526 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 527 : Loss 0.0987\n",
            "Epoch 528 : Loss 0.0987\n",
            "Epoch 529 : Loss 0.0987\n",
            "Epoch 530 : Loss 0.0987\n",
            "Epoch 531 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 532 : Loss 0.0987\n",
            "Epoch 533 : Loss 0.0987\n",
            "Epoch 534 : Loss 0.0987\n",
            "Epoch 535 : Loss 0.0987\n",
            "Epoch 536 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 537 : Loss 0.0987\n",
            "Epoch 538 : Loss 0.0987\n",
            "Epoch 539 : Loss 0.0987\n",
            "Epoch 540 : Loss 0.0987\n",
            "Epoch 541 : Loss 0.0987\n",
            "Epoch 542 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 543 : Loss 0.0987\n",
            "Epoch 544 : Loss 0.0987\n",
            "Epoch 545 : Loss 0.0987\n",
            "Epoch 546 : Loss 0.0987\n",
            "Epoch 547 : Loss 0.0987\n",
            "Epoch 548 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 549 : Loss 0.0987\n",
            "Epoch 550 : Loss 0.0987\n",
            "Epoch 551 : Loss 0.0987\n",
            "Epoch 552 : Loss 0.0987\n",
            "Epoch 553 : Loss 0.0987\n",
            "Epoch 554 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 555 : Loss 0.0987\n",
            "Epoch 556 : Loss 0.0987\n",
            "Epoch 557 : Loss 0.0987\n",
            "Epoch 558 : Loss 0.0987\n",
            "Epoch 559 : Loss 0.0987\n",
            "Epoch 560 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 561 : Loss 0.0987\n",
            "Epoch 562 : Loss 0.0987\n",
            "Epoch 563 : Loss 0.0987\n",
            "Epoch 564 : Loss 0.0987\n",
            "Epoch 565 : Loss 0.0987\n",
            "Epoch 566 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 567 : Loss 0.0987\n",
            "Epoch 568 : Loss 0.0987\n",
            "Epoch 569 : Loss 0.0987\n",
            "Epoch 570 : Loss 0.0987\n",
            "Epoch 571 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 572 : Loss 0.0987\n",
            "Epoch 573 : Loss 0.0987\n",
            "Epoch 574 : Loss 0.0987\n",
            "Epoch 575 : Loss 0.0987\n",
            "Epoch 576 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 577 : Loss 0.0987\n",
            "Epoch 578 : Loss 0.0987\n",
            "Epoch 579 : Loss 0.0987\n",
            "Epoch 580 : Loss 0.0987\n",
            "Epoch 581 : Loss 0.0987\n",
            "Epoch 582 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 583 : Loss 0.0987\n",
            "Epoch 584 : Loss 0.0987\n",
            "Epoch 585 : Loss 0.0987\n",
            "Epoch 586 : Loss 0.0987\n",
            "Epoch 587 : Loss 0.0987\n",
            "Epoch 588 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 589 : Loss 0.0987\n",
            "Epoch 590 : Loss 0.0987\n",
            "Epoch 591 : Loss 0.0987\n",
            "Epoch 592 : Loss 0.0987\n",
            "Epoch 593 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 594 : Loss 0.0987\n",
            "Epoch 595 : Loss 0.0987\n",
            "Epoch 596 : Loss 0.0987\n",
            "Epoch 597 : Loss 0.0987\n",
            "Epoch 598 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 599 : Loss 0.0987\n",
            "Epoch 600 : Loss 0.0987\n",
            "Epoch 601 : Loss 0.0987\n",
            "Epoch 602 : Loss 0.0987\n",
            "Epoch 603 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 604 : Loss 0.0987\n",
            "Epoch 605 : Loss 0.0987\n",
            "Epoch 606 : Loss 0.0987\n",
            "Epoch 607 : Loss 0.0987\n",
            "Epoch 608 : Loss 0.0987\n",
            "Epoch 609 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 610 : Loss 0.0987\n",
            "Epoch 611 : Loss 0.0987\n",
            "Epoch 612 : Loss 0.0987\n",
            "Epoch 613 : Loss 0.0987\n",
            "Epoch 614 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 615 : Loss 0.0987\n",
            "Epoch 616 : Loss 0.0987\n",
            "Epoch 617 : Loss 0.0987\n",
            "Epoch 618 : Loss 0.0987\n",
            "Epoch 619 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 620 : Loss 0.0987\n",
            "Epoch 621 : Loss 0.0987\n",
            "Epoch 622 : Loss 0.0987\n",
            "Epoch 623 : Loss 0.0987\n",
            "Epoch 624 : Loss 0.0987\n",
            "Epoch 625 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 626 : Loss 0.0987\n",
            "Epoch 627 : Loss 0.0987\n",
            "Epoch 628 : Loss 0.0987\n",
            "Epoch 629 : Loss 0.0987\n",
            "Epoch 630 : Loss 0.0987\n",
            "Epoch 631 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 632 : Loss 0.0987\n",
            "Epoch 633 : Loss 0.0987\n",
            "Epoch 634 : Loss 0.0987\n",
            "Epoch 635 : Loss 0.0987\n",
            "Epoch 636 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 637 : Loss 0.0987\n",
            "Epoch 638 : Loss 0.0987\n",
            "Epoch 639 : Loss 0.0987\n",
            "Epoch 640 : Loss 0.0987\n",
            "Epoch 641 : Loss 0.0987\n",
            "Epoch 642 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 643 : Loss 0.0987\n",
            "Epoch 644 : Loss 0.0987\n",
            "Epoch 645 : Loss 0.0987\n",
            "Epoch 646 : Loss 0.0987\n",
            "Epoch 647 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 648 : Loss 0.0987\n",
            "Epoch 649 : Loss 0.0987\n",
            "Epoch 650 : Loss 0.0987\n",
            "Epoch 651 : Loss 0.0987\n",
            "Epoch 652 : Loss 0.0987\n",
            "Epoch 653 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 654 : Loss 0.0987\n",
            "Epoch 655 : Loss 0.0987\n",
            "Epoch 656 : Loss 0.0987\n",
            "Epoch 657 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 658 : Loss 0.0987\n",
            "Epoch 659 : Loss 0.0987\n",
            "Epoch 660 : Loss 0.0987\n",
            "Epoch 661 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 662 : Loss 0.0987\n",
            "Epoch 663 : Loss 0.0987\n",
            "Epoch 664 : Loss 0.0987\n",
            "Epoch 665 : Loss 0.0987\n",
            "Epoch 666 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 667 : Loss 0.0987\n",
            "Epoch 668 : Loss 0.0987\n",
            "Epoch 669 : Loss 0.0987\n",
            "Epoch 670 : Loss 0.0987\n",
            "Epoch 671 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 672 : Loss 0.0987\n",
            "Epoch 673 : Loss 0.0987\n",
            "Epoch 674 : Loss 0.0987\n",
            "Epoch 675 : Loss 0.0987\n",
            "Epoch 676 : Loss 0.0987\n",
            "Epoch 677 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 678 : Loss 0.0987\n",
            "Epoch 679 : Loss 0.0987\n",
            "Epoch 680 : Loss 0.0987\n",
            "Epoch 681 : Loss 0.0987\n",
            "Epoch 682 : Loss 0.0987\n",
            "Epoch 683 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 684 : Loss 0.0987\n",
            "Epoch 685 : Loss 0.0987\n",
            "Epoch 686 : Loss 0.0987\n",
            "Epoch 687 : Loss 0.0987\n",
            "Epoch 688 : Loss 0.0987\n",
            "Epoch 689 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 690 : Loss 0.0987\n",
            "Epoch 691 : Loss 0.0987\n",
            "Epoch 692 : Loss 0.0987\n",
            "Epoch 693 : Loss 0.0987\n",
            "Epoch 694 : Loss 0.0987\n",
            "Epoch 695 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 696 : Loss 0.0987\n",
            "Epoch 697 : Loss 0.0987\n",
            "Epoch 698 : Loss 0.0987\n",
            "Epoch 699 : Loss 0.0987\n",
            "Epoch 700 : Loss 0.0987\n",
            "Epoch 701 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 702 : Loss 0.0987\n",
            "Epoch 703 : Loss 0.0987\n",
            "Epoch 704 : Loss 0.0987\n",
            "Epoch 705 : Loss 0.0987\n",
            "Epoch 706 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 707 : Loss 0.0987\n",
            "Epoch 708 : Loss 0.0987\n",
            "Epoch 709 : Loss 0.0987\n",
            "Epoch 710 : Loss 0.0987\n",
            "Epoch 711 : Loss 0.0987\n",
            "Epoch 712 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 713 : Loss 0.0987\n",
            "Epoch 714 : Loss 0.0987\n",
            "Epoch 715 : Loss 0.0987\n",
            "Epoch 716 : Loss 0.0987\n",
            "Epoch 717 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 718 : Loss 0.0987\n",
            "Epoch 719 : Loss 0.0987\n",
            "Epoch 720 : Loss 0.0987\n",
            "Epoch 721 : Loss 0.0987\n",
            "Epoch 722 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 723 : Loss 0.0987\n",
            "Epoch 724 : Loss 0.0987\n",
            "Epoch 725 : Loss 0.0987\n",
            "Epoch 726 : Loss 0.0987\n",
            "Epoch 727 : Loss 0.0987\n",
            "Epoch 728 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 729 : Loss 0.0987\n",
            "Epoch 730 : Loss 0.0987\n",
            "Epoch 731 : Loss 0.0987\n",
            "Epoch 732 : Loss 0.0987\n",
            "Epoch 733 : Loss 0.0987\n",
            "Epoch 734 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 735 : Loss 0.0987\n",
            "Epoch 736 : Loss 0.0987\n",
            "Epoch 737 : Loss 0.0987\n",
            "Epoch 738 : Loss 0.0987\n",
            "Epoch 739 : Loss 0.0987\n",
            "Epoch 740 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 741 : Loss 0.0987\n",
            "Epoch 742 : Loss 0.0987\n",
            "Epoch 743 : Loss 0.0987\n",
            "Epoch 744 : Loss 0.0987\n",
            "Epoch 745 : Loss 0.0987\n",
            "Epoch 746 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 747 : Loss 0.0987\n",
            "Epoch 748 : Loss 0.0987\n",
            "Epoch 749 : Loss 0.0987\n",
            "Epoch 750 : Loss 0.0987\n",
            "Epoch 751 : Loss 0.0987\n",
            "Epoch 752 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 753 : Loss 0.0987\n",
            "Epoch 754 : Loss 0.0987\n",
            "Epoch 755 : Loss 0.0987\n",
            "Epoch 756 : Loss 0.0987\n",
            "Epoch 757 : Loss 0.0987\n",
            "Epoch 758 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 759 : Loss 0.0987\n",
            "Epoch 760 : Loss 0.0987\n",
            "Epoch 761 : Loss 0.0987\n",
            "Epoch 762 : Loss 0.0987\n",
            "Epoch 763 : Loss 0.0987\n",
            "Epoch 764 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 765 : Loss 0.0987\n",
            "Epoch 766 : Loss 0.0987\n",
            "Epoch 767 : Loss 0.0987\n",
            "Epoch 768 : Loss 0.0987\n",
            "Epoch 769 : Loss 0.0987\n",
            "Epoch 770 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 771 : Loss 0.0987\n",
            "Epoch 772 : Loss 0.0987\n",
            "Epoch 773 : Loss 0.0987\n",
            "Epoch 774 : Loss 0.0987\n",
            "Epoch 775 : Loss 0.0987\n",
            "Epoch 776 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 777 : Loss 0.0987\n",
            "Epoch 778 : Loss 0.0987\n",
            "Epoch 779 : Loss 0.0987\n",
            "Epoch 780 : Loss 0.0987\n",
            "Epoch 781 : Loss 0.0987\n",
            "Epoch 782 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 783 : Loss 0.0987\n",
            "Epoch 784 : Loss 0.0987\n",
            "Epoch 785 : Loss 0.0987\n",
            "Epoch 786 : Loss 0.0987\n",
            "Epoch 787 : Loss 0.0987\n",
            "Epoch 788 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 789 : Loss 0.0987\n",
            "Epoch 790 : Loss 0.0987\n",
            "Epoch 791 : Loss 0.0987\n",
            "Epoch 792 : Loss 0.0987\n",
            "Epoch 793 : Loss 0.0987\n",
            "Epoch 794 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 795 : Loss 0.0987\n",
            "Epoch 796 : Loss 0.0987\n",
            "Epoch 797 : Loss 0.0987\n",
            "Epoch 798 : Loss 0.0987\n",
            "Epoch 799 : Loss 0.0987\n",
            "Epoch 800 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 801 : Loss 0.0987\n",
            "Epoch 802 : Loss 0.0987\n",
            "Epoch 803 : Loss 0.0987\n",
            "Epoch 804 : Loss 0.0987\n",
            "Epoch 805 : Loss 0.0987\n",
            "Epoch 806 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 807 : Loss 0.0987\n",
            "Epoch 808 : Loss 0.0987\n",
            "Epoch 809 : Loss 0.0987\n",
            "Epoch 810 : Loss 0.0987\n",
            "Epoch 811 : Loss 0.0987\n",
            "Epoch 812 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 813 : Loss 0.0987\n",
            "Epoch 814 : Loss 0.0987\n",
            "Epoch 815 : Loss 0.0987\n",
            "Epoch 816 : Loss 0.0987\n",
            "Epoch 817 : Loss 0.0987\n",
            "Epoch 818 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 819 : Loss 0.0987\n",
            "Epoch 820 : Loss 0.0987\n",
            "Epoch 821 : Loss 0.0987\n",
            "Epoch 822 : Loss 0.0987\n",
            "Epoch 823 : Loss 0.0987\n",
            "Epoch 824 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 825 : Loss 0.0987\n",
            "Epoch 826 : Loss 0.0987\n",
            "Epoch 827 : Loss 0.0987\n",
            "Epoch 828 : Loss 0.0987\n",
            "Epoch 829 : Loss 0.0987\n",
            "Epoch 830 : Loss 0.0987\n",
            "Epoch 831 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 832 : Loss 0.0987\n",
            "Epoch 833 : Loss 0.0987\n",
            "Epoch 834 : Loss 0.0987\n",
            "Epoch 835 : Loss 0.0987\n",
            "Epoch 836 : Loss 0.0987\n",
            "Epoch 837 : Loss 0.0987\n",
            "Epoch 838 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 839 : Loss 0.0987\n",
            "Epoch 840 : Loss 0.0987\n",
            "Epoch 841 : Loss 0.0987\n",
            "Epoch 842 : Loss 0.0987\n",
            "Epoch 843 : Loss 0.0987\n",
            "Epoch 844 : Loss 0.0987\n",
            "Epoch 845 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 846 : Loss 0.0987\n",
            "Epoch 847 : Loss 0.0987\n",
            "Epoch 848 : Loss 0.0987\n",
            "Epoch 849 : Loss 0.0987\n",
            "Epoch 850 : Loss 0.0987\n",
            "Epoch 851 : Loss 0.0987\n",
            "Epoch 852 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 853 : Loss 0.0987\n",
            "Epoch 854 : Loss 0.0987\n",
            "Epoch 855 : Loss 0.0987\n",
            "Epoch 856 : Loss 0.0987\n",
            "Epoch 857 : Loss 0.0987\n",
            "Epoch 858 : Loss 0.0987\n",
            "Epoch 859 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 860 : Loss 0.0987\n",
            "Epoch 861 : Loss 0.0987\n",
            "Epoch 862 : Loss 0.0987\n",
            "Epoch 863 : Loss 0.0987\n",
            "Epoch 864 : Loss 0.0987\n",
            "Epoch 865 : Loss 0.0987\n",
            "Epoch 866 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 867 : Loss 0.0987\n",
            "Epoch 868 : Loss 0.0987\n",
            "Epoch 869 : Loss 0.0987\n",
            "Epoch 870 : Loss 0.0987\n",
            "Epoch 871 : Loss 0.0987\n",
            "Epoch 872 : Loss 0.0987\n",
            "Epoch 873 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 874 : Loss 0.0987\n",
            "Epoch 875 : Loss 0.0987\n",
            "Epoch 876 : Loss 0.0987\n",
            "Epoch 877 : Loss 0.0987\n",
            "Epoch 878 : Loss 0.0987\n",
            "Epoch 879 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 880 : Loss 0.0987\n",
            "Epoch 881 : Loss 0.0987\n",
            "Epoch 882 : Loss 0.0987\n",
            "Epoch 883 : Loss 0.0987\n",
            "Epoch 884 : Loss 0.0987\n",
            "Epoch 885 : Loss 0.0987\n",
            "Epoch 886 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 887 : Loss 0.0987\n",
            "Epoch 888 : Loss 0.0987\n",
            "Epoch 889 : Loss 0.0987\n",
            "Epoch 890 : Loss 0.0987\n",
            "Epoch 891 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 892 : Loss 0.0987\n",
            "Epoch 893 : Loss 0.0987\n",
            "Epoch 894 : Loss 0.0987\n",
            "Epoch 895 : Loss 0.0987\n",
            "Epoch 896 : Loss 0.0987\n",
            "Epoch 897 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 898 : Loss 0.0987\n",
            "Epoch 899 : Loss 0.0987\n",
            "Epoch 900 : Loss 0.0987\n",
            "Epoch 901 : Loss 0.0987\n",
            "Epoch 902 : Loss 0.0987\n",
            "Epoch 903 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 904 : Loss 0.0987\n",
            "Epoch 905 : Loss 0.0987\n",
            "Epoch 906 : Loss 0.0987\n",
            "Epoch 907 : Loss 0.0987\n",
            "Epoch 908 : Loss 0.0987\n",
            "Epoch 909 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 910 : Loss 0.0987\n",
            "Epoch 911 : Loss 0.0987\n",
            "Epoch 912 : Loss 0.0987\n",
            "Epoch 913 : Loss 0.0987\n",
            "Epoch 914 : Loss 0.0987\n",
            "Epoch 915 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 916 : Loss 0.0987\n",
            "Epoch 917 : Loss 0.0987\n",
            "Epoch 918 : Loss 0.0987\n",
            "Epoch 919 : Loss 0.0987\n",
            "Epoch 920 : Loss 0.0987\n",
            "Epoch 921 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 922 : Loss 0.0987\n",
            "Epoch 923 : Loss 0.0987\n",
            "Epoch 924 : Loss 0.0987\n",
            "Epoch 925 : Loss 0.0987\n",
            "Epoch 926 : Loss 0.0987\n",
            "Epoch 927 : Loss 0.0987\n",
            "Epoch 928 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 929 : Loss 0.0987\n",
            "Epoch 930 : Loss 0.0987\n",
            "Epoch 931 : Loss 0.0987\n",
            "Epoch 932 : Loss 0.0987\n",
            "Epoch 933 : Loss 0.0987\n",
            "Epoch 934 : Loss 0.0987\n",
            "Epoch 935 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 936 : Loss 0.0987\n",
            "Epoch 937 : Loss 0.0987\n",
            "Epoch 938 : Loss 0.0987\n",
            "Epoch 939 : Loss 0.0987\n",
            "Epoch 940 : Loss 0.0987\n",
            "Epoch 941 : Loss 0.0987\n",
            "Epoch 942 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 943 : Loss 0.0987\n",
            "Epoch 944 : Loss 0.0987\n",
            "Epoch 945 : Loss 0.0987\n",
            "Epoch 946 : Loss 0.0987\n",
            "Epoch 947 : Loss 0.0987\n",
            "Epoch 948 : Loss 0.0987\n",
            "Epoch 949 : Loss 0.0987"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 950 : Loss 0.0987\n",
            "Epoch 951 : Loss 0.0987\n",
            "Epoch 952 : Loss 0.0987\n",
            "Epoch 953 : Loss 0.0987\n",
            "Epoch 954 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 955 : Loss 0.0987\n",
            "Epoch 956 : Loss 0.0987\n",
            "Epoch 957 : Loss 0.0987\n",
            "Epoch 958 : Loss 0.0987\n",
            "Epoch 959 : Loss 0.0987\n",
            "Epoch 960 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 961 : Loss 0.0987\n",
            "Epoch 962 : Loss 0.0987\n",
            "Epoch 963 : Loss 0.0987\n",
            "Epoch 964 : Loss 0.0987\n",
            "Epoch 965 : Loss 0.0987\n",
            "Epoch 966 : Loss 0.0987\n",
            "Epoch 967 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 968 : Loss 0.0987\n",
            "Epoch 969 : Loss 0.0987\n",
            "Epoch 970 : Loss 0.0987\n",
            "Epoch 971 : Loss 0.0987\n",
            "Epoch 972 : Loss 0.0987\n",
            "Epoch 973 : Loss 0.0987\n",
            "Epoch 974 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 975 : Loss 0.0987\n",
            "Epoch 976 : Loss 0.0987\n",
            "Epoch 977 : Loss 0.0987\n",
            "Epoch 978 : Loss 0.0987\n",
            "Epoch 979 : Loss 0.0987\n",
            "Epoch 980 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 981 : Loss 0.0987\n",
            "Epoch 982 : Loss 0.0987\n",
            "Epoch 983 : Loss 0.0987\n",
            "Epoch 984 : Loss 0.0987\n",
            "Epoch 985 : Loss 0.0987\n",
            "Epoch 986 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 987 : Loss 0.0987\n",
            "Epoch 988 : Loss 0.0987\n",
            "Epoch 989 : Loss 0.0987\n",
            "Epoch 990 : Loss 0.0987\n",
            "Epoch 991 : Loss 0.0987\n",
            "Epoch 992 : Loss 0.0987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_14/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 993 : Loss 0.0987\n",
            "Epoch 994 : Loss 0.0987\n",
            "Epoch 995 : Loss 0.0987\n",
            "Epoch 996 : Loss 0.0987\n",
            "Epoch 997 : Loss 0.0987\n",
            "Epoch 998 : Loss 0.0987\n",
            "Epoch 999 : Loss 0.0987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(t, model.predict(t), 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "zV7753KExp3Z",
        "outputId": "dbc1105a-9833-4e39-fc82-98cd6aeca11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import cm\n",
        "color = cm.Reds(np.linspace(0,1,100))\n",
        "theta = model.predict(t)\n",
        "plt.figure(figsize=(5,5))\n",
        "for x,y,c in zip(0.5*np.cos(theta),0.5*np.sin(theta), color):\n",
        "    plt.scatter(x,y,color=c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "omRZCzIbxzGz",
        "outputId": "9cfb6417-647e-4ef4-c5c0-c94c27d962ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initial condition\n",
        "epochs = 1000\n",
        "for num_epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        omega_cal = omega(model,t)\n",
        "        loss1 = loss_fn(np.pi, omega_cal)\n",
        "        loss2 = loss_fn(np.pi/6, model(np.array([0.])))\n",
        "        loss = tf.cast(loss1, dtype='float32') + loss2\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads,model.trainable_weights))\n",
        "    print('Epoch %s: Loss %.4f' %(num_epoch, loss.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSu7wziGykG5",
        "outputId": "5a19950d-d8a5-4e4f-9efb-0b62b678aef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 0.3471\n",
            "Epoch 1: Loss 0.3146\n",
            "Epoch 2: Loss 0.2797\n",
            "Epoch 3: Loss 0.2452\n",
            "Epoch 4: Loss 0.2126\n",
            "Epoch 5: Loss 0.1834\n",
            "Epoch 6: Loss 0.1583\n",
            "Epoch 7: Loss 0.1377\n",
            "Epoch 8: Loss 0.1217\n",
            "Epoch 9: Loss 0.1103\n",
            "Epoch 10: Loss 0.1030\n",
            "Epoch 11: Loss 0.0994\n",
            "Epoch 12: Loss 0.0988\n",
            "Epoch 13: Loss 0.1004\n",
            "Epoch 14: Loss 0.1035\n",
            "Epoch 15: Loss 0.1073\n",
            "Epoch 16: Loss 0.1112\n",
            "Epoch 17: Loss 0.1148\n",
            "Epoch 18: Loss 0.1176\n",
            "Epoch 19: Loss 0.1194\n",
            "Epoch 20: Loss 0.1203\n",
            "Epoch 21: Loss 0.1201\n",
            "Epoch 22: Loss 0.1191\n",
            "Epoch 23: Loss 0.1175\n",
            "Epoch 24: Loss 0.1153\n",
            "Epoch 25: Loss 0.1128\n",
            "Epoch 26: Loss 0.1103\n",
            "Epoch 27: Loss 0.1078\n",
            "Epoch 28: Loss 0.1055\n",
            "Epoch 29: Loss 0.1034\n",
            "Epoch 30: Loss 0.1018\n",
            "Epoch 31: Loss 0.1005\n",
            "Epoch 32: Loss 0.0996\n",
            "Epoch 33: Loss 0.0990\n",
            "Epoch 34: Loss 0.0987\n",
            "Epoch 35: Loss 0.0987\n",
            "Epoch 36: Loss 0.0989\n",
            "Epoch 37: Loss 0.0991\n",
            "Epoch 38: Loss 0.0995\n",
            "Epoch 39: Loss 0.0998\n",
            "Epoch 40: Loss 0.1001\n",
            "Epoch 41: Loss 0.1003\n",
            "Epoch 42: Loss 0.1005\n",
            "Epoch 43: Loss 0.1006\n",
            "Epoch 44: Loss 0.1006\n",
            "Epoch 45: Loss 0.1005\n",
            "Epoch 46: Loss 0.1004\n",
            "Epoch 47: Loss 0.1002\n",
            "Epoch 48: Loss 0.1000\n",
            "Epoch 49: Loss 0.0997\n",
            "Epoch 50: Loss 0.0995\n",
            "Epoch 51: Loss 0.0993\n",
            "Epoch 52: Loss 0.0991\n",
            "Epoch 53: Loss 0.0990\n",
            "Epoch 54: Loss 0.0989\n",
            "Epoch 55: Loss 0.0988\n",
            "Epoch 56: Loss 0.0987\n",
            "Epoch 57: Loss 0.0987\n",
            "Epoch 58: Loss 0.0987\n",
            "Epoch 59: Loss 0.0987\n",
            "Epoch 60: Loss 0.0987\n",
            "Epoch 61: Loss 0.0988\n",
            "Epoch 62: Loss 0.0988\n",
            "Epoch 63: Loss 0.0988\n",
            "Epoch 64: Loss 0.0988\n",
            "Epoch 65: Loss 0.0989\n",
            "Epoch 66: Loss 0.0989\n",
            "Epoch 67: Loss 0.0989\n",
            "Epoch 68: Loss 0.0989\n",
            "Epoch 69: Loss 0.0988\n",
            "Epoch 70: Loss 0.0988\n",
            "Epoch 71: Loss 0.0988\n",
            "Epoch 72: Loss 0.0988\n",
            "Epoch 73: Loss 0.0988\n",
            "Epoch 74: Loss 0.0987\n",
            "Epoch 75: Loss 0.0987\n",
            "Epoch 76: Loss 0.0987\n",
            "Epoch 77: Loss 0.0987\n",
            "Epoch 78: Loss 0.0987\n",
            "Epoch 79: Loss 0.0987\n",
            "Epoch 80: Loss 0.0987\n",
            "Epoch 81: Loss 0.0987\n",
            "Epoch 82: Loss 0.0987\n",
            "Epoch 83: Loss 0.0987\n",
            "Epoch 84: Loss 0.0987\n",
            "Epoch 85: Loss 0.0987\n",
            "Epoch 86: Loss 0.0987\n",
            "Epoch 87: Loss 0.0987\n",
            "Epoch 88: Loss 0.0987\n",
            "Epoch 89: Loss 0.0987\n",
            "Epoch 90: Loss 0.0987\n",
            "Epoch 91: Loss 0.0987\n",
            "Epoch 92: Loss 0.0987\n",
            "Epoch 93: Loss 0.0987\n",
            "Epoch 94: Loss 0.0987\n",
            "Epoch 95: Loss 0.0987\n",
            "Epoch 96: Loss 0.0987\n",
            "Epoch 97: Loss 0.0987\n",
            "Epoch 98: Loss 0.0987\n",
            "Epoch 99: Loss 0.0987\n",
            "Epoch 100: Loss 0.0987\n",
            "Epoch 101: Loss 0.0987\n",
            "Epoch 102: Loss 0.0987\n",
            "Epoch 103: Loss 0.0987\n",
            "Epoch 104: Loss 0.0987\n",
            "Epoch 105: Loss 0.0987\n",
            "Epoch 106: Loss 0.0987\n",
            "Epoch 107: Loss 0.0987\n",
            "Epoch 108: Loss 0.0987\n",
            "Epoch 109: Loss 0.0987\n",
            "Epoch 110: Loss 0.0987\n",
            "Epoch 111: Loss 0.0987\n",
            "Epoch 112: Loss 0.0987\n",
            "Epoch 113: Loss 0.0987\n",
            "Epoch 114: Loss 0.0987\n",
            "Epoch 115: Loss 0.0987\n",
            "Epoch 116: Loss 0.0987\n",
            "Epoch 117: Loss 0.0987\n",
            "Epoch 118: Loss 0.0987\n",
            "Epoch 119: Loss 0.0987\n",
            "Epoch 120: Loss 0.0987\n",
            "Epoch 121: Loss 0.0987\n",
            "Epoch 122: Loss 0.0987\n",
            "Epoch 123: Loss 0.0987\n",
            "Epoch 124: Loss 0.0987\n",
            "Epoch 125: Loss 0.0987\n",
            "Epoch 126: Loss 0.0987\n",
            "Epoch 127: Loss 0.0987\n",
            "Epoch 128: Loss 0.0987\n",
            "Epoch 129: Loss 0.0987\n",
            "Epoch 130: Loss 0.0987\n",
            "Epoch 131: Loss 0.0987\n",
            "Epoch 132: Loss 0.0987\n",
            "Epoch 133: Loss 0.0987\n",
            "Epoch 134: Loss 0.0987\n",
            "Epoch 135: Loss 0.0987\n",
            "Epoch 136: Loss 0.0987\n",
            "Epoch 137: Loss 0.0987\n",
            "Epoch 138: Loss 0.0987\n",
            "Epoch 139: Loss 0.0987\n",
            "Epoch 140: Loss 0.0987\n",
            "Epoch 141: Loss 0.0987\n",
            "Epoch 142: Loss 0.0987\n",
            "Epoch 143: Loss 0.0987\n",
            "Epoch 144: Loss 0.0987\n",
            "Epoch 145: Loss 0.0987\n",
            "Epoch 146: Loss 0.0987\n",
            "Epoch 147: Loss 0.0987\n",
            "Epoch 148: Loss 0.0987\n",
            "Epoch 149: Loss 0.0987\n",
            "Epoch 150: Loss 0.0987\n",
            "Epoch 151: Loss 0.0987\n",
            "Epoch 152: Loss 0.0987\n",
            "Epoch 153: Loss 0.0987\n",
            "Epoch 154: Loss 0.0987\n",
            "Epoch 155: Loss 0.0987\n",
            "Epoch 156: Loss 0.0987\n",
            "Epoch 157: Loss 0.0987\n",
            "Epoch 158: Loss 0.0987\n",
            "Epoch 159: Loss 0.0987\n",
            "Epoch 160: Loss 0.0987\n",
            "Epoch 161: Loss 0.0987\n",
            "Epoch 162: Loss 0.0987\n",
            "Epoch 163: Loss 0.0987\n",
            "Epoch 164: Loss 0.0987\n",
            "Epoch 165: Loss 0.0987\n",
            "Epoch 166: Loss 0.0987\n",
            "Epoch 167: Loss 0.0987\n",
            "Epoch 168: Loss 0.0987\n",
            "Epoch 169: Loss 0.0987\n",
            "Epoch 170: Loss 0.0987\n",
            "Epoch 171: Loss 0.0987\n",
            "Epoch 172: Loss 0.0987\n",
            "Epoch 173: Loss 0.0987\n",
            "Epoch 174: Loss 0.0987\n",
            "Epoch 175: Loss 0.0987\n",
            "Epoch 176: Loss 0.0987\n",
            "Epoch 177: Loss 0.0987\n",
            "Epoch 178: Loss 0.0987\n",
            "Epoch 179: Loss 0.0987\n",
            "Epoch 180: Loss 0.0987\n",
            "Epoch 181: Loss 0.0987\n",
            "Epoch 182: Loss 0.0987\n",
            "Epoch 183: Loss 0.0987\n",
            "Epoch 184: Loss 0.0987\n",
            "Epoch 185: Loss 0.0987\n",
            "Epoch 186: Loss 0.0987\n",
            "Epoch 187: Loss 0.0987\n",
            "Epoch 188: Loss 0.0987\n",
            "Epoch 189: Loss 0.0987\n",
            "Epoch 190: Loss 0.0987\n",
            "Epoch 191: Loss 0.0987\n",
            "Epoch 192: Loss 0.0987\n",
            "Epoch 193: Loss 0.0987\n",
            "Epoch 194: Loss 0.0987\n",
            "Epoch 195: Loss 0.0987\n",
            "Epoch 196: Loss 0.0987\n",
            "Epoch 197: Loss 0.0987\n",
            "Epoch 198: Loss 0.0987\n",
            "Epoch 199: Loss 0.0987\n",
            "Epoch 200: Loss 0.0987\n",
            "Epoch 201: Loss 0.0987\n",
            "Epoch 202: Loss 0.0987\n",
            "Epoch 203: Loss 0.0987\n",
            "Epoch 204: Loss 0.0987\n",
            "Epoch 205: Loss 0.0987\n",
            "Epoch 206: Loss 0.0987\n",
            "Epoch 207: Loss 0.0987\n",
            "Epoch 208: Loss 0.0987\n",
            "Epoch 209: Loss 0.0987\n",
            "Epoch 210: Loss 0.0987\n",
            "Epoch 211: Loss 0.0987\n",
            "Epoch 212: Loss 0.0987\n",
            "Epoch 213: Loss 0.0987\n",
            "Epoch 214: Loss 0.0987\n",
            "Epoch 215: Loss 0.0987\n",
            "Epoch 216: Loss 0.0987\n",
            "Epoch 217: Loss 0.0987\n",
            "Epoch 218: Loss 0.0987\n",
            "Epoch 219: Loss 0.0987\n",
            "Epoch 220: Loss 0.0987\n",
            "Epoch 221: Loss 0.0987\n",
            "Epoch 222: Loss 0.0987\n",
            "Epoch 223: Loss 0.0987\n",
            "Epoch 224: Loss 0.0987\n",
            "Epoch 225: Loss 0.0987\n",
            "Epoch 226: Loss 0.0987\n",
            "Epoch 227: Loss 0.0987\n",
            "Epoch 228: Loss 0.0987\n",
            "Epoch 229: Loss 0.0987\n",
            "Epoch 230: Loss 0.0987\n",
            "Epoch 231: Loss 0.0987\n",
            "Epoch 232: Loss 0.0987\n",
            "Epoch 233: Loss 0.0987\n",
            "Epoch 234: Loss 0.0987\n",
            "Epoch 235: Loss 0.0987\n",
            "Epoch 236: Loss 0.0987\n",
            "Epoch 237: Loss 0.0987\n",
            "Epoch 238: Loss 0.0987\n",
            "Epoch 239: Loss 0.0987\n",
            "Epoch 240: Loss 0.0987\n",
            "Epoch 241: Loss 0.0987\n",
            "Epoch 242: Loss 0.0987\n",
            "Epoch 243: Loss 0.0987\n",
            "Epoch 244: Loss 0.0987\n",
            "Epoch 245: Loss 0.0987\n",
            "Epoch 246: Loss 0.0987\n",
            "Epoch 247: Loss 0.0987\n",
            "Epoch 248: Loss 0.0987\n",
            "Epoch 249: Loss 0.0987\n",
            "Epoch 250: Loss 0.0987\n",
            "Epoch 251: Loss 0.0987\n",
            "Epoch 252: Loss 0.0987\n",
            "Epoch 253: Loss 0.0987\n",
            "Epoch 254: Loss 0.0987\n",
            "Epoch 255: Loss 0.0987\n",
            "Epoch 256: Loss 0.0987\n",
            "Epoch 257: Loss 0.0987\n",
            "Epoch 258: Loss 0.0987\n",
            "Epoch 259: Loss 0.0987\n",
            "Epoch 260: Loss 0.0987\n",
            "Epoch 261: Loss 0.0987\n",
            "Epoch 262: Loss 0.0987\n",
            "Epoch 263: Loss 0.0987\n",
            "Epoch 264: Loss 0.0987\n",
            "Epoch 265: Loss 0.0987\n",
            "Epoch 266: Loss 0.0987\n",
            "Epoch 267: Loss 0.0987\n",
            "Epoch 268: Loss 0.0987\n",
            "Epoch 269: Loss 0.0987\n",
            "Epoch 270: Loss 0.0987\n",
            "Epoch 271: Loss 0.0987\n",
            "Epoch 272: Loss 0.0987\n",
            "Epoch 273: Loss 0.0987\n",
            "Epoch 274: Loss 0.0987\n",
            "Epoch 275: Loss 0.0987\n",
            "Epoch 276: Loss 0.0987\n",
            "Epoch 277: Loss 0.0987\n",
            "Epoch 278: Loss 0.0987\n",
            "Epoch 279: Loss 0.0987\n",
            "Epoch 280: Loss 0.0987\n",
            "Epoch 281: Loss 0.0987\n",
            "Epoch 282: Loss 0.0987\n",
            "Epoch 283: Loss 0.0987\n",
            "Epoch 284: Loss 0.0987\n",
            "Epoch 285: Loss 0.0987\n",
            "Epoch 286: Loss 0.0987\n",
            "Epoch 287: Loss 0.0987\n",
            "Epoch 288: Loss 0.0987\n",
            "Epoch 289: Loss 0.0987\n",
            "Epoch 290: Loss 0.0987\n",
            "Epoch 291: Loss 0.0987\n",
            "Epoch 292: Loss 0.0987\n",
            "Epoch 293: Loss 0.0987\n",
            "Epoch 294: Loss 0.0987\n",
            "Epoch 295: Loss 0.0987\n",
            "Epoch 296: Loss 0.0987\n",
            "Epoch 297: Loss 0.0987\n",
            "Epoch 298: Loss 0.0987\n",
            "Epoch 299: Loss 0.0987\n",
            "Epoch 300: Loss 0.0987\n",
            "Epoch 301: Loss 0.0987\n",
            "Epoch 302: Loss 0.0987\n",
            "Epoch 303: Loss 0.0987\n",
            "Epoch 304: Loss 0.0987\n",
            "Epoch 305: Loss 0.0987\n",
            "Epoch 306: Loss 0.0987\n",
            "Epoch 307: Loss 0.0987\n",
            "Epoch 308: Loss 0.0987\n",
            "Epoch 309: Loss 0.0987\n",
            "Epoch 310: Loss 0.0987\n",
            "Epoch 311: Loss 0.0987\n",
            "Epoch 312: Loss 0.0987\n",
            "Epoch 313: Loss 0.0987\n",
            "Epoch 314: Loss 0.0987\n",
            "Epoch 315: Loss 0.0987\n",
            "Epoch 316: Loss 0.0987\n",
            "Epoch 317: Loss 0.0987\n",
            "Epoch 318: Loss 0.0987\n",
            "Epoch 319: Loss 0.0987\n",
            "Epoch 320: Loss 0.0987\n",
            "Epoch 321: Loss 0.0987\n",
            "Epoch 322: Loss 0.0987\n",
            "Epoch 323: Loss 0.0987\n",
            "Epoch 324: Loss 0.0987\n",
            "Epoch 325: Loss 0.0987\n",
            "Epoch 326: Loss 0.0987\n",
            "Epoch 327: Loss 0.0987\n",
            "Epoch 328: Loss 0.0987\n",
            "Epoch 329: Loss 0.0987\n",
            "Epoch 330: Loss 0.0987\n",
            "Epoch 331: Loss 0.0987\n",
            "Epoch 332: Loss 0.0987\n",
            "Epoch 333: Loss 0.0987\n",
            "Epoch 334: Loss 0.0987\n",
            "Epoch 335: Loss 0.0987\n",
            "Epoch 336: Loss 0.0987\n",
            "Epoch 337: Loss 0.0987\n",
            "Epoch 338: Loss 0.0987\n",
            "Epoch 339: Loss 0.0987\n",
            "Epoch 340: Loss 0.0987\n",
            "Epoch 341: Loss 0.0987\n",
            "Epoch 342: Loss 0.0987\n",
            "Epoch 343: Loss 0.0987\n",
            "Epoch 344: Loss 0.0987\n",
            "Epoch 345: Loss 0.0987\n",
            "Epoch 346: Loss 0.0987\n",
            "Epoch 347: Loss 0.0987\n",
            "Epoch 348: Loss 0.0987\n",
            "Epoch 349: Loss 0.0987\n",
            "Epoch 350: Loss 0.0987\n",
            "Epoch 351: Loss 0.0987\n",
            "Epoch 352: Loss 0.0987\n",
            "Epoch 353: Loss 0.0987\n",
            "Epoch 354: Loss 0.0987\n",
            "Epoch 355: Loss 0.0987\n",
            "Epoch 356: Loss 0.0987\n",
            "Epoch 357: Loss 0.0987\n",
            "Epoch 358: Loss 0.0987\n",
            "Epoch 359: Loss 0.0987\n",
            "Epoch 360: Loss 0.0987\n",
            "Epoch 361: Loss 0.0987\n",
            "Epoch 362: Loss 0.0987\n",
            "Epoch 363: Loss 0.0987\n",
            "Epoch 364: Loss 0.0987\n",
            "Epoch 365: Loss 0.0987\n",
            "Epoch 366: Loss 0.0987\n",
            "Epoch 367: Loss 0.0987\n",
            "Epoch 368: Loss 0.0987\n",
            "Epoch 369: Loss 0.0987\n",
            "Epoch 370: Loss 0.0987\n",
            "Epoch 371: Loss 0.0987\n",
            "Epoch 372: Loss 0.0987\n",
            "Epoch 373: Loss 0.0987\n",
            "Epoch 374: Loss 0.0987\n",
            "Epoch 375: Loss 0.0987\n",
            "Epoch 376: Loss 0.0987\n",
            "Epoch 377: Loss 0.0987\n",
            "Epoch 378: Loss 0.0987\n",
            "Epoch 379: Loss 0.0987\n",
            "Epoch 380: Loss 0.0987\n",
            "Epoch 381: Loss 0.0987\n",
            "Epoch 382: Loss 0.0987\n",
            "Epoch 383: Loss 0.0987\n",
            "Epoch 384: Loss 0.0987\n",
            "Epoch 385: Loss 0.0987\n",
            "Epoch 386: Loss 0.0987\n",
            "Epoch 387: Loss 0.0987\n",
            "Epoch 388: Loss 0.0987\n",
            "Epoch 389: Loss 0.0987\n",
            "Epoch 390: Loss 0.0987\n",
            "Epoch 391: Loss 0.0987\n",
            "Epoch 392: Loss 0.0987\n",
            "Epoch 393: Loss 0.0987\n",
            "Epoch 394: Loss 0.0987\n",
            "Epoch 395: Loss 0.0987\n",
            "Epoch 396: Loss 0.0987\n",
            "Epoch 397: Loss 0.0987\n",
            "Epoch 398: Loss 0.0987\n",
            "Epoch 399: Loss 0.0987\n",
            "Epoch 400: Loss 0.0987\n",
            "Epoch 401: Loss 0.0987\n",
            "Epoch 402: Loss 0.0987\n",
            "Epoch 403: Loss 0.0987\n",
            "Epoch 404: Loss 0.0987\n",
            "Epoch 405: Loss 0.0987\n",
            "Epoch 406: Loss 0.0987\n",
            "Epoch 407: Loss 0.0987\n",
            "Epoch 408: Loss 0.0987\n",
            "Epoch 409: Loss 0.0987\n",
            "Epoch 410: Loss 0.0987\n",
            "Epoch 411: Loss 0.0987\n",
            "Epoch 412: Loss 0.0987\n",
            "Epoch 413: Loss 0.0987\n",
            "Epoch 414: Loss 0.0987\n",
            "Epoch 415: Loss 0.0987\n",
            "Epoch 416: Loss 0.0987\n",
            "Epoch 417: Loss 0.0987\n",
            "Epoch 418: Loss 0.0987\n",
            "Epoch 419: Loss 0.0987\n",
            "Epoch 420: Loss 0.0987\n",
            "Epoch 421: Loss 0.0987\n",
            "Epoch 422: Loss 0.0987\n",
            "Epoch 423: Loss 0.0987\n",
            "Epoch 424: Loss 0.0987\n",
            "Epoch 425: Loss 0.0987\n",
            "Epoch 426: Loss 0.0987\n",
            "Epoch 427: Loss 0.0987\n",
            "Epoch 428: Loss 0.0987\n",
            "Epoch 429: Loss 0.0987\n",
            "Epoch 430: Loss 0.0987\n",
            "Epoch 431: Loss 0.0987\n",
            "Epoch 432: Loss 0.0987\n",
            "Epoch 433: Loss 0.0987\n",
            "Epoch 434: Loss 0.0987\n",
            "Epoch 435: Loss 0.0987\n",
            "Epoch 436: Loss 0.0987\n",
            "Epoch 437: Loss 0.0987\n",
            "Epoch 438: Loss 0.0987\n",
            "Epoch 439: Loss 0.0987\n",
            "Epoch 440: Loss 0.0987\n",
            "Epoch 441: Loss 0.0987\n",
            "Epoch 442: Loss 0.0987\n",
            "Epoch 443: Loss 0.0987\n",
            "Epoch 444: Loss 0.0987\n",
            "Epoch 445: Loss 0.0987\n",
            "Epoch 446: Loss 0.0987\n",
            "Epoch 447: Loss 0.0987\n",
            "Epoch 448: Loss 0.0987\n",
            "Epoch 449: Loss 0.0987\n",
            "Epoch 450: Loss 0.0987\n",
            "Epoch 451: Loss 0.0987\n",
            "Epoch 452: Loss 0.0987\n",
            "Epoch 453: Loss 0.0987\n",
            "Epoch 454: Loss 0.0987\n",
            "Epoch 455: Loss 0.0987\n",
            "Epoch 456: Loss 0.0987\n",
            "Epoch 457: Loss 0.0987\n",
            "Epoch 458: Loss 0.0987\n",
            "Epoch 459: Loss 0.0987\n",
            "Epoch 460: Loss 0.0987\n",
            "Epoch 461: Loss 0.0987\n",
            "Epoch 462: Loss 0.0987\n",
            "Epoch 463: Loss 0.0987\n",
            "Epoch 464: Loss 0.0987\n",
            "Epoch 465: Loss 0.0987\n",
            "Epoch 466: Loss 0.0987\n",
            "Epoch 467: Loss 0.0987\n",
            "Epoch 468: Loss 0.0987\n",
            "Epoch 469: Loss 0.0987\n",
            "Epoch 470: Loss 0.0987\n",
            "Epoch 471: Loss 0.0987\n",
            "Epoch 472: Loss 0.0987\n",
            "Epoch 473: Loss 0.0987\n",
            "Epoch 474: Loss 0.0987\n",
            "Epoch 475: Loss 0.0987\n",
            "Epoch 476: Loss 0.0987\n",
            "Epoch 477: Loss 0.0987\n",
            "Epoch 478: Loss 0.0987\n",
            "Epoch 479: Loss 0.0987\n",
            "Epoch 480: Loss 0.0987\n",
            "Epoch 481: Loss 0.0987\n",
            "Epoch 482: Loss 0.0987\n",
            "Epoch 483: Loss 0.0987\n",
            "Epoch 484: Loss 0.0987\n",
            "Epoch 485: Loss 0.0987\n",
            "Epoch 486: Loss 0.0987\n",
            "Epoch 487: Loss 0.0987\n",
            "Epoch 488: Loss 0.0987\n",
            "Epoch 489: Loss 0.0987\n",
            "Epoch 490: Loss 0.0987\n",
            "Epoch 491: Loss 0.0987\n",
            "Epoch 492: Loss 0.0987\n",
            "Epoch 493: Loss 0.0987\n",
            "Epoch 494: Loss 0.0987\n",
            "Epoch 495: Loss 0.0987\n",
            "Epoch 496: Loss 0.0987\n",
            "Epoch 497: Loss 0.0987\n",
            "Epoch 498: Loss 0.0987\n",
            "Epoch 499: Loss 0.0987\n",
            "Epoch 500: Loss 0.0987\n",
            "Epoch 501: Loss 0.0987\n",
            "Epoch 502: Loss 0.0987\n",
            "Epoch 503: Loss 0.0987\n",
            "Epoch 504: Loss 0.0987\n",
            "Epoch 505: Loss 0.0987\n",
            "Epoch 506: Loss 0.0987\n",
            "Epoch 507: Loss 0.0987\n",
            "Epoch 508: Loss 0.0987\n",
            "Epoch 509: Loss 0.0987\n",
            "Epoch 510: Loss 0.0987\n",
            "Epoch 511: Loss 0.0987\n",
            "Epoch 512: Loss 0.0987\n",
            "Epoch 513: Loss 0.0987\n",
            "Epoch 514: Loss 0.0987\n",
            "Epoch 515: Loss 0.0987\n",
            "Epoch 516: Loss 0.0987\n",
            "Epoch 517: Loss 0.0987\n",
            "Epoch 518: Loss 0.0987\n",
            "Epoch 519: Loss 0.0987\n",
            "Epoch 520: Loss 0.0987\n",
            "Epoch 521: Loss 0.0987\n",
            "Epoch 522: Loss 0.0987\n",
            "Epoch 523: Loss 0.0987\n",
            "Epoch 524: Loss 0.0987\n",
            "Epoch 525: Loss 0.0987\n",
            "Epoch 526: Loss 0.0987\n",
            "Epoch 527: Loss 0.0987\n",
            "Epoch 528: Loss 0.0987\n",
            "Epoch 529: Loss 0.0987\n",
            "Epoch 530: Loss 0.0987\n",
            "Epoch 531: Loss 0.0987\n",
            "Epoch 532: Loss 0.0987\n",
            "Epoch 533: Loss 0.0987\n",
            "Epoch 534: Loss 0.0987\n",
            "Epoch 535: Loss 0.0987\n",
            "Epoch 536: Loss 0.0987\n",
            "Epoch 537: Loss 0.0987\n",
            "Epoch 538: Loss 0.0987\n",
            "Epoch 539: Loss 0.0987\n",
            "Epoch 540: Loss 0.0987\n",
            "Epoch 541: Loss 0.0987\n",
            "Epoch 542: Loss 0.0987\n",
            "Epoch 543: Loss 0.0987\n",
            "Epoch 544: Loss 0.0987\n",
            "Epoch 545: Loss 0.0987\n",
            "Epoch 546: Loss 0.0987\n",
            "Epoch 547: Loss 0.0987\n",
            "Epoch 548: Loss 0.0987\n",
            "Epoch 549: Loss 0.0987\n",
            "Epoch 550: Loss 0.0987\n",
            "Epoch 551: Loss 0.0987\n",
            "Epoch 552: Loss 0.0987\n",
            "Epoch 553: Loss 0.0987\n",
            "Epoch 554: Loss 0.0987\n",
            "Epoch 555: Loss 0.0987\n",
            "Epoch 556: Loss 0.0987\n",
            "Epoch 557: Loss 0.0987\n",
            "Epoch 558: Loss 0.0987\n",
            "Epoch 559: Loss 0.0987\n",
            "Epoch 560: Loss 0.0987\n",
            "Epoch 561: Loss 0.0987\n",
            "Epoch 562: Loss 0.0987\n",
            "Epoch 563: Loss 0.0987\n",
            "Epoch 564: Loss 0.0987\n",
            "Epoch 565: Loss 0.0987\n",
            "Epoch 566: Loss 0.0987\n",
            "Epoch 567: Loss 0.0987\n",
            "Epoch 568: Loss 0.0987\n",
            "Epoch 569: Loss 0.0987\n",
            "Epoch 570: Loss 0.0987\n",
            "Epoch 571: Loss 0.0987\n",
            "Epoch 572: Loss 0.0987\n",
            "Epoch 573: Loss 0.0987\n",
            "Epoch 574: Loss 0.0987\n",
            "Epoch 575: Loss 0.0987\n",
            "Epoch 576: Loss 0.0987\n",
            "Epoch 577: Loss 0.0987\n",
            "Epoch 578: Loss 0.0987\n",
            "Epoch 579: Loss 0.0987\n",
            "Epoch 580: Loss 0.0987\n",
            "Epoch 581: Loss 0.0987\n",
            "Epoch 582: Loss 0.0987\n",
            "Epoch 583: Loss 0.0987\n",
            "Epoch 584: Loss 0.0987\n",
            "Epoch 585: Loss 0.0987\n",
            "Epoch 586: Loss 0.0987\n",
            "Epoch 587: Loss 0.0987\n",
            "Epoch 588: Loss 0.0987\n",
            "Epoch 589: Loss 0.0987\n",
            "Epoch 590: Loss 0.0987\n",
            "Epoch 591: Loss 0.0987\n",
            "Epoch 592: Loss 0.0987\n",
            "Epoch 593: Loss 0.0987\n",
            "Epoch 594: Loss 0.0987\n",
            "Epoch 595: Loss 0.0987\n",
            "Epoch 596: Loss 0.0987\n",
            "Epoch 597: Loss 0.0987\n",
            "Epoch 598: Loss 0.0987\n",
            "Epoch 599: Loss 0.0987\n",
            "Epoch 600: Loss 0.0987\n",
            "Epoch 601: Loss 0.0987\n",
            "Epoch 602: Loss 0.0987\n",
            "Epoch 603: Loss 0.0987\n",
            "Epoch 604: Loss 0.0987\n",
            "Epoch 605: Loss 0.0987\n",
            "Epoch 606: Loss 0.0987\n",
            "Epoch 607: Loss 0.0987\n",
            "Epoch 608: Loss 0.0987\n",
            "Epoch 609: Loss 0.0987\n",
            "Epoch 610: Loss 0.0987\n",
            "Epoch 611: Loss 0.0987\n",
            "Epoch 612: Loss 0.0987\n",
            "Epoch 613: Loss 0.0987\n",
            "Epoch 614: Loss 0.0987\n",
            "Epoch 615: Loss 0.0987\n",
            "Epoch 616: Loss 0.0987\n",
            "Epoch 617: Loss 0.0987\n",
            "Epoch 618: Loss 0.0987\n",
            "Epoch 619: Loss 0.0987\n",
            "Epoch 620: Loss 0.0987\n",
            "Epoch 621: Loss 0.0987\n",
            "Epoch 622: Loss 0.0987\n",
            "Epoch 623: Loss 0.0987\n",
            "Epoch 624: Loss 0.0987\n",
            "Epoch 625: Loss 0.0987\n",
            "Epoch 626: Loss 0.0987\n",
            "Epoch 627: Loss 0.0987\n",
            "Epoch 628: Loss 0.0987\n",
            "Epoch 629: Loss 0.0987\n",
            "Epoch 630: Loss 0.0987\n",
            "Epoch 631: Loss 0.0987\n",
            "Epoch 632: Loss 0.0987\n",
            "Epoch 633: Loss 0.0987\n",
            "Epoch 634: Loss 0.0987\n",
            "Epoch 635: Loss 0.0987\n",
            "Epoch 636: Loss 0.0987\n",
            "Epoch 637: Loss 0.0987\n",
            "Epoch 638: Loss 0.0987\n",
            "Epoch 639: Loss 0.0987\n",
            "Epoch 640: Loss 0.0987\n",
            "Epoch 641: Loss 0.0987\n",
            "Epoch 642: Loss 0.0987\n",
            "Epoch 643: Loss 0.0987\n",
            "Epoch 644: Loss 0.0987\n",
            "Epoch 645: Loss 0.0987\n",
            "Epoch 646: Loss 0.0987\n",
            "Epoch 647: Loss 0.0987\n",
            "Epoch 648: Loss 0.0987\n",
            "Epoch 649: Loss 0.0987\n",
            "Epoch 650: Loss 0.0987\n",
            "Epoch 651: Loss 0.0987\n",
            "Epoch 652: Loss 0.0987\n",
            "Epoch 653: Loss 0.0987\n",
            "Epoch 654: Loss 0.0987\n",
            "Epoch 655: Loss 0.0987\n",
            "Epoch 656: Loss 0.0987\n",
            "Epoch 657: Loss 0.0987\n",
            "Epoch 658: Loss 0.0987\n",
            "Epoch 659: Loss 0.0987\n",
            "Epoch 660: Loss 0.0987\n",
            "Epoch 661: Loss 0.0987\n",
            "Epoch 662: Loss 0.0987\n",
            "Epoch 663: Loss 0.0987\n",
            "Epoch 664: Loss 0.0987\n",
            "Epoch 665: Loss 0.0987\n",
            "Epoch 666: Loss 0.0987\n",
            "Epoch 667: Loss 0.0987\n",
            "Epoch 668: Loss 0.0987\n",
            "Epoch 669: Loss 0.0987\n",
            "Epoch 670: Loss 0.0987\n",
            "Epoch 671: Loss 0.0987\n",
            "Epoch 672: Loss 0.0987\n",
            "Epoch 673: Loss 0.0987\n",
            "Epoch 674: Loss 0.0987\n",
            "Epoch 675: Loss 0.0987\n",
            "Epoch 676: Loss 0.0987\n",
            "Epoch 677: Loss 0.0987\n",
            "Epoch 678: Loss 0.0987\n",
            "Epoch 679: Loss 0.0987\n",
            "Epoch 680: Loss 0.0987\n",
            "Epoch 681: Loss 0.0987\n",
            "Epoch 682: Loss 0.0987\n",
            "Epoch 683: Loss 0.0987\n",
            "Epoch 684: Loss 0.0987\n",
            "Epoch 685: Loss 0.0987\n",
            "Epoch 686: Loss 0.0987\n",
            "Epoch 687: Loss 0.0987\n",
            "Epoch 688: Loss 0.0987\n",
            "Epoch 689: Loss 0.0987\n",
            "Epoch 690: Loss 0.0987\n",
            "Epoch 691: Loss 0.0987\n",
            "Epoch 692: Loss 0.0987\n",
            "Epoch 693: Loss 0.0987\n",
            "Epoch 694: Loss 0.0987\n",
            "Epoch 695: Loss 0.0987\n",
            "Epoch 696: Loss 0.0987\n",
            "Epoch 697: Loss 0.0987\n",
            "Epoch 698: Loss 0.0987\n",
            "Epoch 699: Loss 0.0987\n",
            "Epoch 700: Loss 0.0987\n",
            "Epoch 701: Loss 0.0987\n",
            "Epoch 702: Loss 0.0987\n",
            "Epoch 703: Loss 0.0987\n",
            "Epoch 704: Loss 0.0987\n",
            "Epoch 705: Loss 0.0987\n",
            "Epoch 706: Loss 0.0987\n",
            "Epoch 707: Loss 0.0987\n",
            "Epoch 708: Loss 0.0987\n",
            "Epoch 709: Loss 0.0987\n",
            "Epoch 710: Loss 0.0987\n",
            "Epoch 711: Loss 0.0987\n",
            "Epoch 712: Loss 0.0987\n",
            "Epoch 713: Loss 0.0987\n",
            "Epoch 714: Loss 0.0987\n",
            "Epoch 715: Loss 0.0987\n",
            "Epoch 716: Loss 0.0987\n",
            "Epoch 717: Loss 0.0987\n",
            "Epoch 718: Loss 0.0987\n",
            "Epoch 719: Loss 0.0987\n",
            "Epoch 720: Loss 0.0987\n",
            "Epoch 721: Loss 0.0987\n",
            "Epoch 722: Loss 0.0987\n",
            "Epoch 723: Loss 0.0987\n",
            "Epoch 724: Loss 0.0987\n",
            "Epoch 725: Loss 0.0987\n",
            "Epoch 726: Loss 0.0987\n",
            "Epoch 727: Loss 0.0987\n",
            "Epoch 728: Loss 0.0987\n",
            "Epoch 729: Loss 0.0987\n",
            "Epoch 730: Loss 0.0987\n",
            "Epoch 731: Loss 0.0987\n",
            "Epoch 732: Loss 0.0987\n",
            "Epoch 733: Loss 0.0987\n",
            "Epoch 734: Loss 0.0987\n",
            "Epoch 735: Loss 0.0987\n",
            "Epoch 736: Loss 0.0987\n",
            "Epoch 737: Loss 0.0987\n",
            "Epoch 738: Loss 0.0987\n",
            "Epoch 739: Loss 0.0987\n",
            "Epoch 740: Loss 0.0987\n",
            "Epoch 741: Loss 0.0987\n",
            "Epoch 742: Loss 0.0987\n",
            "Epoch 743: Loss 0.0987\n",
            "Epoch 744: Loss 0.0987\n",
            "Epoch 745: Loss 0.0987\n",
            "Epoch 746: Loss 0.0987\n",
            "Epoch 747: Loss 0.0987\n",
            "Epoch 748: Loss 0.0987\n",
            "Epoch 749: Loss 0.0987\n",
            "Epoch 750: Loss 0.0987\n",
            "Epoch 751: Loss 0.0987\n",
            "Epoch 752: Loss 0.0987\n",
            "Epoch 753: Loss 0.0987\n",
            "Epoch 754: Loss 0.0987\n",
            "Epoch 755: Loss 0.0987\n",
            "Epoch 756: Loss 0.0987\n",
            "Epoch 757: Loss 0.0987\n",
            "Epoch 758: Loss 0.0987\n",
            "Epoch 759: Loss 0.0987\n",
            "Epoch 760: Loss 0.0987\n",
            "Epoch 761: Loss 0.0987\n",
            "Epoch 762: Loss 0.0987\n",
            "Epoch 763: Loss 0.0987\n",
            "Epoch 764: Loss 0.0987\n",
            "Epoch 765: Loss 0.0987\n",
            "Epoch 766: Loss 0.0987\n",
            "Epoch 767: Loss 0.0987\n",
            "Epoch 768: Loss 0.0987\n",
            "Epoch 769: Loss 0.0987\n",
            "Epoch 770: Loss 0.0987\n",
            "Epoch 771: Loss 0.0987\n",
            "Epoch 772: Loss 0.0987\n",
            "Epoch 773: Loss 0.0987\n",
            "Epoch 774: Loss 0.0987\n",
            "Epoch 775: Loss 0.0987\n",
            "Epoch 776: Loss 0.0987\n",
            "Epoch 777: Loss 0.0987\n",
            "Epoch 778: Loss 0.0987\n",
            "Epoch 779: Loss 0.0987\n",
            "Epoch 780: Loss 0.0987\n",
            "Epoch 781: Loss 0.0987\n",
            "Epoch 782: Loss 0.0987\n",
            "Epoch 783: Loss 0.0987\n",
            "Epoch 784: Loss 0.0987\n",
            "Epoch 785: Loss 0.0987\n",
            "Epoch 786: Loss 0.0987\n",
            "Epoch 787: Loss 0.0987\n",
            "Epoch 788: Loss 0.0987\n",
            "Epoch 789: Loss 0.0987\n",
            "Epoch 790: Loss 0.0987\n",
            "Epoch 791: Loss 0.0987\n",
            "Epoch 792: Loss 0.0987\n",
            "Epoch 793: Loss 0.0987\n",
            "Epoch 794: Loss 0.0987\n",
            "Epoch 795: Loss 0.0987\n",
            "Epoch 796: Loss 0.0987\n",
            "Epoch 797: Loss 0.0987\n",
            "Epoch 798: Loss 0.0987\n",
            "Epoch 799: Loss 0.0987\n",
            "Epoch 800: Loss 0.0987\n",
            "Epoch 801: Loss 0.0987\n",
            "Epoch 802: Loss 0.0987\n",
            "Epoch 803: Loss 0.0987\n",
            "Epoch 804: Loss 0.0987\n",
            "Epoch 805: Loss 0.0987\n",
            "Epoch 806: Loss 0.0987\n",
            "Epoch 807: Loss 0.0987\n",
            "Epoch 808: Loss 0.0987\n",
            "Epoch 809: Loss 0.0987\n",
            "Epoch 810: Loss 0.0987\n",
            "Epoch 811: Loss 0.0987\n",
            "Epoch 812: Loss 0.0987\n",
            "Epoch 813: Loss 0.0987\n",
            "Epoch 814: Loss 0.0987\n",
            "Epoch 815: Loss 0.0987\n",
            "Epoch 816: Loss 0.0987\n",
            "Epoch 817: Loss 0.0987\n",
            "Epoch 818: Loss 0.0987\n",
            "Epoch 819: Loss 0.0987\n",
            "Epoch 820: Loss 0.0987\n",
            "Epoch 821: Loss 0.0987\n",
            "Epoch 822: Loss 0.0987\n",
            "Epoch 823: Loss 0.0987\n",
            "Epoch 824: Loss 0.0987\n",
            "Epoch 825: Loss 0.0987\n",
            "Epoch 826: Loss 0.0987\n",
            "Epoch 827: Loss 0.0987\n",
            "Epoch 828: Loss 0.0987\n",
            "Epoch 829: Loss 0.0987\n",
            "Epoch 830: Loss 0.0987\n",
            "Epoch 831: Loss 0.0987\n",
            "Epoch 832: Loss 0.0987\n",
            "Epoch 833: Loss 0.0987\n",
            "Epoch 834: Loss 0.0987\n",
            "Epoch 835: Loss 0.0987\n",
            "Epoch 836: Loss 0.0987\n",
            "Epoch 837: Loss 0.0987\n",
            "Epoch 838: Loss 0.0987\n",
            "Epoch 839: Loss 0.0987\n",
            "Epoch 840: Loss 0.0987\n",
            "Epoch 841: Loss 0.0987\n",
            "Epoch 842: Loss 0.0987\n",
            "Epoch 843: Loss 0.0987\n",
            "Epoch 844: Loss 0.0987\n",
            "Epoch 845: Loss 0.0987\n",
            "Epoch 846: Loss 0.0987\n",
            "Epoch 847: Loss 0.0987\n",
            "Epoch 848: Loss 0.0987\n",
            "Epoch 849: Loss 0.0987\n",
            "Epoch 850: Loss 0.0987\n",
            "Epoch 851: Loss 0.0987\n",
            "Epoch 852: Loss 0.0987\n",
            "Epoch 853: Loss 0.0987\n",
            "Epoch 854: Loss 0.0987\n",
            "Epoch 855: Loss 0.0987\n",
            "Epoch 856: Loss 0.0987\n",
            "Epoch 857: Loss 0.0987\n",
            "Epoch 858: Loss 0.0987\n",
            "Epoch 859: Loss 0.0987\n",
            "Epoch 860: Loss 0.0987\n",
            "Epoch 861: Loss 0.0987\n",
            "Epoch 862: Loss 0.0987\n",
            "Epoch 863: Loss 0.0987\n",
            "Epoch 864: Loss 0.0987\n",
            "Epoch 865: Loss 0.0987\n",
            "Epoch 866: Loss 0.0987\n",
            "Epoch 867: Loss 0.0987\n",
            "Epoch 868: Loss 0.0987\n",
            "Epoch 869: Loss 0.0987\n",
            "Epoch 870: Loss 0.0987\n",
            "Epoch 871: Loss 0.0987\n",
            "Epoch 872: Loss 0.0987\n",
            "Epoch 873: Loss 0.0987\n",
            "Epoch 874: Loss 0.0987\n",
            "Epoch 875: Loss 0.0987\n",
            "Epoch 876: Loss 0.0987\n",
            "Epoch 877: Loss 0.0987\n",
            "Epoch 878: Loss 0.0987\n",
            "Epoch 879: Loss 0.0987\n",
            "Epoch 880: Loss 0.0987\n",
            "Epoch 881: Loss 0.0987\n",
            "Epoch 882: Loss 0.0987\n",
            "Epoch 883: Loss 0.0987\n",
            "Epoch 884: Loss 0.0987\n",
            "Epoch 885: Loss 0.0987\n",
            "Epoch 886: Loss 0.0987\n",
            "Epoch 887: Loss 0.0987\n",
            "Epoch 888: Loss 0.0987\n",
            "Epoch 889: Loss 0.0987\n",
            "Epoch 890: Loss 0.0987\n",
            "Epoch 891: Loss 0.0987\n",
            "Epoch 892: Loss 0.0987\n",
            "Epoch 893: Loss 0.0987\n",
            "Epoch 894: Loss 0.0987\n",
            "Epoch 895: Loss 0.0987\n",
            "Epoch 896: Loss 0.0987\n",
            "Epoch 897: Loss 0.0987\n",
            "Epoch 898: Loss 0.0987\n",
            "Epoch 899: Loss 0.0987\n",
            "Epoch 900: Loss 0.0987\n",
            "Epoch 901: Loss 0.0987\n",
            "Epoch 902: Loss 0.0987\n",
            "Epoch 903: Loss 0.0987\n",
            "Epoch 904: Loss 0.0987\n",
            "Epoch 905: Loss 0.0987\n",
            "Epoch 906: Loss 0.0987\n",
            "Epoch 907: Loss 0.0987\n",
            "Epoch 908: Loss 0.0987\n",
            "Epoch 909: Loss 0.0987\n",
            "Epoch 910: Loss 0.0987\n",
            "Epoch 911: Loss 0.0987\n",
            "Epoch 912: Loss 0.0987\n",
            "Epoch 913: Loss 0.0987\n",
            "Epoch 914: Loss 0.0987\n",
            "Epoch 915: Loss 0.0987\n",
            "Epoch 916: Loss 0.0987\n",
            "Epoch 917: Loss 0.0987\n",
            "Epoch 918: Loss 0.0987\n",
            "Epoch 919: Loss 0.0987\n",
            "Epoch 920: Loss 0.0987\n",
            "Epoch 921: Loss 0.0987\n",
            "Epoch 922: Loss 0.0987\n",
            "Epoch 923: Loss 0.0987\n",
            "Epoch 924: Loss 0.0987\n",
            "Epoch 925: Loss 0.0987\n",
            "Epoch 926: Loss 0.0987\n",
            "Epoch 927: Loss 0.0987\n",
            "Epoch 928: Loss 0.0987\n",
            "Epoch 929: Loss 0.0987\n",
            "Epoch 930: Loss 0.0987\n",
            "Epoch 931: Loss 0.0987\n",
            "Epoch 932: Loss 0.0987\n",
            "Epoch 933: Loss 0.0987\n",
            "Epoch 934: Loss 0.0987\n",
            "Epoch 935: Loss 0.0987\n",
            "Epoch 936: Loss 0.0987\n",
            "Epoch 937: Loss 0.0987\n",
            "Epoch 938: Loss 0.0987\n",
            "Epoch 939: Loss 0.0987\n",
            "Epoch 940: Loss 0.0987\n",
            "Epoch 941: Loss 0.0987\n",
            "Epoch 942: Loss 0.0987\n",
            "Epoch 943: Loss 0.0987\n",
            "Epoch 944: Loss 0.0987\n",
            "Epoch 945: Loss 0.0987\n",
            "Epoch 946: Loss 0.0987\n",
            "Epoch 947: Loss 0.0987\n",
            "Epoch 948: Loss 0.0987\n",
            "Epoch 949: Loss 0.0987\n",
            "Epoch 950: Loss 0.0987\n",
            "Epoch 951: Loss 0.0987\n",
            "Epoch 952: Loss 0.0987\n",
            "Epoch 953: Loss 0.0987\n",
            "Epoch 954: Loss 0.0987\n",
            "Epoch 955: Loss 0.0987\n",
            "Epoch 956: Loss 0.0987\n",
            "Epoch 957: Loss 0.0987\n",
            "Epoch 958: Loss 0.0987\n",
            "Epoch 959: Loss 0.0987\n",
            "Epoch 960: Loss 0.0987\n",
            "Epoch 961: Loss 0.0987\n",
            "Epoch 962: Loss 0.0987\n",
            "Epoch 963: Loss 0.0987\n",
            "Epoch 964: Loss 0.0987\n",
            "Epoch 965: Loss 0.0987\n",
            "Epoch 966: Loss 0.0987\n",
            "Epoch 967: Loss 0.0987\n",
            "Epoch 968: Loss 0.0987\n",
            "Epoch 969: Loss 0.0987\n",
            "Epoch 970: Loss 0.0987\n",
            "Epoch 971: Loss 0.0987\n",
            "Epoch 972: Loss 0.0987\n",
            "Epoch 973: Loss 0.0987\n",
            "Epoch 974: Loss 0.0987\n",
            "Epoch 975: Loss 0.0987\n",
            "Epoch 976: Loss 0.0987\n",
            "Epoch 977: Loss 0.0987\n",
            "Epoch 978: Loss 0.0987\n",
            "Epoch 979: Loss 0.0987\n",
            "Epoch 980: Loss 0.0987\n",
            "Epoch 981: Loss 0.0987\n",
            "Epoch 982: Loss 0.0987\n",
            "Epoch 983: Loss 0.0987\n",
            "Epoch 984: Loss 0.0987\n",
            "Epoch 985: Loss 0.0987\n",
            "Epoch 986: Loss 0.0987\n",
            "Epoch 987: Loss 0.0987\n",
            "Epoch 988: Loss 0.0987\n",
            "Epoch 989: Loss 0.0987\n",
            "Epoch 990: Loss 0.0987\n",
            "Epoch 991: Loss 0.0987\n",
            "Epoch 992: Loss 0.0987\n",
            "Epoch 993: Loss 0.0987\n",
            "Epoch 994: Loss 0.0987\n",
            "Epoch 995: Loss 0.0987\n",
            "Epoch 996: Loss 0.0987\n",
            "Epoch 997: Loss 0.0987\n",
            "Epoch 998: Loss 0.0987\n",
            "Epoch 999: Loss 0.0987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import cm\n",
        "color = cm.Reds(np.linspace(0,1,100))\n",
        "theta = model.predict(t)\n",
        "plt.figure(figsize=(5,5))\n",
        "for x,y,c in zip(0.5*np.cos(theta),0.5*np.sin(theta), color):\n",
        "    plt.scatter(x,y,color=c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "1otorTlCz7u6",
        "outputId": "bd635fb1-be4f-4cd8-d59d-4ad148740f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.linspace(0,2,100)\n",
        "omega_measured = np.pi + 0.01*np.random.normal(size=(100,))"
      ],
      "metadata": {
        "id": "uR4Bd7St0Wx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(t, omega_measured)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "hOtXw8nO0g9D",
        "outputId": "d041dc7e-9ca8-4dbf-bb63-5de4c306d24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a3177f06e60>]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGgCAYAAACJ7TzXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACnzklEQVR4nO39ebxddX3vj7/Wns98MudkJiQECAQDRgyIoBIVkELLxeGqYK924GIreu3V3PtrqbfVRE0r9P68sfZSoLWYagvS2wqpKEGLzBAMAZnJPCdnPnte3z/2fn/WZ629xr3XtM9+Px+PPCDn7Jyz9l7D5/15v1/v11tRVVUFwzAMwzBMjElEfQAMwzAMwzBOcMDCMAzDMEzs4YCFYRiGYZjYwwELwzAMwzCxhwMWhmEYhmFiDwcsDMMwDMPEHg5YGIZhGIaJPRywMAzDMAwTezhgYRiGYRgm9nDAwjAMwzBM7PEUsGzduhVr1qxBf38/+vv7sX79ejzwwAOWr9+9ezeuu+46LFu2DIqi4Lbbbmt4DX3P+Ofmm2/2/GYYhmEYhpmepLy8eNGiRdi8eTNWrlwJVVVx991345prrsFzzz2H1atXN7x+cnISy5cvx/XXX4/Pf/7zpj/zqaeeQqVSEX9/4YUXsGHDBlx//fWe3ki1WsXBgwfR19cHRVE8/VuGYRiGYaJBVVWMjY1hwYIFSCRs8ihqi8yYMUP9v//3/zq+bunSpeq3vvUtx9d97nOfU08//XS1Wq16Oo59+/apAPgP/+E//If/8B/+04Z/9u3bZ7vOe8qwyFQqFfzwhz/ExMQE1q9f3+yP0VEsFvG9730PX/jCFxyzJIVCAYVCQfxdrQ+d3rdvH/r7+305HoZhGIZhgmV0dBSLFy9GX1+f7es8Byy7du3C+vXrkc/n0dvbi/vuuw9nn3120wcq86Mf/QjDw8P41Kc+5fjaTZs24Stf+UrD10lfwzAMwzBM++CUqPDcJbRq1Srs3LkTTzzxBG666SbceOONePHFF5s+QJk77rgDV1xxBRYsWOD42o0bN2JkZET82bdvny/HwDAMwzBM/PCcYclkMlixYgUA4IILLsBTTz2F22+/HX/913/d0oHs2bMHDz30EO69915Xr89ms8hmsy39ToZhGIZh2oOWfViq1apOS9Isd955J+bOnYurrrqq5Z/FMAzDMMz0wlOGZePGjbjiiiuwZMkSjI2N4Z577sGOHTuwfft2AMANN9yAhQsXYtOmTQBqIloqFxWLRRw4cAA7d+5Eb2+vyNIAtaDnzjvvxI033ohUqmkdMMMwDMMw0xRP0cHRo0dxww034NChQxgYGMCaNWuwfft2bNiwAQCwd+9eXQ/1wYMHsXbtWvH3LVu2YMuWLbj00kuxY8cO8fWHHnoIe/fuxX/5L/+lxbfDMAzDMMx0RFGpH7jNGR0dxcDAAEZGRrhLiGEYhmHaBLfrN88SYhiGYRgm9nDAwjAMwzBM7OGAhWEYhmGY2MMBC8MwDMMwsYcDFoZhGIZhYg8HLAzDMAzDxB4OWGLEkdE8tu54HScnilEfCsMwDMPECg5YYsTfPvomvv7gr/H9J/dGfSgMwzAMEys4YIkRI5Ol2n+nShEfCcMwDMPECw5YYkShXK39t1SJ+EgYhmEYJl5wwBIjivWApVipRnwkDMMwDBMvOGCJEYVyLbNSKHHAwjAMwzAyHLDECFESKnPAwjAMwzAyHLDECA5YGIZhGMYcDlhihBawsOiWYRiGYWQ4YIkR1B3EGRaGYRiG0cMBS4wockmIYRiGYUzhgCVGUKBS5ICFYRiGYXRwwBIjWMPCMAzDMOZwwBIj2IeFYRiGYczhgCVGcFszwzAMw5jDAUtMUFVVs+bnkhDDMAzD6OCAJSbI84M4w8IwDMMwejhgiQlykFIoV6GqaoRHwzAMwzDxggOWmGBsZS5VOGBhGIZhGIIDlphgLANxazPDMAzDaHDAEhPIll/8nXUsDMMwDCPggCUmNGZYOGBhGIZhGIIDlphg1LCwPT/DMAzDaHDAEhNYw8IwDMMw1nDAEhOMAQrb8zMMwzCMBgcsMcEYoLCGhWEYhmE0OGCJCbLTLcAaFoZhGIaR4YAlJjSUhFjDwjAMwzACDlhiApeEGIZhGMYaDlhiApeEGIZhGL+pVqfPmBcOWGJCY4aFS0IMwzBM84xMlbB+80/xRz98PupD8QUOWGJCo4aFMywMwzBM87x8eAxHRgt45JVjUR+KL3DAEhMajOPYh4VhGIZpgfFCCQAwWZweGXsOWGJCgzV/hQMWhmEYpnnG8mUAwGSxDFVtfy0LBywxoTHDMj0iYoZhGCYaJgq1daSqTg+ZAQcsMYE1LAzDMIyfUEkIACYK5QiPxB84YIkJFKBkkgnd3xmGaS92vHwULx8ei/owGAbjeS1ImQ46Fg5YYgIFKP1dKd3fGYZpH/afmsSn7nwKN33vmagPhWEwXtCCFA5YGN+grqD+XLr2d/ZhYZi24/BIHgBwcGQq4iNhGH1JaLLIJSHGJyhA6ctxhoVh2pWxuk4gX6qixJ1+TMRMcIaFCQJqa+6jDAv7sDBM2yFrBuT/Z5goGJOEtiy6ZXzDqGFhHxaGaT/GpCBljAMWJmLG81pJaGoaWGVwwBITRMAiMiztf3ExTKchawZGpcWCYaJALgnJ/9+ucMASE1jDwjDtj5xVGZ8GKXimvZGvQRbdMr5h1LAYrfoZhok/XBJi4sRYXu4S4gwL4xNaSYgyLO1/cTFMpyHvaMe4JMREiKqqmJCClAnOsDB+QZoV0SXEGRaGaTvkIIVLQkyU5EtVVKrawMMpzrAwfkFdQaxhYZj2RZ9h4YCFiQ5jwMyiWwYAcGK8gCfeONH0+G5VVaW2ZtawMEy7Igcp3CXERIkxYJkqtX8AzQGLD/zRP/0KH/nu49h1YKSpf1+qqKBYh635GaZ9YeM4Ji4Yr7+Oy7Bs3boVa9asQX9/P/r7+7F+/Xo88MADlq/fvXs3rrvuOixbtgyKouC2224zfd2BAwfwiU98ArNmzUJXVxfOPfdcPP30057eSJTQ/JBD9f96RQ5O5JJQsxkbhmGiYZS7hJiY0JBh6TQNy6JFi7B582Y888wzePrpp/He974X11xzDXbv3m36+snJSSxfvhybN2/G/PnzTV9z6tQpXHzxxUin03jggQfw4osv4i/+4i8wY8YM7+8mIsrVWvmm2TKO/O8oYFHVWuaFYZj2QTaO4y4hJkoaNCzToEso5eXFV199te7vX/3qV7F161Y8/vjjWL16dcPr161bh3Xr1gEAvvzlL5v+zK9//etYvHgx7rzzTvG10047zcthRU65rsRuNmAh/UomlUAunRRfL1aqyKS4ascw7UCpUkVemgHGXUJMlFDwnEklUCxXO9uHpVKpYNu2bZiYmMD69eubPoB/+Zd/wdvf/nZcf/31mDt3LtauXYu/+Zu/cfx3hUIBo6Ojuj9RUa5nQpqdzkoBSzaZQCapnRK252eY9sGoGeCSEBMl43XNyrz+LIAOdbrdtWsXent7kc1m8fu///u47777cPbZZzd9AG+88Qa2bt2KlStXYvv27bjpppvwh3/4h7j77rtt/92mTZswMDAg/ixevLjpY2iVcj1QaXZgIWlYsukEEgkF6aRS/zp3CjFMu2DMqHDAwkQJBdBz+3IAgMlOE90CwKpVq7Bz50488cQTuOmmm3DjjTfixRdfbPoAqtUqzj//fHzta1/D2rVr8bu/+7v4nd/5HXznO9+x/XcbN27EyMiI+LNv376mj6FVSi2WhOjfZVNJ3X+5tZlh2gdjGzNrWJgooZLQ3L56hqVUaftGDs8BSyaTwYoVK3DBBRdg06ZNOO+883D77bc3fQBDQ0MNGZqzzjoLe/futf132WxWdCvRn6hoPcNCAUtC91/OsDBMvDg2VhD3uxHa0fZla9LA8UK57RcIpn2ZECWhWoalUlXbfk1pWdFZrVZRKBSa/vcXX3wxXn75Zd3XXnnlFSxdurTVQwuNlkW3JU10C8gBS/un8BhmuvD6sXFc+LWH8PkfPG/6fSoJDQ3WFoiqCt0sF4YJEypJzqlnWID2H4DoqUto48aNuOKKK7BkyRKMjY3hnnvuwY4dO7B9+3YAwA033ICFCxdi06ZNAIBisSjKRcViEQcOHMDOnTvR29uLFStWAAA+//nP46KLLsLXvvY1fPjDH8aTTz6J7373u/jud7/r5/sMlFZFt8VKXcNSD1QynGFhmNjx+tFxVFXgBQuDSHmBeP3YBCpVFeP5Mnqznh6zDOMLE/UAur8rjWwqgUK5isliGTN7MhEfWfN4upOOHj2KG264AYcOHcLAwADWrFmD7du3Y8OGDQCAvXv3IpHQkjYHDx7E2rVrxd+3bNmCLVu24NJLL8WOHTsA1Fqf77vvPmzcuBH/63/9L5x22mm47bbb8PGPf9yHtxcOrfqwUIaFNSwME19oA3Fqsmj6/bEClYTS6MulMDxZwli+hPkDudCOkWEIyvj1ZpPoyaZQKBc7K8Nyxx132H6fghBi2bJlrmq4H/rQh/ChD33Iy6HEBlVVhcFbqz4s2XRC918uCTFMfKD7e2SqhEpVRTKh6L5PItu+XEoELKPcKcRExJgIWNLoqvt7tXvAwq5kLSJN70axSWdaCkzIg0VoWEqcYWGYuEAbC1WtBS1GSHTbm0uhN1ubCcbmcUxUTIiAJYWebD1gafPrkQOWFpF1Ky23NadZwxJ3xgtlvHZ0LOrDYCKgKGU8zcpC4wWtS4hGbHBrMxMVIoDOptCVqV2P7S4C54ClRcpSiqX1tmbWsMSdP/z+c7j8L3/OQUsHIm8ghk0CFhLd9uXS6BcBS3vvaJn2RWhYcin0ZKgk1N7XIwcsLSJ7MpRanSVkLAmxhiV2vHViAgCw58RkxEfChI28gTg10Zg5GdOVhOpeLBywMBFQrapi2GFvNoXueoaFNSwdjjxRuekMS0mz5ge4JBRnSFfE56bzkM/5SdMMiyy6Teu+xjBhUnO1rf1/LWBh0S2Dmnsg0fTwwwo73bYL+XpwmefBlB2HvCExKwmNSyJH0rBwlxATBSS4TSYU5NIJFt0yNeQgpdkAw8qHhQOW+KEFLHxuOg15evqpSZMuIRLd5lLozaV0X2OYMBmTBLeKoqArzaJbBgbRbasaFrbmjz10rvjcdB5eRLdcEmKiRM72ARAZlikW3XY2OtFts9b8huGHGfZhiSXlSlUEqJxh6TycRLdyGyl3CTFRMmEIWLq5rZkB/Mqw6GcJibbmJgMgJhjy0vllDUvnYSe6zZcq4n7tk7uEuCTERAAFypRZIdHtFAcsnU254oPoVpSE6hqWNGdY4ogcpOS5JNRx2JWE5MCkJyN3CXHAwoSP5sFSuw4pYJngklBnU6q27nRbKFt1CfGiGCfkgIWDyc6jULYW3coix0RCYadbJlImJNdlQCsJTRbae03hgKVFyj74sJDlN/uwxBtZt8LBZOdRNGRY5MGu43mtQwjQtAOcYWGigDIsoiREbc2l9r4eOWBpkbIPs4TYmr890JWEOMPSccgbiFJF1QkYxwq1TAoFKv31VHyhXOX7mAkdLeNXuw57OMPCAD7NEipxW3M7IJ8PPjedhzHjeWpC07GMGTMs9f/WvsdlISZcJqQ5QgDY6ZapUfZFw6LvEuKSUDyRdSucYek8ioYgVZ7YLFqa65mVZEIRiwR3CjFho/mw6LuEWHTb4cizhKqq3qrfLUUra35eFGOF3BnEbc2dR0OGRRLeijlCWS2z0sdeLExEaAELdQlpww9l7VW7wQFLi8iiW6C5LIuVNT/7sMQLveiWz02nQff2YHdtEZBbm2VbfoJam0e5JMSEzLjRh6X+30pVbet1hQOWFpFLQkBzQUaDNX+aNSxxRC+65XPTadB9Or8/B8CgYTE4i8r/P84ZFiZkjAF0dzopvtfOwlsOWFrEjwxLgzV/kktCcSSv07C0703PNAfdp3PrActJXUlImyNEdGJJqFiu4l+eP4hjY4WoD6WjmTCUhFLJhNgQT7bxs4sDlhZpNcOiqqomuq1nVnL1/7Zz6m46ojOO45JQRyHfp/P7swAMJaG8visD0FqbO6lL6IEXDuEPv/8ctmx/OepD6WjGDD4sANBDnUJtLALngKVFSoYMS8njQlauqiCdbjap17BwhiVe6EW3fG46Cfk+FSUhB9FtJ84TOjicBwAcG+cMS5QII8OslvGbDgMQOWBpkXKltQyLvFOnDIvsw9LOiu7phk5028ZpVcY7cql33kAtYHEW3XZeSYhKEay/i45KVcVU/fkkZ/w0L5b2vR45YGmRcrU1DYv8etKuUK2xqjb+fCY6Cjz8sGORNxbz+uoaFhPjOHmBoP8f7aCAhQI3zg5Hh24Qp1QS6s62v9stBywt0hCweM6w1C6eTDKBREIBoJWEALbnjxNGa/ZmPHeY9oTuw1RCwazeDABg2FF0W/v/TioJ0efAAX10UJYrk0zo1hLqFGLRbQfTUBLyGGAYbfmN/8/izvhg7AzitHfnIDYWqQRmdNcCllMmJaFeU+O4zhHdTnCGJXKMgw8J+juLbjuYBtFtkxqWrBSkJBMK0kml/n1eFOOCMWBh4W3nIFsPzOipBSyTxYrQmZlqWDpwYrMoCfFGKzLMypMA0MWiW8ZYFmhWwyIHLAB7scQRY4DCwWTnIJs79udSSNbLt8OTJUyVKuI5YOZ020nGcdROyz5F0WH0YCGorXmKRbedS8now+K1JCSlmmWyabbnjxvGujxnWDoHLROahKIoGOyqLQYnJ4oiIEkmFHRJjqIdXRLiDEtkGAcfEtzWzDQ63TZdEtJfXDwAMX40loTa98ZnvGGcqE7zhE5NFkUXUG82BUVRxL+hlPxYG2sGvELBG2cfo2M836inArS25ikOWDqXVkW3oiSUNpSEUjxPKG40loSmVzCpqir7/lhgnPdFwtvhyZKp4BbQMizjhTKqHdJRNi5KQlW+liJCXI85fUmIBiBOtHEAzQFLi5SqRtGtt5vUuHMj6O9xa2s+OprHX/z7yzrTrE5hOmdYRvMlXPrNHfiv//Bs1IcSS4xaMxLenposai63BpEjWfOrKjDRxroBt1Srqu59cjk7GixLQtOgrTnl/BLGjkrD8ENvF4Nx50YIe/6YBSzf2P4y/umZ/VAUBV/YcEbUhxMqxnMxnQKWn710FHtPTurM0BiNxgxLLRgZnixhZndjhxBQC25SCQXlaq2LqM+w451uTJYqkJMqhXK1odTNBI9Vxk8zjmvf4JkzLC3SILr1qmEpOWhYYlYSevLNkwCA14+OR3wk4UNOt1rLebyCyVb42a+PAqjZdnMqv5GiQWtGJaGTE0WtjdSwQCiK0lH2/MZuqOkU0LcT45ZdQiy67XiMolvPJaGKRVuzCFjisygeHctj78lJAMBbJyYiPprwydfPxUBXbbGaLg/kcqWKR145BqA2DiJO11xcMHbzDUrmcWPCg6Uxg9LXQRObjY6+3DAQDRQ4Go3jWHTLoFxtTYhJu3YrDUucFo9n3jol/n/PicmO24lTgEIdItPlgfzcvmGMTGkL6mQbP9CCokHDIpWExi2MugAt69IRGRZjwBKz7HCnMGFiYghoAUs766k4YGkRyrCQ/4J3H5b20bA8vUcLWMYLZZzoIL2DqqoiYBmoe3BMl3kpVA4i2nmaa1AY7QfciG7lr4UVsFSqKv7+sbfw0qHRUH6fTGNJKD7Prij5wVP78ONdh0L7fWPCmt8YsNT+zhmWDoaGH1L02rw1v0HDkiYflvhcXHLAAgB7OqgsVKqooIYwMg2bLhmWhw0BSzs/0ILCOPNLzBOaKGq2/FmzgIVKQuEELE++eRJ/fP9u3Hr/7lB+n0xjhmV63B+tcGqiiC/d+yt84Qc7Q8tIW/qwcFszQwEKXQy+W/PH5KafKlaw+8AIAGDprG4AwJvHJ6M8pFCRsykD9XLAdNCwHBiewq8PjyGhAP31bACXhBopVvSl2xnCOK5kKboFZC+WcDQsZDdwaHQqlN8n06hh4etoZKoEVa1lm7zqG5uFSj7GjB+Jbtv5/uaApUWoJNSdrl0M3jMsVtb88fJheX7/MMpVFXP7srjo9NkAOivDQsGJomj+GtOhJETZlbVLZmBufw5Ae9e4g0Lr5tOLbkfzJaH/MRfdhlsSoi7F4YnwRb7GnXtcNltRIgcHYWl6NNGtcfhhbVNdrqqxWVe8wgFLi5DottkMi7U1f7w0LM/Uy0FvXzYDp82uZVjeOtE5GRZasHKppFSui8e5aQUKWN575lxpOFr7B2J+U6wYAxbNFO7AcC2bYSa6DT1gqT8vxgplz5unVmHRbSNTJe0zCetZPmblw5LR1ph21alxwNIiRg1LweNDwsqaP24+LE+/VfNfuWDpTCyd1QOgszIsdB5y6YQIJts9w5IvVfDo68cBAO9ZNVfswNo5ZRwURg1LOpkQwcj+U7XA3Ux0S14YYWdYAOg6v8LA+B5ZdAtMFOQMS/CfR7FcFWtKn8GHJZ1MCKlBu97jHLC0iNYlVC8JNZ1hia8PS7WqahmWpTOwrB6wvHl8omNam/OSwV+uHly2+wP5sTdOIF+qYmggh7OG+qZFF0FQaBkWbZdKwlvSJhgXCCD8ic1yhjfs8RmNJSG+jnQloRA0PfI5MPqwAFolgDMsHQqlXeni8O50a6FhSTVXYgqC146NYzRfRlc6ibMX9AvR7Vi+jOHJ6W+IBWgallw6gVzMynXNQuWgy1bNhaIoIsPCGpZGxMwvKRNKwlsiTiUhoCYIDhPuEmok7JIQnYNcOoFUsnF5F263hfYMJjlgaZHA2ppjlGF5um4Yd97iAaSTCeTSSQwN1ASaneJ4S9mUXFrTsLRzl5CqqsJ/5b1nzgUAoWFp13RxkFAgkJEWARLeEnY+LMbFPCjk58+pkH2SGktCfB3pRbfhBSxmHWsA2r7sywFLi1REwFK7QHxra07Fx4fl6T01/crbl84UX6Msy54OEd7SwzebTooMSzs/kF87Oo79p6aQSSVw8YpZAKaHsVRQFEy0ZjN79AGLeVtzuNb8+pJQuBmWCcNiOR1E6a0yFXJJyClg0TYl7ZlF5YClRYQPS6bZLiGrklC9rTkGI9pJv3LBshnia7KOpRMggW0uVcswAe39QKbsyjuXzxKBSrvvvoJEiG6TWiZ0UCoJZZLadSETdklIFv0PT4WbYaHFclZvLZCLQ3Y4aiLLsJhk+4D2v8c5YGkRIbqlgMXr8EOLDEs2JovisbEC9pyYhKIA5y/RApZO6xTSlYRi1sHVDI+/cQIAcNkZc8TXuuvXnFx3Z2qYDSmdIZWErBYIMUsopJJQHDQss3uzANo7A+kXcmAQhh5ReLBkrDIsZB7Xnvc4BywtQj4sPaIk5O0mddawRHvTP1MvB50xt0/M0AGAZbM6y4tFJ7pNU0mofXeQB4fzAIAVc3vF14Totk0FeUFiJo6XRbdWKXgqCRXL1VDu5Si7hChgoVIZZ1iAqWI0olszPRUAdGdZdNvRlBoyLP74sMSlrZkEt3I5COjEDAsFLFJbcxtnWA6N1MzOSDwNaM6Y7ZouDhKjcRygF91aLRByIBNGWUgvug05w5KnDEvtc+EMS/hOt0YdkREti9qe54YDlhapGLuEyl5LQvWdW9JCwxJ1wCL5r8iQ6PbUZAkjHdDaLJfu2l3DMlEoY7S+uMyXAha6hrkk1Iiw5pd0KrLo1mqBSCYUIXQ0TjMOAl2GJUQNS7lSFYsglYSi3mzFgbA1LGMWtvxEuw9A5IClRYQPC5WEmmxrzjU43Ubv9ZEvVbD7YG3godwhBNRuiDl9tQfTnpPTP8tSkDIsFEy2a4bl8GitHNSbTenm33Sl21uQ54U9Jyawa/+I69fTfa1va9Y+O7M5QsbvhZFhkZ8/YXYJTUjXjFYSmv7XkROyViRM4zgrTVU3i247G/Jh6RIZlmbbmuOnYdl7chKlioq+XAqLZ3Y1fL+TdCz5sia61TQs7XnTHx6pBSxydgXQ2pon27S+7YVP3PEEfmvro651HgXR1m4uurUqCcnfC6O1WS+6DS/DQtqJTDIhArR21nj5RVRdQn1WGRYW3XYuqqqKkhBlWLzOErLsEoqBhoWMp2b1ZKAoSsP3qbX5rQ5obRYallRCG35YrrblaAIRsPQbAhay7Z7mJaFSpYp9J6dQqqg4Pu4yYDExjtN1CVksEIC22w2jU0juUjw1WQrt+qRyV28uJbLFnGHRa0VCKQkV7EtCPcLNuj3PDQcsLUDZFUAS3XpYxMqVqgh44mjNT22RMwwGWcSy2fWApQOEt7JxHJ0bVY2HT45XqCTUmGHpjGnNo9JQQDeLqqqqmuhWyrB0ZbTyoH2GJcSSkPR+iuVqaOLKcbFQJmNRzo4LsRPdtrk5JAcsLVCWdjPy6G45kLFDvqEbSkLp6DMslC6f0W0esHSS263swyLrjdox7W3WIQQA3enO6BIa1gUszuevVFFBe5BsUn+fkl7DSjMARFcSAsLTsWgOq2lN49WG94bf6J1ug/88JhwyLB0lut26dSvWrFmD/v5+9Pf3Y/369XjggQcsX797925cd911WLZsGRRFwW233dbwmj/90z+Foii6P2eeeabnNxIFpap2AcpGPW6zIvLrrJxuK1UV5Yh28ZRhGew2FxQus2ltrroM2vzgZ78+gv/7izfwz8/sx8O/Poqd+4ZxpJ5F8AvZhyWTTIAqZO2Y9rbSsHRltJbHMM9f2Mi6FTc6JDmLZrQfoNZmO9FtmDOajBm/sHQsVBLqy6a0Lro2vDf8ZjJkHxbKqHWZuC4Dcidge54b622BCYsWLcLmzZuxcuVKqKqKu+++G9dccw2ee+45rF69uuH1k5OTWL58Oa6//np8/vOft/y5q1evxkMPPaQdVMrTYUWGnGHpkjIsbgcg0gWcSihIJvQaETmAKVaqppM3g8Ypw7KknmE5Pl7EWL4kHtoPvnAIf/RPv8KfXr0a112wKNBjPDqWx6fvfhrGKpyiAFs/fgE+eM58X36PEN2mklAUBdlUAvlStS1bmw9ZaFho4riq1jqgui3cMsNCVVVMlfw/Djnr4GYRkbs7jPYD8/uzeOkQMNuibApoi0cYIu2oMiwTupIQzUFrv3vDb8IuCeVLjaVLmW4xrbkDMixXX301rrzySqxcuRJnnHEGvvrVr6K3txePP/646evXrVuHb37zm/joRz+KbDZr+XNTqRTmz58v/syePdvbu4gIcrlVlFqAQTGH2wyLGFmfajwN8oMxqhv/lAhYzHeP/bk0ZtUf1FQWOjySx3//p19hLF/Gz189FvgxnhgvQlVrn/8lK2fjnIX96MuloKrA8/uHffs9snGc/N927BQ6YqFhyUllyTiUhb6x/WWc95V/xwsH3Lcfu0EXsLi4tyhrkU4qSBg2FhuvPAtfvuJMvKc+8doMulbC0A2QkSVtgMLKsIyJdtq0VM6O/hqKkkpV1QXEYWRY6DM3m2sFyNb87Xlumt62VyoVbNu2DRMTE1i/fn1LB/Hqq69iwYIFWL58OT7+8Y9j7969Lf28sKAMSzpR+xi9utNqE2AbL65UMoFU/aETlY7l5ASVhKx3j7KORVVVfPneXwlTsjBEhhQwzO3L4u8/fSH+9Q8uwacuWgbAX6MuYzeXNrG5vXaRhXJFdMYMDehb1RMJRWQD4iDKe3bPKZQqqv8Bi0fRrTCNSzXep2fM68PvX3q65QIBSMFtiNb8c+rmbWHNE5LFnnRvdHqGxVh2CaOBQmjtTK5VoAOHH+7atQu9vb3IZrP4/d//fdx33304++yzmz6ACy+8EHfddRcefPBBbN26FW+++SYuueQSjI2N2f67QqGA0dFR3Z+wKRt2M+l6VsRtSaho0dJMZCL2YnEqCQFSa/OJCfzjU/uw42UtqxKGyFAWwxK9Wf/TnoWGDEt77iKPjhYA1K4ts8xZnIylqAzndwvmiJR1cFUSopZmi/vUCS3DEsYOu/Y75vbXApaRsDQsImBJxqJhIA5MGp4/YXweeRO/IBkq+3aMD8uqVauwc+dOPPHEE7jppptw44034sUXX2z6AK644gpcf/31WLNmDT7wgQ/gxz/+MYaHh/GDH/zA9t9t2rQJAwMD4s/ixYubPoZmIdFtKlkLWISdvmsNS+NANZmo7flFSajHWlBIM4V++fpx/Nm/1q6Dd9cnAIeZYZE7d0ghP+5jwGL8Pdk2zbCQfmVoIGfqrSMGIMbggZavByp+19u9dgk5bSycCHP2FLU1z+2rlfvCyrDQvV7rEtLmqlWmsXjbCWPQH8bmpmCygZOhTsBSRY187EszeL4DM5kMVqxYgQsuuACbNm3Ceeedh9tvv923AxocHMQZZ5yB1157zfZ1GzduxMjIiPizb98+347BLaIkVM+skO7EtYalZP8gjNrPgGr9thmW2bWS0KOvncBEsYJ1y2bgc+9bASDkgEVKgVIbqb8Bi/5BIBahNtOwkAfLPIPgluiJkU8DLfB+ByyndBoWFyUhh42FE11i9lR4GpZ5/VQSCifDIlvCy5uHdlwU/aIhYAl4c1Opan5BOYtrVW4OicM97pWWW0+q1SoKhYIfxwIAGB8fx+uvv46hoSHb12WzWdFeTX/ChkS3pDVJp7yVhApiAqx5NByleE1VVbETdVMSAmoP5i3Xn4eBLjLKCqEkVP9s5BuxJwAlfL5syLCkow0mm+WwhQcLEacaNz1Q/c72DHssCbWeYQmvlZQWLMqwhO/DktQ9z9otoPcT4xDRoJ8VcnBolWHJpBJiYx2HLKpXPPULbty4EVdccQWWLFmCsbEx3HPPPdixYwe2b98OALjhhhuwcOFCbNq0CQBQLBZFuahYLOLAgQPYuXMnent7sWJFbRf+xS9+EVdffTWWLl2KgwcP4tZbb0UymcTHPvYxP99nIFhlWFyLbkv2tXHx8yIoO4zmyyKda+XDAugDlv9x5ZlYOqtHdKGMF8pQVdW09OAXeRNBJJWE/LRCF7Xh+u/RzLHa64F8yMKDhdA0LNE/zOiznfB5ttGIx5KQJri2FtbaoWXjgt9h0z1LGRa3s5JaZVwqCSUTCtJJBaWKGnpAX6pUsevACN62aLChoytswi4Jyc8iu+C6K5NEcaoai02JVzwFLEePHsUNN9yAQ4cOYWBgAGvWrMH27duxYcMGAMDevXuRSGgf1MGDB7F27Vrx9y1btmDLli249NJLsWPHDgDA/v378bGPfQwnTpzAnDlz8K53vQuPP/445syZ48PbCxbKsJDoNiMyLG6dbq3bmgEpwxKBcRw96LqkYX9mDHSn8aUPnomJQhkfv3ApAK0kU1VrN62V66If0C5cTkPT7/crw6KqqklJKLzODz8h07ghi5JQnOz56TP3XcMy6bFLyCfRbdDBrbzDnisClpAzLPV7L5tKolQph54d3vbkXvzx/btx02Wn40sfjNaAlAICRal5GwUdvNGzKJVQbH27ejJJjEyVDKZ2FSQURWy+44qnleSOO+6w/T4FIcSyZcsc5+ps27bNyyHECgpMSHSb9qphcUg1ZyNsDxRzhGyyK8RNl52u+3tXOolkQkGlqmIsXw40YMmb+A70iC4hfx6WBV2qNaH7fe3WuqllWBqnbwOSsVTEAYtcjw+0JOTi/DltLJwIqySkC1iE6Db8LiGg9lmNF8IXpb9+rOa6/b3H9uDm96ywHUoZNBT09+fSGJkqBf6sMOuYNMNY9n345aP4wj/uxKIZ3fh/f/CuQI+xVeIdTsUcSr8afVi8WvNbalgibGumSc12HixWKIoiHhRB61joJu3SBSy1/x8vlH2xmDeb+USitnbLsFiZxhFahiXakpB8zY/7WBKqVFXhE1T7Pe41LK2LbgPWMFTkgKXe1jxVCmXMgjxLCEBk9vyUjRsrlPFPT4ffiCFDAQFt+oL+LArlxmyzGaKLMl/G7Q+9iv9y11M4NVnCrgMjoegOW4EDlhYgcS1lWDIefVicUs1eAyA/cdPSbIcY+BawBXTBpK25L6sd86QPu1r6HQml5nYKaOW6dmprLleqODpWE8jHXXQrl6SMfhatIOtXAG8loVYzLIGXhCra84Q2GlUVGA1hEWosCUXjxSJn4+5+bE+kM7Go5ELnIvCSkI3BoQxtSv7k/hfwrYde0Y01oQxsXOGApQVIdJsyaFj8sOaXvx5FJ8opFy3NdtBcoaBbm6dKjSWhXFobk+CH/kFOtZKAWHPzbJ8My/HxIipVFcmEgtm95qMy4mIcl5eueT81LEYRqjfjuNZEt2GVhDLJBDKphBi6GLSOpVCuiN/dWy8pZiISpctl4DePT2DHK0dD/f0ydA/RRO/gAxZ70ziCyr4HR/LIpBL4xn9agzPn99W+NjwV6DG2CgcsLSDamo1dQm4zLA6DqqL0YXHjcmtHX5MlIa87IuOMH6BWkhKdQj4ETGY6mVwLbc35UgWvHhnDrv0joe4AD9Vbmuf1ZRuGbRLdYtZItCUhOcPip55m2JhhcTNLqMUMizz80EnT1wrG0hXt7IPWschBApVjo9J40XVLI0PufPStUH+//lhqnwt1WVaqKsoBNlCYeVKZQfPfFg524Z9//yJ8+O2LRcY17hmW9hiLHFNKhgyL8GFxq2GhFG4yhhoWh8GHToiSkIeA4c/+9UXc++x+PHjLuy2NzYxYCc36simM5cs+ZVjoQaAtWF7amlVVxbd+8goee+ME9p6cxJFRzbfoLz98Hn7r/GAnWhOHHVqagRhlWKTPdcLH9viRyWZKQq2Jbsmzp6rW7vlm26OdKFW0DAtQWygPDE8FnmGhe6wrnRSbt6iyw6R3+t13L8cf/+gF/OLV43j1yBhWzusL9TgATQcmb/oK5aptB08raM9C+5//h+9biTPm9eG6CxaJ7M/QYE2Ef4gzLNMXIbo1Ot36lGGJVsPiPPjQDuE26yFg2fHyUZyaLOH5fcOu/42ZNT8gdwr5WxIivOgS3jg+gb/62Wt46q1TIlihtfflw/Yzs/zksIPgFohPW7P8uZar/vl5DE95Lwm1KrqVr80gNU9GTdyMkDIstCmRuwGzIel2jFCGZdW8Pmw4ex4A4M5fvhXqMWjHohfdAsE+y50mNROLZ3bjd969XAQrALCgTTIsHLC0QIPoNlX7r9sMi7OGJQYloSZFt7057yUhEu55ycpMWaRBe30U/Wq1Yb1OBnB3bo5LQtf7b74Yz/3xBnzh8jMAhOeTAUgZln7zlmYA6App/PwjrxzD5gd+bTlrxriw+3U8p+oTyLs8lPRaNY7LJDVNVZCaJ1oMSRhOpYigrzG6b2mTAmjZyNBFt/UMS082hd+++DQAwL3P7g/NQE+GBP892ZQ4J0F+Hk5zhOygye0csExjylWD6NYmwzKWL+EXrx7TaRYc25ppUYzCh2Wi1QxL7WE56iH4oGyMlyDH6ib1c2KzWRZHG37ovADRDndoIIfzFg9iRk8Gg/XdjbFrJUjkwYdWdNc/Rz+6q+z42r+9hO888jqe2XPK9PtGgapfwlvSsFCWyU0A0WqGRVGUULxYtC6h2u+iDEvQi7WYI2SSYYmqrbknk8KFp83EWUP9yJeq2PZU+C3OlKXsziSlzWdwn0e+hdLl0GDtfjg4wiWhaQsJqFIufFi+9uOX8Mk7nsSPdh4QX3Nsa07GQcPSWknIbbakUlWFuNJLhkWbJWQoCfk4TyhvIrr00tZs1nE1WJ+3ZCxRBIkrDQuNnw+4Hf34eC3rNGoRsBkDQb/M40bq1zX5lLhJ0beqYQHkEmJwm49SQ0modo0FPbGZspgkuAVkjVd4m61KVRUBYXe21tH32xcvAwD83S/fClTwagaVp7oyqVA0PWYNCG5ZQBmW4XygwvBW4YClBUSGxeh0a3Jj7D9Vi1wffOGw+Jpba/4ofVhmtphhGS+4e1jKk5W9+EZYKeP9LAkVTFun3e+YTk5QeU37LGlAZJgloUOj9oMPAblLKLggWR6saZVxCDrDQqJubyWh5h+XXSFoOui5k60/hwZC6xLSm8YBcsk0vM2W3NlG2Z7fOG8BBrrSODiSx/P7h0M7FkDKsKSTWsASpIbJpejWDNrETJUqoWZ9vcIBSws0DD+0ybDQgvzoa8fFTezamj/kgCVfqoid0WCzxnEe24rlgKUZDUs2yJJQ/fOXgyIvO+Zhk44r0hdYZRj8RlVVHBmpZTXsOrCE6DbAhXWsoA3WtBL3Gks1frndUoBIwwHdLKittjUD2uYj0JIQaVjqWroZYWlY8o0aFq1kGt6zi4LshKKdq1w6iXetnA0AeOSV46Edi3w83ZlkKCUyrSTkPcOSSyeFCPfgcHx1LBywtEDJcvihScBSv6knihU8/Vatbi8ehBYpvKjammlHlkooIvDwiteSkNxN5KkkZLGrEPb8PviwmLnpipS3i3MjSkI9ckmori8IKWA5OVEUO3C7gIUyAUH6sMitxVa/x7iw+1WiasiwuJol1JroFggpwyIZxwGShiXgsqNZSSiKDIvQr2RTuhb4S1fWBun+/JVjoR0LoAUsXZmkVN4PsiRk33XqhObFEl8dCwcsLaBlWAyiW5OLUt7pP/zrmvtiwfCAMZKJSGmvCW7TTXtfaCUhdwuNLLRtpiTU1ZBhod/f+gPTrDbsxRiL5jLJGhYqCU0WK6GU/EhwO7s3aysepdbUfKlq2cHTKvKO30rca9yZu72OnH937Vx4KQm1KroFwrHnL1T0x0lZPLqfg8KsJBRFdlh0CGX0m6xLzqhlWH61fzjUbiEKxnuyKa2BIsgMi0vjOCvaoVOIA5YWsBTdmmVY5IDlZQpY7K2UsxH5sNBN3WyHECBnWNw9LMeaLAlZdwnV/h6cD4v7B5CZCV9fLiW8WMKoGR920SEEaCUhILjyhbzjtyoJNWRYfNLUaCWh2udQrFQd3Yb9Ed0GL0LVRLe1czgYUpeQeUkofGt+EmZ3Z/XPgqGBLqyc24uqCvzHa+GVhUSGJSwNS9n8WeiWBYOcYZnWWIpuy/oHoKqqOnvx149NYO+JSc04LmYaFq2rpTn9CqBpSNy2NculG7cZlkpVFcGh8SYVE0l99WExa2turksokVBElmUkhE6hQy5M44DatUiBVFBloVO6kpBVhsWoYWn9WGqTmvUaFsDZ6NGPDEuYolutJFS7viYCzuKNi1Zif0ZXNAtdr70mZex3n1ErC/0iJB1LRTI71Lc1h9El1GxJSOsUiiscsLRA2aXTbaGspddXL+gHUMuyCFW/Q5dQVBqWVjIs/fWSULFcdXX8zYhu5Ye/8Sbt9TNgKTemWrUds4cMS4/+8wyzU+iIMI2zD1gURRFeLEG53Y5IO36rLE5DW7MP53EsXxKTaef2aZ+D067XDw1LNgwfFhFY1SLO/lxaGNYFmWXRJjXLJaHwPaSo/CtnCQkKWH7+6rFQ2nbl89yta2sOsiTUWoaFsq9x9mLhgKUFSFxrFN0Wy9a7w6vWDAGoBSxahsVCdGujiQkSTXPRQoZFSg+7Eb7KpSO3ZSRdwGJsaw7Aml/OsNDvKzsMNKtUVVHyMXraDIoMS/AByyEXHixEt/jsAioJSQGaVVBEnzndU36UhOj39mSS6MokxX3rJJwWAUuTO1dAu16CLAkZRbdyFi9Icfe4qXFcBG3NkmmckQtPm4lsKoFDI3m8dnQ8+GOpZ3sUpba5yXpwxm6WVkuX7TAAkQOWFhCi24S+JERDEQlaNLszSVx+Vm2+xWOvnxALs3OGJaKSUE/zGZZkQhEpYjcZEzmoyZeqpp1WRvJSqj5hmD7sZ0lI1IaloEhevOzOz8iUtqsfNASAA0JjEIKGxYUHC6G1NgdTEpIXT8suoXqAMqe3Vrrx4zwaM4duswDGQKAZyNgwyJJQqdJYuhLzhCYCzLDkGwMWulfCzLBQ2b3HpCSUSyfxjtNmAqiNhQiaKUm/oiiK2JQGuflsxTgOABYMaqLbuJrHccDSApqGRT+h1HhRjkvtdivn9mLhYBcK5aq4wSwzLBHc9IDsG9J8wALI84RcZFgMC5Kbf0MPhZxJwEe/208Ni050K50zu0WITOP6cikR0BJh7H4JLxkWrbU5+AyLpYalvluc1Zupv67180ifMwWObtP0TuJ4N+Q8jHJoFjPn7IEQ3G61klC0GZYJk/ZqmUtFWSh4HYvswQKEM71aE902d53O689BUWrr14kAA9xW4IClBcqG4YdahkV/UVJqvbfuD3DZqjm671ta80fsw9JKSQjQWpvHXLjdGstGbgzV7HYUckmo1d2CmZgtkVBceSvYBX+iJBRwF4eqqlKXkPXgQ4Iesm4DlsMed2QjLrqE6DOfVc/y+dGePjJpDFjcCSGd7Afc0JUJT3QrB8ZhzBMyLQlFYBwnuoRMSkIAcEndj+WJN04E3r0ke7AAcjYvvm3NmVQCs+sZzcMxLQtxwNICDcMPLTIsxsj/Pavm6r5v3SUUkYZFPNhby7B4MY8zvsbNvymU9Q8FGXp4VtXWhY5WrdNZF8JbM1t+ghbOoDUsY4WyeIA6iW4B7YHvRnR7/84DeOemn+KO/3jT9fG46RKaqn/ms+oPUD+0SKJdv27a5zYLoGlYmhfdhjL80CTDIiY2B3SNqapqGrBEYs0vTWo244x5vZjfn0OhXMVTb50M9Fg0W/7asWRD6Jpq1TgOABaQ8HY4nsJbDlhaoGThw2K8KMcNYrCLVszS7dasfViiaWv2rSTkwZ7fWLpxI7wVqniTHUV3Jinac1stC4kuIcN5crOLHLZpEQ+rJES7pYGutGlwZ4QyLG4GDj63dxgA8PLhMdfHM+yiS4h2olQS8iVgqX/OVCZxo7NQVdUXDUsYwwDNjnNGwPOE5A7IXhNr/nCN4xrbq2UURcEldZv+oF1vJ8Tgw/BKQsJ+oYVutvkxF95ywNICRqdb+m9jSUi/A+nOpHDh8pni+1YPQrrInTpR/MYPHxZAa212E3wYNSxu/FuEhsUk4FMURZrY3NouzyrV6mYXaTdEMqy25iN1DxbZe8QOIbp1kWGhYMiL3kXOKDkZx83uqWdY/NCwUOaw/rm7EbXLFgWt7FzDKAmVTGwSxDyhgNxuaTOiKBDt8PIxRGEcZ5VhAaT25oD9WKaEANgYsASvYWpWdAtoJeO4tjZzwOLA3z++B99++DWR2pexFN1WLDIs0o303jNrZaFkQhH/3oic2nUyt/KLcqUqzLX8Kgm5aWser/9OEny6MY8Tw74sblDhxdLiPCEt1WoMWJwzLCdtPG3oa0GXhEanau+fSiFOdHmY2HxkrBawuA0oVFU1iG7N/13ekGGZ9EHDYswcullE5HJsS063qWhKQkFPbJazx3KnXjTGcfogwYx3rZgNRQFePjIWqE5Dc7mt3UsZlx1prdCqcRwgud3G1DyOAxYHbn/oVXxz+8tilypTrlJJiGYJ1W6UUoOGpbG2+r4z5yGhALN7rRcROVIOqmPDiF0brleEhsVFOp92akP1G8ZNGcnJKEkMQGy1JCRSrcaSkPMARNrZzjSZeh2WhoWCP9k63Q4volsypHMbUEwUKyLQB6wXcNqhzvKxrdlYEnJTtpC/10pJyMvsqWYxF90Gm8UzZo8JOcMSVovsuLCPsL7OZ/RksGbhAICaiVxQTAoBMGVYgg3gVFVz1m2lJKTNE+IMS1tiV3ukkpDoEqo7TBqzIRPCMlq7kJbM6sb3PnMh7rhxneXvTiYU9NcXmTC8OgCtHGTWhusVGobmpiRED5uFdS8AdxoW2sWYH6df5nFW3UjaImQjurXJsGgloYCn6XoMWHpEwGL/uVWrKo6OFQC4z7AY/UBKFdXUc4c8dqhLqFCutlwWbSgJudj1yq3CzQ4CBSQflhBKAmY+LEFNbKaNRW/OGLDUrqGqCl2AGiSTUjemHVQWuvfZ/YEFU1OWbc3BnH95ffIjw3KQMyztidApmCxKDaJbyThOHqhmVhICgItOn41z6tG+FdRdElRK14hfgltAWyCd9CiVqip28wsGKGBxk2GxN0ryy4vFyt8g50ID4aqtearkOICvFcbEcDp3GTO3JaETE0WxGLnNAFI2aabUNWX8t5WqJnSlNksAunlczTAypS91uukSouPIthi8i5JQgJnSkmGWECBNbA44w2J8trk1VvQTLcNin2H48NsXI5tK4PE3TuJfnj8YyLHQFHIhug3YBFQ/pqT1DMuR0Xygz6Rm4YDFAdEJYnKhVaoG0a20sylVtdebOUG6ZTAEp0oZvwS3gHsNixxQaCUhDz4sFilQEt22ErDIqdaGDIsLMzCtrbnx8+yvByxVFRgPaNAgIAcs3kpCTourXCZ1m8WiLMec3qywxjf+HjmA6MulxALcaqZMm0LupSTUumkcAORIdBtghsVMwyL7sASRTaB7q8+iJASEJ7yddCG6BYDFM7vxB+9dAQD48397yfWwVS80ZliCLQnSNZxMKC1lxuf2ZZFQalmx4+MFvw7PNzhgcSBrl2ERPiz6DAugF+tZ7ULcMDPgGrQRPwYfEn0uu4To+5lUQpQASChqh6ZhsS8JtRKw6FOtVj4sbtqaGz/PXDopjn0kwPNLD2QKkJzoclkSkgMWtxkWKk0Mdqe1IYuGe0sOYHLpJLqz7o7Hjqo006mhJGTXJeRDSzMgZ1jCbWum4KxUUVvOUJkxZqFhqdnRhztaxM6a38jvvHs5ls/pwbGxAv5i+8u+H8ukwcQu6JKQtnlr7TpNJRNiMOjBGLY2c8DigL2GpR7VJkl0ax6wmBkruYUWupOhl4T8y7A4lXfkXZoXd1xxk1qkgKkk1MrOXD9g0VASEjt084dQtapqbc0Wc5mocydI4a3XDEuPy5LQYTnDUnTnKDwsuc3mLAKjvLTw1mZSUeDZ/MN+LF8GZbgHjNb8NhkAP0zjAPvSsl8UTWYJdaWT4u9BaKXsNmNhuLsSpUpVPHOtfFhksqkk/vyacwDUOkF37R9x/Df/+6evYv2mn2LfyUnH12pdQuGIbq06GZthSHQKxU94ywGLA3btedrww9rHmEgoomNIHoCoiW5bKAmFFLD45XILSCUhh4BhXFpQvbjjCkM3q5KQDxkWehCkTNrPsw5tzfIiadVxNRhCBk0T3boLQt12CR0Z1VLGqurOFE12m7UqPRn9dajbq5XAkzI73ZmkWDzcuI8KDUuLO9euEEpCJZOSkKIogXYKjdsEw073h5/IXWp2XUIyF62YjWvetgBVFfj//WiXKPGbUa2quOuXb+HQSB7P7j3lfDzGklA6WNdyvzIsgKYj5AxLG2JngEQ6FeoSAszt+c3amt1C7bBeNCzHxgr45B1P4Me7Dnn+ff6KbqkkZL/QiLRyLiXKFu6GH9q3Nfvhw2In7HUyx6Igs0daJI30C7fb4AJSrxkW1yUhwwPNTWAoZ1ishiwaP/MeH7q9jB1CgLuSEGXPrOZ9uYWC6lIlOBNIswwLEKzbrV32OEx7ftoUZpIJT+fqf151FvqyKTy/fwT3PLnX8nUvHR4VAwHdlD8nQ3a69cM0jqCJ7pxhaUPsUnlG0W3t/xvN47QuIe8Xk5Zhcb87+sWrx/CLV4/jH57Y4/n3kUjUzDfEK3KGxW73MiaJkkVnkZvhhxaW+YRoa25B+2D3O5zMsexamgm5UygohIbFZ9HtYYM3kRuNybDUqWOVyckbOiz8OI+aB4t2LtzoCkgk2WqGRV5IzAT8fkDXoVF0SVk8M/PLVrHqgATCteenYLbb4zN2bl8OX/zAKgDANx78teXG8NHXNGdcN4GzcLoVGhb78nGrCK8oX0pC5MXCGZa2w+6hJnxYEtrHaJ5hab4kRNoHL/VnWgCaaaH0syQkv1+73bfWRZV2nZUBtNp4l6VxXOvaB1EbNsmQ5ByGHw476FeAsEpC3tqaRSDhoD0wmim6GYEgZ1jEkMWSQcNimBElZhu1cB61UpScYXHu3LDKWngljK4ZK4EwDbwMwtl13MKHBQjXnn/CECB44RPvXIoz5vViLF/GAy8cNn3NL17VAhZ3GRYLHxaLa23jvbvwmbufajr7ZmVu2QwiwxJD8zgOWBywc6gk34OkZEmdMWRYqpLHSDMloWZ2R3TxNrOz8bMklEsnxedhG7AUtAwAZViKlarjg87J6VYrCTUfDGg7l8ZbxWn44ckJbXG2YiDgDIuqqk20NddFtw4BgjFgcZNhGZnSAocukcnRf35TBjG1nyUhub3cjTdGwSZg9UIioXXNBOHFoqqqeOYYF635A8HtmK3amoFw7fknW8hiJxMKfnPtIgDAAy80ltHzpQqefFOb7uwm0ydEty58WCpVFd9/ci8eeukoXjrkfoio7hgtvKKaYSjGAxA5YHHAzn69LEpCjRkWCmbki7uVLiEvO3B6IDbzoDg16bzIekET0Vofv+yW2ZtJiSnLTlkWsbA5Ot02v0CI2rBNhsUqzesuw1LvEgoowzJVqohynNcMS7Fi7S5bKFfEtULuxG7aZunfDOg0LMYMi15AqA2xbD1gGejyWBIyMWNrFm0B9z9gqVRVMVLDmA0S82EC2DHbl4TCa2t2Y8tvxxXnzAcA/PL1Ew1loWf2nNK9BzdjKOjZRMcjb2SNhmzyGrFz/7D3g4eziaYXFgxq5nFhDt11AwcsDmg+LNZtzTrRbVJfEqLFMintsLwgSkIe3FApuPL6YKwNpiOjs9YzLICWKrYLPmQNSyKhiEDDyb/FqW7rdZbQtx9+DX/w/ed0ehu7gWJOww+FaZxNtmogYNEtfbYJxV27J6DtCgHrstDReodQJpUQO7JJL6Jbmy4ho4ZFZFhayEzI/i+EK+M4mwybVyhAC8KLRdbMGQOWoRAyLGabsTBLQpTRaGZTCADLZvfg7KF+VKoqfvLiEd33/kPSr8i/y/54DLOEpGdUw3Bc6dn4q33Dno6bsNtYeWV2bxaphIKqCjF6Iy5wwOKA3UNNZFgkDYuYJ1R/vTbNNNnULBJ6wFaqqitdB6A9EL26Kk4UK6Id2w8fFsBdhmW8oK+D99czAU6W/nkHDYvbtmpi647X8f+eP4jnpV2O3c7FKcNyysY0jtDmCQWTYZFbmt1ef+R/AliXL0hwO78/5zqgUFVVKwl1ayUhY1BkdDDu9aGtecSuS8iFhsUPbYDQPAWQYZE1c0bRLQWUQcyHsWtrDrMkNGEIEJrhynNrWZYfG8pC/1HXr5y/ZBCAuxlbtIkxdgkBjdeb/Hx6vskMS8Eh2+yFZELBvP546lg4YHHAblEi0W3SLMNCJaEWBLdALWCim9BtWyKlI73ubCgVmkklLIMAr/RlnUW04wZRqJsgB3AzrVkrJTiZmpUrVfHgeOPYhPh6weZ3ZB2s+U/Z2PITQU9sHvWoXwFq3h1OXiykX5nXnxWZLKcH+aQuILbLsOgf9pRWby3D0ljqdDNLiM5/q6JbQM7IBRewKIo2PZ6ggOX4eMF3H5C4GMe14iZOXHHuEIBaRxAFuKcminjhYM1UbsPZtYDG6TqUnZvpGk8lFNBpMV5v8rPx1aPjTflGaaJbf57bcR2CyAGLA3adBOTDkk5Y+7D4cSN59VFoVnRLu/yZ3ZmWJtPKuDGCI1dbEu65NY+zK9cA2mderqqOn4WczXnj2Lj2O2zbmu1r9KdcCJiDdrql9nC3+hVC68wxPwfUcTKvP6cFFA61fQoaMqkEcumEJu41BDpGbZIfU7ep1KnXsLiZJeSP6BbQApYgRLdFSWtjvHdn9mTEc8kolG6FiUJZeCiZ6bTCbWumxobmz9Ppc3qxal4fShUVD71UKws9+vpxqCqwal4fTpvdDcC59CkH+ZQlrI0qMP885ABFVYEXDji77hpxGlPiFU2ozRmWtsJKmCeL3GQH1LSY2GwoCbUSsJB5nNsMiyS69TLw7ORkY52/VdxoWIzDIftdziByO/wQcC4Lyb4vcobF7nc4DT+0myNEBF8S8p5hASC1HFtoWOq17fn9OaGNccqwUMZpsKtWnnJrHNftUYtkxrDJUE9Ps4R8LQkFoGGxOU5FUaSykH8L0IH6z+rPpcR1LBPGOAJCDD5sUnRLXFEvC1G3EJWD3rVytphi7pRhEaZx6SQS0mbWKqNnNLZ8vgkdS6Gsv2da5bTZPQCA//f8IVsPrbDhgMUBq3a0sjSNWRbdZo0ZlhZs+QmRYZlwt6jJi4xR4GWHny3NBAUf4zazgcYMGhbXGZayvnRgJJlQHDMFhJzheOO4lGERMzpM2podhh+6CQBprs1UqRJI9wh9hm5N4wirYILQZVhcdmONGMoywq7eOPzQwum2leGHsmEdoWVP7WYJ+edv0RVkScihm4kCFqPZXyvQTJ3FM7tNvy+s+UPpEmreOkLmynpZ6OevHMdYviT8V961crYIzKdclD6BRj2NJkI2Zlj0z8ZfuZhrZMTPWUIA8Ml3LkVfLoVdB0aw7SlrB+Cw4YDFgZxFSagszQpKmxnHiQxL66lKryUhOWDxMsfDjebCK26CD6Nwj8oXdm63pUpVRP52yni384TkEfNvnZgUP9uuNmznXil3XNm1NfdlU6K2HURZyOscIaLb4eFMC9+8gZwIxp0CCrlDSP4djRmWeiBKAYvLkpMV1ap2Lsw1LGFlWILXsFgdp5gP46MmQQQsM8wDllyIGhZjV06zrJzbi+VzelCsVPG3//EWDgxPIZ1UcOFpM11rqUTAkjUGLJpdgAw9G+f2ZQEAO5vIsPhpHAcAc/qy+MKGMwAA39z+sqfRMEHCAYsDWQtlvxywyMZxaUNbMy3GrWlYvJWE5Aeil127ny63hCsNCwUsWb3o1q5LSA7K7FpO+4R5nPsMS7FcxYFTtXS33YwOu7bm8UJZJzC1IpFQNPO4AMpCzWZYnLImRylg6ctqWSyHBzm1FlNWybkk5M/ww/GiNKnZpEvILoAIQsNi9fta0bY4BSzzA3Av3V+/RxbN6DL9vpvhkn7Ryrw2GUVRcOU5tSzL/9nxGgDg/CUz0J1JaeJyh+uQzmN3Wn8sVl1ptJlaf/osKEqt1HZ83Fs7cd7mOdUsn3znUpw5vw/DkyV8Y/vLvv3cVuCAxQEr0W1JKgmlXXQJmTlBuoU8UdzOE9IFLB4yLFpJyEcNS9Zej1KuVEXw0WvIsNgFOfQeFcV+V6G13DppWPTff70uvLUT9toteJRNyKUTliUrQvNiiVGGhYIJk/emqqrW1jyQExkQpwe5UUcidDJWPixpwyyhJgOWEelcyA90N6JQv6Y1136/tQ/LA7sOYfWtD+Ifm0y/O5aEApgPs++UQ0koTGt+H7SCBOlY6Lq4ZOVsAJIDdKli64llHHxIOGlY5g/kcPqcXgDArzy2Nzs1IDRDKpnAV35jNQBg21N7PR9TEHDA4oCd6BaoZVdkVX6anG7Lte/7IroVGhbvJSEvuxs3viFeccqwyDt4Ibrtcm5rLkjzZuw6mjQTOvcZFkAOWJwzLGbiZjemccRAgG63zYturUtCo/my+FxqGhbKsDgFLPphkJoPi3mXEO3Q5VS8W/NEGatuLbq3y1XrCcp+TWsG7H1Ynt5zClUVePS1E039bKcMy1AAvhr7TtZ+1uKZ0WdYNNFt6xmGs4f6sXSWFoRdvIICltrPVlV7Lx3N5da8JGTVJdSXTeG8RYMAgJ37vOlY/DSOk7lw+Sxc+7YFUFXgj+/f3dT95yccsDhgZX5EXUBGzwMtw1K7aP2I/Ac9loTkHZyXkpC4cTwubnY4BSzU0pxNaWPhhYbFJmBxu6Po8SgIJd44XusUEm3NJguB/LuN14eblmZiMMAMy2iTGZYuGx8Wao0d6Eojl05qGRankpCwx6cMi4PTrSHDAlh3LXn5vYRcSrQSp/tpHGcnuqXrr9mAggIWo2kcMTTo/wDE/fUMyyILDUs7WfPLKIqCK+plof5cCmvqQYTsTWV3rTuJbo2fx5jk1XXe4gEArWRY/A1YAOB/XHkWerMpPL9vGD94ep/vP98LHLA4YJXW1CY1K6av97NLSJvY7L0k5EV0W/SxXk+I8o5Fl5BZBsCN7sXYSWKFW5dUWtiX1NPb5MVSsPk98teMpTcRsLgQMGutzf4L25oxjgPkzpzGBzMtejQF2G0nltG8TbOqN3YJ6bNauXRCCJObKQuZmcYB+vKJVelUG34YrOiWApZmRbFOU6VJdHt8vOhLN9rIVElcW5Yaljay5jfy0XWLMbcvi0+uXyo0igmp69BunpA2+FB/LBkLEbI28TotMizP7xv2ZElR8Fl0KzO3P4dbLl8JAPj6g78O5DnlFg5YHLBK41Fbc8qwo9F8WKgk1LoYjHbpbiY2q6pqKAm5f1j42RFBCHt8i+DDbBZJv4uAxcnllhA+MC7bmtfW7bfJi8Xu99i5V1ILuqsMS7dzV1SzNFsSshpMCGgZlrn9ta4Gu+BGZsSqS6hU0T2cC4YMi6IoWqdQE8LUESpFdenPRSqZEBsOqyyAv6Jb6zZ4uv4ONzlwruSQCRrsTovv+ZFloQ6h2b0Zy6xGqNb8lGFpoRtTZtnsHjz5Py/HH33gTN3XtfKkzWaKOpbS7jIs8jPwzKE+ZJIJnJosiZKbG9w+D5vlxouW4Yx5vejOpITYOgo4YHHAqvWRAhJZcAtIUbTB6ba3lbZmKcPiFHWXKqrO6MfLw8LPybSEnC0xO3ajLT/gzjjObQq0x6Vgk4KFtYsHAdSM0cbyJdt2QUVRLDuFvHjaBFkSarWt2a4k5D3Dom8t7pI0AfJ1ajaF2+15NOPYuLUfjtPEZj+DeLuSEF1/lara1MA5cZwW966iKGIKrx/CW1q0FlqUg4DwMiyqqopAtlXjOCfcjKGYEBkWlxoWyTgzm0rirKE+AN7mChVsHLn9IJ1M4LuffDse+sKlOGfhQCC/ww0csDhAIqaKQZhHQUEqYZ5h8deav/agLVaqnuZYAN66hGhn62+GpXbsZWkgmMyYSYZF7hKyCtDcalh6M94ClkUzujG7t5Y5eOPYhGTNbx4YiYDFsOCd9DD1uj9At9um25ot9CUAcKQ+qZkGpMkZFruAWmub13cJ0b8lzILRVtxuH3u9Zv511lB/w/echKF+GsfR7zLT4cgaqmbcaJ00LIBmHueH8Jb0K4stykFAeNb8hbLmydSK35UbKOi008RNOWpYDCUhg3HmefVNkxfH26AzLEAt6+TU8Rg0HLA4IAvzZMdGIbq1yLD4ac3flU6Kn+vUKWTczXgqCTnUwZuhO50ENfGYZUzoa70mGpZyVbUUWYpduEOq3m1JiOrx/V1pLJ9Ts6V+4/i4rdMtYL2LPGViBW8Fdc34bRynqqq4/vpNrNPt6LYR0sqmcbXX1s5BuapaildVVdVKQvX3m0wo4lqTd6z0wJcfvm7N6YycGC/gmT2nAACXnz2v4ftOE5v91HW50bAAmuW9FwouMkHzfZza7ORyCzhPM/cL+Rr1Q3RrhxvXZdGxZHjmi2y94VoTz8D660nH4sXxNu9jYB1npve78wG9ME+7McpVc9Gt1fDDVsRgiqJgZrc74a1xR+wlwxKEhiWRULTWYpOgQZSEpM+nO5MUQjcrHUvB5bAvt6UEWjAGutI4nQKWYxOOMzqs6vQUWNq53BJBlYQmixWx82y2rdnswXy0oSSk/WyrnedUqSKCmUEpeDLL5GgmWImG1417dLv92a+PoqoCqxf0Y+FgYzbAqSTkJhBwS5dF+bBUqeoW3WYCCjebDRLe+qFhcTKNA+Rp5sFmWOje7kondSaeQeA0xVz+nnHivVnGSd5U9IkMS63ksuvAiGs9U5BdQnGCAxYHEglFBC0F0wyL/iPM1DMuJWEc548DI6XRTzootI2liaZEtz5qWABZk2ISsJi0UiuKFORY6FjofTqlKN2YjqmqKkpC/V0pLJ9dM29649iElmq12GE7ZVjcuAaT8+uIz+p76nxKJpSGh6cTdm3NIsNSF90mE4oILqw+Zwq000lFlyrvMpRJqlVVXIddZhkWjyUhmrp7+VmN2RXAuWzhr3Gc+bVizKw1UxIi3ye7gIVam/0oCQnTODsNS0jDDydERiP4xdqN+NtLSWiqVBEuzHSNL5/di95sClOlCl49Og4nVFV1zARPF6b3u/MJM+FtxSnDUqmiWK6KnU9vi6nKGSLDYr+oNWRYPNSP6Vj9Fm5pwluzkpC+fkuQeZyVPb/TpGbCjXHcZLEiMmYDXWmcPreWYXn92LijVsZKdCvmMrkpCZE1v88ZFrlDyM5czwwrF9pypYpj0qRmwsmLRfNCyeiOxRgYyQG3vFt0OxNKJl+q4Oev1PQrG0zKQYC1+yjhZ4bFqiTkR8BCvk92m40hn0pCqqpKpnF2JaFwNCy0KQy6HARoWiq7wHnSQXRblD4Pup4VRQtwEgkFaxa592ORy7CcYWGk1KZUEhJdQsYMi3aTyrvNVqN/Ki04aVgaRLdeAhaRYfH3orcLGkTAktUv7DRXyKrVl8zxnKaTurHmp0xEqp6JoAzLm8cnHFOtZrsmVVU9GceJDMtUyVcnSa1DyPuD3Cr1fWKiiKpay6rMqouTATi63Ro7hIy/hwIjOfDTiW6bGID4y9ePY6pUwYKBHFYvaBTcAtbDTYF6ticA4zjjPdoQsDRRsnFTzh2iklCLE5tPTBQxVapAUYAFgznL18ltvF48Rbzipy2/E27mZtE4C2MAZbbxlTuE5EB+jQfHW90947PTbdzwdBdu3boVa9asQX9/P/r7+7F+/Xo88MADlq/fvXs3rrvuOixbtgyKouC2226z/fmbN2+Goii45ZZbvBxW4Jj1z1PJx1gzTUslIYqes6lEQ+nIK1pJyH4Xbty9eWkpDELDAth7sdBodWOGxck8Lu+yjY9+jt1CJ+tXFEXBohldSCcVFMpV0b7u2CUkPTSmShVxrbjpEiLjuKrqLA72gjCNy3oT3ALyg1l/PKR/mNOb1V372jwh+wyLMeNEA+IoMKLFPJNM6H5+r4t2UiM/ebFeDjp7nmWGyW5is7xz9dWa3xAc0fVH32+lS8hNhuXkRLGlVmPSr8zry9mKkeUgL8gsi5+2/E64mZs1ZTE52mwdkW35Zai1mUaE2EElN0VptNmYbni6CxctWoTNmzfjmWeewdNPP433vve9uOaaa7B7927T109OTmL58uXYvHkz5s+fb/uzn3rqKfz1X/811qxZ4+WQQsGsFkslBCsflmK56ovLLaG53TqVhPQPBrcPikpVFe/J/4DF2mpfdLE0BCz2AxCN9u1WiFKCTUmIuleokyaVTGDprB7da6x22Ga6BNKvZJIJVw/RbCop3oef5nHNmsYB1iWhI4YOIe31DhkWqSQk02UQ91qV4Oh43JaEqlUVD710FIC1fgWwF93K906QXUJ0zlfNqy1SI1Mlz+3bxYrzvTvQlRbXWSteLFqHkLXgFjA4QQcYsIiSUCgZFm0AohVOJSF5HRm3KIkvqz9/3qqPCLEj73Ku2nTA08p09dVX48orr8TKlStxxhln4Ktf/Sp6e3vx+OOPm75+3bp1+OY3v4mPfvSjyGazpq8BgPHxcXz84x/H3/zN32DGjBne3kEI5EyEedosIWNJSGtr9jNVOejS7bbRh8XdTkquqwaVYTEV3ebNg7p+G90L4MHptv6AIU2RGXJLM7F8tj5gsS4JNV4bVLYb7E67foBQBs1PLxb67Ly2NAPaw7YsiWABKWDp09/PTu2ejiWh+nVq1tIMyG3N7q7n5/cP49hYAb3ZFN65fJbl6+xEt/S+/dq5ypoOufRHGZYFg13iuj/kMcviJjuqKIovwls3glvA4AQdoPBW2xiGkGHxoGFxk2Ex86ECtIDl6FjBMasYtGlcnGj6HVYqFWzbtg0TExNYv359Swdx880346qrrsLll1/e0s8JiqzJLlqIbm0yLLRA+xGwzHC5oDWrYdEFLD53CdHuwWzXOGYVsHS5y7A4tzVrDw2rDhZaMOQsz+lze8X/p5OKZbukeYbFfUszIeYJTfnXKdRahkX73OQsC+kf5ltlWCxKQpotvz5g6TJoWAoW3V9ejeOoO+jSVXNsF3E7HxYxqTmZ8GXnapVxGJGGM5IbrVcvFipf2RnHAZJ5XAvCWzctzYDeCTqUDEsYolsXXUKTwprfYpZQ2SzDor8vBrrT4pn/1vFJ22MKwzQuLng+w7t27cL69euRz+fR29uL++67D2effXbTB7Bt2zY8++yzeOqppzz9u0KhgEJBs7AeHR1t+hicMIuMLUW3ckmofiMZ65PNQFoIp4nNeYvJt04UKtrr/K6D2lntjxXMU6K0yFpNbHbrO5BKJpBLJ5Av1TRFZpqSUUnDQsgZFjshm3ggm5SEzKzgrRgIoFNItGp7tOUHatd1JplAsVLFZKmMAdR+htHlltC6hOxLQsbPRJtZRBkW8zZyr8ZxpF95v0V3EGHXJeRnSzOgn/idL1VEUCZrqBYOduHXh8c8d/IUKbhyOFYS3raUYamXhBbZdAgR2VQCk8VKoOZxoWpYHLRUVcnRu7Ek5F7DAtScZU/tHcZbJyZwtoVoHOgc0zigiQzLqlWrsHPnTjzxxBO46aabcOONN+LFF19s6pfv27cPn/vc5/AP//APyOWs1eZmbNq0CQMDA+LP4sWLmzoGN5iljUtVK9EttTWrUkmo9RuJuk28O916y7BkU/7sJmXclISMi6qj6NZlWzOgLXZWu/MRs4BljpZhsetEEj4sJiUhLxmWYEpCzWdYAO2BK2dNREnIELCILiGLDAsF2gOGriljSUicV8PDvkdoWJwXvj0nJvDKkXEkEwouO2Ou7WvtSkJaS7M/C2EqmRCbATkTKjJ8XWlRsvEqvCVxeNYhw7JA2PO3nmFxKgkB4ZjH+eEm7hYna375vBqf+2IMRKkxYDHTOQodywl7HUunmMYBTQQsmUwGK1aswAUXXIBNmzbhvPPOw+23397UL3/mmWdw9OhRnH/++UilUkilUnjkkUfwV3/1V0ilUqhUrB9OGzduxMjIiPizb9++po7BDWYW02WH4YfFcsXXG4nSg6dcloQoYvcasPitXwGs25rLlao4XuMN2+cwAFGkQV3sqpwCllETrQe53QL2ZSfzDAvpNTwELF3+2/O30tYMmLvQGgcfEs4aFvMuoS5DZkYbuWAQ3YqAyDnDQtmVC0+bKVrGrbCaoCt/zc+da87EIkEOmKkk5DVgcXv/zh9wPwBRVdUGp9VqVcUBlyUhIBx7/kmfzDndQL/DbMYWoNdYGTdTZgJvKx8qwL3wVjONm/4BS8tnuFqt6kozXnjf+96HXbt26b7227/92zjzzDPxpS99CUkbP5BsNmsr5PUTs11C2WL4YUZkWKq+2PITVMqYKlWQL1Uso2l64A90pzFWKLt+UPjpN2FEBB+GxWZc51NjFN1SZ5H5AmW1sJnhZDpmlmEZ7M5gZk8GJyeKtjsXs7ZmkWHxELAMiAxLEBoW7yUhoLGDB9DamsnllnByANU0LOYZFmEcR91fhkDUi9Otk7utjKZhCb4kBNQC7LFC2TLDQsGlZw2Li+GHAFxncEqVKq68/RfIpZO4979eJH7u0bECipUqkglF6GHsCCXDEmJJyKkbbkqy5U8Ysu/mJSH9HCGZZbNrGSwnDYsQ3XZAScjTSrpx40ZcccUVWLJkCcbGxnDPPfdgx44d2L59OwDghhtuwMKFC7Fp0yYAQLFYFOWiYrGIAwcOYOfOnejt7cWKFSvQ19eHc845R/c7enp6MGvWrIavR4lZZFx2HH6oajeSDwFLXzaFVEJBuVozJaNatBF64A92p7H/1JTrWUL0Or8Ft4C10y0tqNlUomFn6Lok5GJX4TRPaHTKvCy1fHZPPWBxFm3KDq3HJ8w7YuwIQsPSakmox9DCef/OAyKAtGprtgoo3BvHmZf63LY1TxUreOqt2rBDK3dbGbtpzQWXuhAvmHmxyAEzfR5eSzYFl4NLF7g0jzs8khe28Nt3H8aH1iwAoHUILRjMufKWcnIS9gO65sJoa+5x6FabLJl7sADm5cdxm3vUfUmoc0S3nu7Eo0eP4oYbbsCqVavwvve9D0899RS2b9+ODRs2AAD27t2LQ4cOidcfPHgQa9euxdq1a3Ho0CFs2bIFa9euxWc+8xl/30XAmE3ZtBx+WL+JK1VVLIR+BCyKoogSw6kJ60WNHvy0kzXOFrIiiEnNhFXwoc0RalzYhejWYgGnm97NTUrlMSsvFjPRLQCcXtex2OlkjHXpHz13AA/sqt0Dy6WykhNBaFhGRUmoxQxLoYI7H30Tn9u2EwDw0XWLG4I7zVHYyZrfXnRrJViU25rtXFOPjxdQqarIpRO2tvGEXUlIZFh8XAi6TEqIoyYloUMjU55cj92XhGqB5vBkybKsAdTcbIm7f/mW+P/99YBl0aDzZwvYOwnL/PSlI/jctueaCtjpmusJpUvIvjRp5cECmPt52WpYZmutzXalUAryO0F06+kM33HHHbbf37Fjh+7vy5Yt82zJbPwZccDWh8Wwy0hLFw2l9/3yB5jRncbx8YJtp5BcEgLcT2sOUsNCTqtWGRaz3YWzhsWdcRzgXBLSNCz646CAw26gWE7KsNz77H588YfPo6oCH3vHYkfBp8xAABObx4SguTUNy9ZHXsMLB2pdeJ+6aBn+5EONXYF2052niprzb0OXkNGHxaJdnQSM5aqKQrlqGah6GYkAuDOOcxKyeoGO26wkNNCVxry+LBJKLUN7fLyAuf3umhHoeeSUIe3PpdCTSWKiWMHBkSkRlBs5OaGV+Z966xR2HxzB6gUD0gwhZ/0KIFlCOGycvv7gr/HKkXG876x5+I3zFrj62YSfzQ1OUKavUK6iUlUbmi6sBh8C2rUmOyjbaVgGutKiLL3nxKRlpxCLbhkddj4saYsMC6A9PP0Sg4lOIduApb4w1BfAOIhuKSDJl6riwQrY12/7Je8Ws6DXamEzQysJWegrLDIs7zlzLga707j0jDmWP5seEs/tHcZ/qwcr//nCJfjqtec21LDtoIyYn063rWZY6KFLwcoX338Gbr36bNP31WMz64fKQamE0nCuLUtChoev7LFht9s8JUYAuA1YrDMAWoYlCNFt7WeXKlWRIRjoSiOVTAhBsxcdi3b/2l9ziqKILMthm7LTiXH9M+bvfrkHgORy66JDCLD3uSGGJ4t45Uit/NRMhoWyGmHOEqr93sbrUMuwNB6LXBKiZ5pdhgUAls6q61hsykJatnn6L+fT/x36gGlbc4WM4wwZFknTQqUbP0S3ADCjx7lTiHxYaCfrtnasdUT4H6XLuwe5LGNlGgdoHTtV1bzM4GVXIWYZFcw/Nyu/kjPm9eG5P96A33336ZY/mx7II1MlqCrwiXcuwZ9fc46nYAXwvyRUraqWYw/cQkFCQgG+9pvn4rPvXWnZ8t5t408he7AY/32XmCVk6BIynNdkfTBl7bXW17SYkt3jLkizmyUkG8f5BXW10fUrB6h0nrROIfc6Fi+DS910IpGj9mn1ssSPdh7AqYmiZhrnOsPibBz3zJ5T4v+bCdgpgDXLavhNNqXNuDK7DjXTOOuSkKpq64dWFje/R0+r61jetOkUKnCGhZGxFd0aFiZFUcQD7iRlWHyqrbrxYqEHPr3WrTq/6DKl3AzpZEIsNrKOxe5mzaY0zwrjQ0xVVamVz0WGxcbDw7jDNeLkSSPXqm9YvxR/1kSwIv9uv5xuJ4plUGKq2QzLh9YM4ayhfvyfj5+P/3zhEtvX2mZYLPQrgPW0ZrNSX48Lt1taaP0oCQWTYan9LLpPKaPQm02JzU8zrc1eNGhDLrxY6HN875lzsXpBPwrlKv7x6X2ubfkJIUq3MbB8WgpYrET2dvjZjemEoii2OhYrW37AOAyy9rpxBzd0mmm2xybDkg+gmy2uTP936ANm9tJlC2t+QHtoDPtcEhp0URKiB8NAl7cMS5AlIUAT+71yZEx8za5+qyiK5QBE+Ty40bDQzzd7wMjBUDPdNBcsnYFLVs7GLZevxFd+Y3XTpnukOcqXqr50VNBnlkooTaeKL1s1Fw987hJ88Jwhx9faOYCOTFn70gjti9E4zuSYnbxeAO2e81wSsjOOC0DDkjcELHIw14w9f8nD/evGi+WEZH5440XLAAB//9ge8W/cCJoB+8+XePqtk+L/rZytrahWVXHthGHND8iuzmYZFmvRrXwd0edhNUuIcNPazBoWRoeZV4PV8ENAKwtR2s+vyH9mj3PZYEq0Ndce2HK91I4gWjhlLjp9FgDgF68eE18TLX0Wn49VO7RcD3dzk/ba7MxHpbKUmzZNI92ZFP7+0xfilsvPaMkhWE4h23VvuEUWNIcxwdVuxsrJCfM5QoDs9WLwYTE5r90u3G4pq2k2gsEMuwxAEGXSLouApV8XsHh3u3Xb1gzIbrfOJaFZPRn8xnkLMKM7jQPDU6hUVWRSCczpdeeB5WQcly9V8Py+EfF3rxmWfLkiMolhiG4B+06hKeEJY74Jy0hdaYVyRWwUqTHBCJXk3rTLsHDAwsiY1bmF6NYmw0L4dSO5mdgs+7AA+nqpHUFnWN5dF67+4tXj4mtCcGaR2bBqh6agLJlQHI2yAPsuIbPBh1Eg27b7YbI11qLg1iv0gC6W9cJqADg6VtuVz+1vXORoAS/Wuy5Ei6bJw7fXhdst6btmuvTAsdewBFASMviwaBkW7fojr5SDLuf9qKoqGcc5B6dD1Dpto5GRMyy5dBIfWaeVBBcNdrkuezoZx71wYETXNeNVw0L3tKK4y7b6gabX8pZhAfSbX7l8arVGUEnomE1rcxCOzHFl+r9DHzDrJLAS3QKNi75vGZZ6wGLnhqr5sGgPbDclBlGvD0DDAgDrT5+FZELBG8cnRKeBkxOr5narf4hp5mLujrXXxjhu1GSHGxXUQWKcuN0MoqW5K5xATH5ATxoyIEfHai2yc/oaW3TlNP5UqSLeu7mGxd4AEJBFt613CQUiujVkWMw8gBa4CChk5A1J1oXoljQsduZx1NY8q7f2OX7inUtAMYqboYeEU4aFTP7odVY2BlYIW/5MOJlEQLtm7QIWKwGwXCKjDHNXOmmZ3aXWZsC6U4gzLIwO01lCVXPRLdBoj+1bW3O9JHTSImBRVVU88OUF2M2OPegMS38ujbWLBwFoWRZ6OFkFdNrEZv0CRZ4OVrsYI3azhKxamqMga1jMWkG0NFukmv0mk0qIhd1oW360PuF5bl9jhiWXToDWmcli2da1UxP2trHo1uDDYnb9LawHLCcmiq6uBTlD4eb+pfMwMlWy/PknxynDUnvtohndYtTBEpcdQoB9QAho+pV3rZgNwHtJaEK4iYe3WPfY2PPb+bAAeqPCMbJ1cMjuLptlr2MRDQicYWEAi1lCFXOnW0C/I1MU/9rtqCQ0bOF0W6xUQeaYXZmk7cPY7N8CwQUsAHDJSioL1XQsTi19VuZx2g3q7nO125mbDT6Miq6Mc0eFW0ZbtOVvBqvWZioJGSc8A7W6PmVTpooVWw0LLUpWbrqApu/yV3Tr32JonD1lFrD0d6XEouhGx1IqewtYBrrS4nXHxhrnwOVLFfEZyxPH/+Tqs/GxdyzBZ9613PF3EGbTzIlqVRUdQu85s2ay6FV0OyFlWMKCRgCYjaGgcSxWAmDZ7ZaO3UrDRzhZ9HOGhdFh2tZMGRaHklCvj6lKKgmNFcoNOgEAyBf13TN2tuNGghj0ZuTdZ9R2UY++dhzlStXRNMlSw1J0bxon//y4Z1j8LQmFq2EBrFub7TIsgH4Aol2XULdDhkVVVUl027qGJYgMS5fB+dXs+lMUxZMXC202EgoanFfNUBRFnAsKJmVIv5JOKjpt16IZ3dj0W+cKy3g3mE0zJ147No6RqRK60km8c3lNlN9shqU7xAwLCeRNBeb1zBSV0ozoSkJuMyyz7ac2exlT0u5wwOICs10YZVhMRbdSEOOn+2J/V1qkz81am2mhS9XFqMY5N3YUAi4JAcCaRYPoz6Uwmi/jVwdGpMFf9hqWhgxL2duOggKWfKkq/HMIq8GHUUAlLrvz9fNXjmHbk3sdf1argw+bwWySbbVas5gHzEW3gL5TyMo4DrDXIgG165+CjJkeu4QqVbXh2ghCzCgyLEXrgAXw5sXSTDlXBCyjjRkWWnRndGda3mzZZVieqpeD1i4ZFBmxyWLFdDNmxWQEGRa79voTpP3pMb/WdSUhG+NMGSe3W7sgf7ox/d+hD+RMdmGleu0ladLWLD84/KytJhOKZjBm0tpsTKfnXM7xAGTjuOCi9GRCwbtW1rIsv3jluK6l2AxtAKLBh8XDHCH6OVS6Ozauf0C3W4bliz98Hl++dxf2nrAfOU9BXpjdT1qqXDv+k5NFlKsqFAWYbdEKK7f62mpYHAYskn4lk0q4vjbksqIxy0LXmb/Tmuvv1ZBhMZYkvXixNOMXQ+W5IybCW7HoumxdtsNs4B/xdF1w+/ZlM3WBtdWQUjO0OULhB+ZmotsTjhmW+jyhsnOGmaDW5rcs7vkgXcrjBgcsLtA0LI1Ot2YZFll067f74kwbt1uxO63fUE6CNxl6TZAZFkDTsfz81WMiJWqVBbDMsHgcp55KJrCk3tnwxjH9LsVq8GEUmM2sMkKBqp2HBuDcgRUEZmJEWhBn9WQsW9C7pK4L0SVkovvqcWhrplEYMz1kBuTr3RiwUBDv50KQk/Q6ADBSD8aNAfNCD14sYvChh+PUSkImGRbJg6VVzAbHEpRhWbdshs4N24uORZSEQrDlJ3pMAnOglqWjkqRlwCJMSCsiMHMqCcmtzWZlbc6wMDrM6tya6NYpw+LvQkj+KnYlIbrx4ya6BYBL6hmWnfuGReDhWcPSxA26vD6V9vVj47qvm7WVRkWXQZBppFypivNk58UDhN/WDJi3e9q1NIt/l9YCESpvmLWs99iY0wHaPWGcCG1HzcunFtwY75MggnijD4vV9SdKQi68WJrRn9EUaLuAxW1ZzQ6rIPzwSB77T00hoQBrl8wAoF2rXnQsYdryE2alT6B2/ZGJ3UwL0bdcEhJNBw7HLrc2m1n0s4aF0WFW59ZEt/bGcX4HLHThmg1AzBvEqN5Et8E63RKLZnRj+ZweYbwHWO8wKE1unOBqZy5mxelzarsUY4ZlxGLwYRQYW16NyDqAE44BSwSiW5MMyDEHwS2gLQByEN5UhmWyuYXWKhOpZViCLwkZA5ahAe+iWzemcQSdD/OSkI8BS0ozBpR5ek8tu3L2gn4RbPRZ+C7ZMSHaiEPUsFj4sFCgN9idtvRVkY3j7EaTGLFrbdZ8qThgYaCPXGnxL9s53QZYErJzuzVmWIwmVXYEbRwn8+56WQioBVdWpQKaP3RgeEo3XsBuQJ4VpztlWDzsyoMi51ASki37nTIspPsJU3SriRG146QF0S5goeBEfk9mD18n47hTHj1YCKvAPohxFV2S6FbulGssCWmiW6fRGk2JbusZFrO2ZtHp4kdJyKILS+hXls4UX7PSrNkxKTIs4S3WXRbW/CQut/vc9F1CdOzOzx7RKWTIsNQGwXJJiJGQAxC6OMhd0lR0q+sS8vdGmtFNolsbDUtDSchFhoV2kyFc9FQWAuxv1oWDXVCU2gIoL2bN3KDL2yDD0mXTAgroAxnnklAUbc2NqXIqOZh5sBDdhoAlk0yYWr9rolvzBe0kebC4bGkmrEqnlHHxM4jXMixVnSGiUXQ7byALRandu07ZtGbKuXYaFpFhsdBheMFM/wfI+hUtYLHSrNlBc6W6QywJ0TPdmAnVBLfWwbk8S8ithgWQvFgMrc2liiq8t1h0ywAAEglFBCEiw0JpWDOn25T2Nb9LQjNsSkJThjkWbialEsUmOg2a5Z3LZ4nMlF0GIJdOYl5d+7DvlFbLbyYFShmWA8NT4nNSVVUsGnHQsDiVhOSvO5eEomhrbhQj2s0RIihQo4DFKhClWr/VDpwyLFb6ASs0IaT+PqF7zM/sm9wRRcFyTybZkGXMppLi/RpLokaauXcpgDw5UWwo1whbfl9KQo2bprF8CS8dGgUAvH3ZDPF1K2drOybFsMEQfVgs/IBO1DMss20CPTk4dqthAawzLHIHaBibzaiZ/u/QJ4w3HmkwTI3jpNbgXp9rq4NdNE/Iua3ZrqXQSNDW/DI92RQuWFp7UDktqIvrNuA0fwhoztlxRk9GZKfeOF4rC00UK+I8xiFgyTqIbvUlocadMVGtqsJxM9ySkHWGxb4kVDtGLWAxP69UxhiZKplOtNZEt02WhHRO1lXR3jvXRjDsFQrGpqSAxeras+pGMaINPnR/787oTotNg7HVXxPdtt7WnJO6YoiHXjqCqlq7t+XMG2WZvGRYSMMSZluzlYblhOiusv7ctGdyFWMeBMOkYXnToGGha1ZR2JqfkcgabrxSRKJb6oAwm2pq3SUUD+M4GWpvdgxYZtRu1L26gKWuYfG4q6IsC5WF6DNMJ5VY1H+7vGRYxq0zLOPFsuhWCLPUZZphIdGti5IQBRxW57U/J1nWm3TPNC+6bSwJnZiodXwkE4ov4lPxu+rnWFU1/YjVWAirbhQjzWw2FEXBnF4yj9MLb/0V3daOqVRRUamqGJkq4Ws//jUA4PoLFutea9UVaAdlOcIU3XZbiL+PO3iwAMbhh+6cbgEtw3J8XN/aLBoQUonQhj9GSfRP6TZBODaWqCRkN0tI+5rfolthHDfVuGAJf5KMXnTrKcMSQkkIAD6ybjHed+ZcfOqi02xft7jun7L/lBSwlLWb1AukYyHhrbzDjcPN7ii6dVkSogd+OqmEuusyZlhUVRWLspsuoZN1HxWrUp9sWW82yZh8WLy0NQPmpVMKtGb1ZFzZ3btFFoqTINkqw6K1iTsELE12M80V5nFahqUoObD6UhKSNgKFcgVbtr+MY2MFLJ/dg9+7VD+TSExndyiByWjGcWGWhMyN46gkZKdhMSsJuVkj+nNpcT5kHUtBPAunv34F4IDFNcbySikiHxY7p9t2yrDM7s3ijk+tw4az59m+jgKWfSe1HbU2S8ifDEscBLeAsw9LXnpAnpooWnaPaC634QZiRh+W4cmSWEznuOgSogxJziZzNmRjWd90hsVkGrsb7U0zpJMKKP456hiwWDuqypSa9FCiIPKYNE+IykGyq3YryAvpE2+exPee2AMA+PPfPKdhke1vIsMyGUFJiK7zclXV6X/os5tt2yXUKLp1W7ZdMss62xyHDHEYdMa79AHjLox8WJycbv2O/Gn3ODxValiwhOhWBCweRLchGcd5ZfGMuoZFl2FpzijJaB5nZYseFU5t6HKGpVxVLcWnUbQ0A/Lww9rvJ/3KYHfadgdICzPpicxM4wjhAGtSEjrZdFtzow+LlhnyT78C1LJEdJ4POwQsQWpYAC0YkzuFSLczoztj2qnlFdmY73/euwuqCvzW2oW46PTZDa9tyoeFMixhloSkgFrOfrkppVFJcLJY8ay/WTqzMWApeJyr1u7Ea3WKMUY/gUrFRnQrPXD9XjRIUFgsVxt24sZ2X09OtzGdR0EZlgOnpsSCZhQXu0U2j6tWtQ6h+AQs7ktCgLa4GImipRnQavu066WSxzyHRd94Hu20SZqhmj5gmSpWxL05o+kMi1QSclHKahZ6v1SKccqwOGlYmpklBGjnRTaP89OWn6AS38GRPAa60vgfV51l+rqmnG4jsOZPJxPiGS+7Lh/3UBKSR6u4lQ3QeJE9J0wyLDF7bgcFBywu0TQsBtGtmYYlwJJQTyYpaurGdkejD0vOocQg04y9dxjM688hk0ygXFXF/JxCEz4sQC34SSUUTJUqODyaj9XgQ6DRBdWIsTPGyoslipZmQO6e0GdYnMoqXYbdsd3Dd6huJnhoRK9hoRkumWTCc4urWWAvSkIBBCw5EbA4ZFgsulGMNNvhZ5Zh8dOWn5B1LP/jyjMth2B6zbBUqqrjeI+goGuMjOsKZc251k1bM33OXnRmS+peLHtPahqWTjKNAzhgcU1DSUhkWBxKQj6nKhVFwaCF8LbBh8WkNm9FXEtCyYSChVQWqutYjIGZW9LJhBjV/saxCck0LvrBh0DjYDwjxszLcYtOIS3DEu77EhmBegmDFn07/Yr87wi7DMtCCw3LKckW3atux6wkRKLbOTbdTc1Ci4sIWCxEwlaOqkaa17DU5wlJolvqPvPDNI6gz3fdshkNnUEymnGcuwyLnHnqDlF0C0heLPV7lQKQVEKx1cTRZ0HZmN5syvX1utRGwxK3zHhQxGt1ijHyLkxVVWHNbya6lSPmICL/gW5z4a2l6NYhw1KuVEW5JawuIS8sMuhYWhGayTqWOA0+BJwzYsaSkFWGZTSCSc2Alk2cKtX8bWghtHO5BRpLQnbnVRPd5nUarmYFt4C5OD3IkhCdZ2FMZ6lhcSe6DSLD4mdJ6B2nzcTMngy+9pvn2upitLbmRn2eGRRcdWeSoS/Y3YYMiwj0euy1P7SJHPXgcktQSejgcF4Eqdpctfg9t4MgHlvLNkBrEa7qBvc5i279/4gHLTqFGozjXIpuKbsCxC/DAsidQhSwNN/Kd/qcXvwER/DGsXFponE8ApYuJ9Ft0dyR1EhUJSGjGNFtWcWYYbHLnFFJiIzXjLO1vLY0A+aZyGNiynRwAQth7cPira3Z62aDMiwnJgooV6pIJRO+erAQ3/rI21AoVxzvV7peS5VaqcfJZ4msDmhDEybdhrlZbvQrQGPJ3c0cIWJuXxbZVAKFchUHTk1h2eyejprUDHCGxTVCw1KuiOwKYOV0mxD/DSIAGBBTjPU7bKMPi1vRrdyaF8eAZYlFwOLVOA6QvVgmRK08PhkWd6JbyiBbebHIbc1hkk0lhL5qsljRTOMcRLdG0y+7h28unRS7f3mSMQXvzWVY9IG9W/+YZjFmlKw1LCS6dZlh8RiwkMeMqmrlRT9t+WXcbC56MinR8u3G7XZ/fVzHorq5ZJgY52aJlmaHUprxc3Bjy08oiiKehXsNz0IOWBgdsqVyScpI2IlugzIzol2llei2cVqzQ4alrNk7m72fqCG3W5onpJWEmsuwAMAbx8ZjNfgQkDIs5appSpweTrSIOpeEws2wKIoi6VjKHkS3Bg2Lw3kdotZmScfSbEsz0Fg6HZly5x/TLMaSl6NxnIOGpdmSUCIhud3Ws2F+2vJ7JZFQRAndjfA20gyLQRB9wuWE64YMi8d7lHQseyhgadJEs13pjHfpA/IujAS3gPkCTyWhoMyMrMzjGn1Y3GVYClKHUBwcX43I84QqVVUsJnZ+HVZQa/PBkbyjD0bYkEdDpaoKY0IZOr8kPLXuEoouENO8WCpiEfTa1uykTVpQb20+JHmx0PTylgKWMomF3fnHNEvWZYbF2CZuRSuCeQomqcU6iJKQF6g85mYAopZhCT9g6THY8x+vZ6acAr3GkpC3NWLJzNrzS8s2s3EcY0JOqnNTSzMAU9vucxcNYPWCfvzW+YsCORbZPE7GWCox85cwo9kaeFhQhuXoWEGXVWomwzLYnRG7IOo6ikvAIj90zFqbKYO2sP55WM0TikrDAmiL7OHRvHiYOmVYMqmELvB3yrCQPf8BqSR0sh68e/VgARqHTmqlrGCyDO5LQt7amr0axwHaezRmWOzm4QRJnwd7/ihLQkYX4hMu5ggBjSUhrxmWJfXN25761GZhHNchXUIsunUJXWh5SXSbTiqmGYnebAr/9oeXBHYsQsNi0SVEF69Zu6YZWko5nhf9YHcafdkUxgplvHZ0XHy92brt8jk9Ov0HGVZFTSaZQEIBqmrNht+YIREBS33BtjKOo2xDFGJiWmRp3klfLuXqPHVlkiLQMmYgjGheLFqG5ZQoCTUhum3IsJBY2P+WZkAfmHZnkpaBhuvhhy1lWLTW5nKl2pIWyA+82PPHqyRUuxcdNSyGTIgXDQsALK17sZB5XKGF8ng7Es8tdQyRH2plmzlCYUAZFjnboKqqFrBkasclRJweSkJxRFEULKqLzV49Ogagtrg3O5SOdCxEXDIssm27me4oLzIsWknIqHVRVVXsPCmwCRNaZN+s7wDdZinkTiG3GRZ5ACK1NTeVYTG0NR8NsEMI0O+G7a49r9b8zdy/coaFzPcUpbnSmh/0ufRiKZQr4jxFKbqlDq4Toh082JKQ3DGpqiobxzHmiLbmsia6jUqgOthVe5jIxnGFchW0djW0NbvOsMT3cqCZQq8eqWVYWvEdoE4hImy/Ejvs3G5Jw7KovmCXKirGDILMY2MFFMpVJBRtYQ8TWmQpw+LkwULInUJOu8UFddHtgeHGDMvMpjQs+i6hwEtCGXcBS5fLDEuphZKubB4nC5f9nFDtBcqwOIluDw3noaq1Z10zWbVWobZmMkkMqyS0eGYXFKXWOXZiotiSxUM7Et8VKmbInQTCNM7EgyUMzIzj5FbYnIno1s6Iqdm2yDBZbMiwtJIClTMsfdlUZA9nMyjYNHO7pQzajJ6MeN1Jg46FugcWDHZFEoBSwPLmcW8ZFjmr4jbDcmQ0L8qzZMLWlOjW4MNybDzgDIv0/uzKdlRemyq6u3+b0bDMk8zjTo5HK7gFtM/Dqa1ZFtxG0SggZ1hUVRXlWauxA4TxnvSaYcmmkhiqbwL2nJhk0S1jjvxQK9sMPgyDQRMNCy1m6aQiHlwUdVdV6LxjjBQrtX/bDhmWV+oZFq+DD2WWSwFLXEzjiKyNF4tsDEg7OaMXy956bZv8GsKGHuQ062euywyLnHVwevjO7cshmVBQrtb8UvKlihTMtaBhEaJbb8fuFTlgscuwkIC5LHXGmVFoIUM6VxqAGHWHEKAJxa0mkRNR6lcAbf7VRLGCyWJFBA5OGRZ5ejXQnDBeLgtRkO2k+5ouxHeFihlyeaVc7xJKR7Qzp4fcWKGMsrBobhRfyWUTu06hdigJLan7D5ChVys7isUzusRDI24Bi+zFYkRuW6dOJ2NrMxlKRRWwGE3gmtGwOGXPkgkF8+o/9+DIlNCvpCQfDy8YS0JBmsYB+mvXNmCRPgc7HYsfbc3HxwuaW2uUGZac1wxLtIH5VLEsykFd6WTD9W+GXL7x4nRLCC8WXYaFAxZGQtfWXM+wJKMqCUkPOfIrMHqwAHqBl5V7KhB/0S2gtTYTrdygqWRCqO3jMviQsBqAaBRV0y6YuhMI8mdYHFWGxWCW6DrDknYfsAB64a3QXvRkmioPWPmwBBawuBTdpiSnbDsdS7PDD4FacEKdaZS9jEOGxUl0G3WGRdawaB4s7j433ay5Jp4/olPo5AQbxzHm6I3jKMMSzceXSiZEOxy1sE6Z2NUriiIeYu2eYTHupFr1HSADubh0CBE5iwnbxUoVVUlUTQZVDSWhesBCu7Cw8SPD4mbkwpA0tfnURL0Vt8nOlpzkVzRZLGO8LmQOqiTkVnQLyDt5mwxLCxq0VDIh5t/8+vAogGgzLMKHpU0yLJNShsWppZlodTiuXBLiDAtjipglVKpELroFJOFtvbU5b/BgIbT6vIuUcoxFt12ZpE7QlmtijpAMCW+bGZYXJFai27w0+DAnaViMJaE9EZeEGjIsbkW3cpeQi8CZOoXkklCz51Iu91KHUFc6KRYlv3FbEgK0ANBunlCrGw46Ry8frgnaoxXdus2wROdyC+jPywmXgw8JWW/SjIZl6UytJKQZx8X32e0nnfEufUCXYalG68MCNJrH0QJnXMjdTGwmsWGcMyyA5vIItH6DfnTdElx57nx8/MKlrR6Wr2iuq/oFyiiqnmmiYZkqVoT+IjYaFtdtzd4yLGTPf3BYC1iaXWjlkpA8/yio7hO3JSFACwDt5gm12uVHredkgjbT5cIbBG6cbgvlCo7Uzf2iC1i086J5sLi7/uTz1Mz4Frq3j44VxPOfMyyMDjltLEpCEWZYjOZx2uBD/Sl1mgAMtCbaCxNZl9HqDbpkVjf+z8cvwHmLB1s8Kn+hxcwoup0yTGUVGhYpYNlXr+v35VKRlbrkrERPJuk65a3TsLgo92lut3lREhpssiQkd9ORe25Q+hVAv6lwOk9dbjIsLd6/xvcarejWOcMie7BElQ0Sc55KFU2s7DrDUjtPiqIXVrtlsDstMjN0/3PAwujQ0saS6DZC/w5hHmfUsKQtSkIuNCxxF27Jwtvp6jvQVXcpNpaEjKLq2aIkpIluqaV56azuyIZYdksBihcNCGVVMqkEEi7uqwVCw5KXMixNloSka4lEy0HZ8gP6gMypS83oqGpEVbVBmX4FLNGKbrUOyIqFFQMZBkblwQJoHjmqChyol6e8alh6MylX17oRRVEaNGpxf3b7RWe8Sx8Q/hhlra05Kh8WwFrDYkynuykJtYNxHKBNbQZa82GJM1qGxbwkROeXRLeycVzULc2APsPixXiNUuxuS30UsBwfL+Bw3fOlWTt5+bqngZhBmcYB3kS3xpk1RmR/lmaM44DGwDJa0a0W8I5blMGoQ2hhROUgQP/8ofvO7cBIeiY30yFEGO9xzrAwOiiCrVRVofmIsiRED7pho4bFmGGhUpaLklDczYf8LAnFFVrMjOMU8oYMGi0qx6V5QnsjbmkG9BoWt7b8tX9Xe19u9CtAbcghZdleqne3NBuwJBKKCFqorOY0YboVvIhuScMyYbF4F6WNSLO7bGOGpZl5TH6RSydFpsjKiyVqwS1Qu2bomqWsnNMcIUJkWJrQrxBLZurHi0zXjLORzniXPiAvkOSJEKXoVrjdigxL7cHVSkko9hkWqSQU9+CqWax8WIwBKaXti+Wq0DfEIsMidQl50YGQVsNtIKooihDe0uTaVkoZdJ9QwDInQOFpbzaFhFK731rOsEj3dbP3r5xhGehKN52p8Yt+B7fbqFuaCW2adl2s7NaHpR5ctJJhMZaEpusGzki8XLNijPwwoFRlVMMPATvRrf7CzVl0nci0Yu0dJkMDNUv2SlWdtjsK0T5vVRKqn8/uTBLZVAKFchUnx4vozaZiEbDIGRYvAQuJD7346wwN5vBGfWYR0FqLejadwFihpokBgvNgAWo6jW/8p/OQSycc7zltUTRfvEticrzSlB4C0OYJAdGWg4j+XBrHx4s2GZZoTeOI2rWulWSd5ggRoiTUUoZFf4/HfbPpF53xLn1AThtTejZSHxaD6NZaw+KcYaFe/rgHLKlkQvhvTFcNS5eFUZhRw6IoilhcTkwUUK2qIjW91JAuDhM5w+KlJPS2JYNYONiFD6ye5/rfUIaFaC3DUjtuEnoG2SUEAP/pgkX40JoFjq9zMo7zw/Rxdm8WpF2NUnBLiHlCFp1CccuwEF6dbpvxYCHkgMWtUH06wBkWD2RTCRQrVYznKWCJ3oeFRLeWGpZpJLoFaovxvpNTQqU/3bBqazZqWIBaG+XBkZo1/bHxAgrlKpIJBUODwWUHnMilklCUWveEl0V/dm8W//Gl93jq+iC3W6LZtmagUf8RdMDiFtkC3gwaXNpKGSedTGBmdwYnJoqxCFjsJjYXy1UcHo3Wg4WQPVT6cynXQaMfGpahgRxS9QGgnWIaB3CGxROkm6CaZVTDDwGpJDSpLwk1BizmVu8y7WDNT/zX95yOa9+2AO87a27UhxIIViU8s4BU9mKhctCCwVykGoREQhED7OYPeAucvLaoLpB+fjKhtDQXSr72UwmlaQGv3zi1NftVzqUSmNtOlyCxmyd0aGQKqloTmUZdvpIzLG7LQYAWhLbilZRKJkTA1in6FYAzLJ6gxV8rCUUoupXamuXBeNYaFpsMS5sYxwHARafPxkWnz476MAKDfFisnG7p+wB0E5sT9cU+Sv0K8ae/cTb2nZzC8vr4g6BYIGVYZnQ3N/iQkEXcc/qysUmxOxnH+ZUdnduXxUuHYlISylq73crloKg8WAg5y+sl0Lv+gkU4MpLHR9Ytaen3L5nVg7dOTHLAwphD6u5YiG7rGpZKVcVEsSJpWPQPLi8Zlk4xH4ozoiRkFbCYZVjGC6KLxNjuGAW/uXZRKL9ngVT6mtHiTCj52o9LOQiQMiwWbc0kum313j1zqA+PvHIMK+f2tfRz/EDMEzJ5z3ER3AL6DIvblmYAWD6nF3/5kbe1/PtpVEknPbc5YPEA6UHGYyC6pQ6DYrmK4cligxMqofmwtL/TbSeQtciI5U3O78xerSSk1g3k4pBhCYshSXTbqneIfO0HaRrnFSofOLU1t1oG/PzlZ+CKc4awZuFASz/HD+zmCcXBg4Xozsp6svAzUySu76QMC69QHqBW2sm6AC5KHxZFUXTmcdQG25Toto1KQtMdMa3ZIsOS0+3qtJJQHFqaw6Ynq81Maj3DIpeEohMtG3HSsJDottV7N5dO4m2LB2NRCrObJ0Q2+AsHo7/OdSWhCEppZw31A9C3pU93OMPiAdqFUYYlSqdboGYed2ysgJGpknWGxUVJSExrTnZOpB5XrIZVTpkYAwp7/okiDtXt6TspYAFq3RIjU6WWtRfyPKE4lYS63WpYptFmQ2RYTLqEYpVh0WlYwr9mLl4xC9/95AVYs2gw9N8dFZ6u8q1bt2LNmjXo7+9Hf38/1q9fjwceeMDy9bt378Z1112HZcuWQVEU3HbbbS3/zCihXRiZOCUjzLAAevM44XSbMRfd2paEOMMSG+j8WXUJ6duaa4v0gVNTODZWG4K4ZFZnBSwL68LbVlqaAYOGJUY71m4HDUuRBh+2gSWBW+x8WOKkYemJuCSkKArev3q+5268dsbTVb5o0SJs3rwZzzzzDJ5++mm8973vxTXXXIPdu3ebvn5ychLLly/H5s2bMX/+fF9+ZpSIDEs+HhkWzTyu5GJa8/Roa57ukOi2VFF102rNjAFnSW3NQK1NspVWyXbkbYsHAQCrF/S39HPkUmqQk5q9QjqJyVJFzIySERqWaXTvWvmw6D1Yog/Mu5oU3TLN46kkdPXVV+v+/tWvfhVbt27F448/jtWrVze8ft26dVi3bh0A4Mtf/rIvPzNK6KFWrpIddrQPCc08rug8/NDW6bZ9jOOmO/L5y5cqwpzKzGfHWAbptHIQANz8nhW4du3Clgc+xrdLqHb+VbUmxDZmUNvJ9NEtfRazhA6P5FFVa+dqdgz8YmQNSxyOpxNo+iqvVCrYtm0bJiYmsH79el8OJoif6SfGLpoou4QAyYtFyrBYim5tu4Rq/zY7TefztBPyNSYLb81KQr3ZlG6h6sSAJZFQfJlOrRfdxidgkc+32Twhce9OpwxLzjzDIpeDovZgAQxtzRFoWDoRz6LbXbt2Yf369cjn8+jt7cV9992Hs88+u6WDaOZnFgoFFAoF8ffR0dGWjsENxgU96pIQTWw+Uk+TAtazhIzD9GSEhmUa7dLalURCEUMNZR2LWUlIURTM7MmINHmn6Vf8RF7wvbiWBk0ioaArncRUqVLrTjR48U1H/RkFLIVyFYVyRQSTcZkhRFD2M6Foz2ImWDxf5atWrcLOnTvxxBNP4KabbsKNN96IF198saWDaOZnbtq0CQMDA+LP4sWLWzoGN2QNk2TjIro9PKIFLMa5Ek6iW1VV2YclZpi5E1tplOSyUCdmWPyCNiMzezKxW/x7hI6lMcNSmoai215pxILc2hwnwS2gBSwze+LjjDzd8XyVZzIZrFixAhdccAE2bdqE8847D7fffntLB9HMz9y4cSNGRkbEn3379rV0DG7IxSzDQuI02mFnkomGcQFOottyVQVpO+P2oO5UukzmCVmV/OTuBA5Ymoc2I3HSrxCitdlkAGJBiG6nz4KZTChiMKBsHvfykTEA8cmwrF7Qjw+tGcJn33N61IfSMbTsw1KtVnWlGT9w8zOz2Syy2XAfLsYMS9SiW2rlpAyLMaACnI3jitLXOWCJB2ZeLELDYij5zeIMiy/QZx4n/QrRbWMep4lup5eHUl8uhfFCWWRYRiZLePjXxwAAl6yMxyyxdDKB//9/Pj/qw+goPAUsGzduxBVXXIElS5ZgbGwM99xzD3bs2IHt27cDAG644QYsXLgQmzZtAgAUi0VR2ikWizhw4AB27tyJ3t5erFixwtXPjBOxE912abVeoHExA5y7hHQByzRKK7czOYPbbbWqaue4oSRUW2BTCQVDHeTH4DeXnjEH71w+E59459KoD6UBCljMMizT1ZKgP5fGoZG8CFj+368Oolip4sz5fS23sDPti6eA5ejRo7jhhhtw6NAhDAwMYM2aNdi+fTs2bNgAANi7dy8SUtbh4MGDWLt2rfj7li1bsGXLFlx66aXYsWOHq58ZJxoClojrloMGO3LjYgZYD9MjSLSXUKKdPs1oGDUssmDaeI6pJLRwRhefvxZYNKMb2343fp2JgKaVMMuwlKah6BaQzeNqJaF/fnY/AOC68xfFokOIiQZPAcsdd9xh+30KQohly5aZmh15+ZlxwqgfiHqBoInNhNkQLLcZFmO5i4kOY0loSrJlNwbNpLlYNiv6Kc1MMGglIZsMS8TZXr+RzeNePzaO5/YOI5lQcM3aBREfGRMlPEvIAw1tzRFnWPpyKShKzVQKsAhY6gtcpaqiXKk2BFmFaZpSbmeMAxA1wW2ioRvhinOH8NrRcXxoDT/IpytkUGaqYZnuGZapMu579gAA4N0rZ8fKhZgJHw5YPNAguo04w5JIKOjPpTFSV9KblYTkYy6UGwOW6VoDb2e0VvRaoJK3aGkGauZxG688K7yDY0KH7PltNSzTrBxIAcvIVAn3PVcLWK67YFGUh8TEgOl1lQdM3ES3gF7HYiq6lY7ZTMfCpnHxw6hhmSqaC26ZzqDbVYZlel0bZB73kxeP4MDwFPpyKVx+1ryIj4qJGl6lPNCgYYmBWZDssGi2oCUSighGzHQstItn07j4YOwSEiUhk4CUmf640rBMs/u3rx6wkPfKh9YsMC15M53F9LrKA6axSyj6j69fClisbmjNPK4xYJmuNfB2pkF0a1MSYqY/mobFOmCJ2sTSb/q79GqF/3TBwoiOhIkTvEp5wKhhicNDgszjAKArY346tU6hztmhtTMNoluTwYdM56BpWKxLQtMtQ0oZFgA4bXYPzl8yI8KjYeLC9LrKA8bYJRS16BZwLgkB9hObp6tor51p8GExGXzIdA6dWBLql+YJ/dbahey9wgDggMUTuQZr/uhvIp3o1ipgMbF6J8QOzcTWn4kGKgkVGtqaOWDpRMQsITvjuGlnza89137zfC4HMTW4rdkDjRmW6AOWAVnDYrEDt5snVOAMS+zgkhAjQxqWKZMMC21CpluGZfWCfrzjtJk4d+FAbIYdMtHDAYsH4ii61QUsFq2NtqLbaZpSbmeyhmnNLLrtbISGxZBhUVUVR8dqQ2Jn92Ya/l07k0sn8YPfi+eoBCY6eJXyQPxFt04Bi/V4+unm49DOGNuaWcPS2YguIYNx3OhUWehahga6Qj8uhgkbDlg80GgcF/3H507DohdxyrDoNn50NRjHsYalkxHTmg0ZloMjUwBqzwAOZplOgFcpD8gmbEA8RLcDLnxYcjYZFi4JxQ8rH5YcC6M7EgpY8qUqKlVtmOyhesDC2RWmU+AnoEfkLEscAhZdW7NVSSht09ZcYafbuNHFGhZGoierSQ2npE6/g8N5AMCCAR4IyHQGvEp5RO4UikNJqN+VD4uz6JYDlvjAPiyMTDaVAO2NJiXzuMMjtYBlaJADFqYz4FXKI7LwNg6i21w6KQIV54CFS0LtgCgJlfVtzaxh6UwURZG8WKQMC5eEmA6DVymPyBmWZAxKQgCwZtEAejJJLJ5p/uAy7thleFpz/BBdQkUuCTE1hPBWyrAcopIQZ1iYDoF9WDyiy7DEwIcFAP7+0xdiqljBgNQxJGPb1lziDEvcoIClUK6iWlUxVT9HHLB0Lj3ZFDBW0GlYWHTLdBocsHiEFv+EUusaigOZVMI24LB1uuVpzbFDLv0UylXki6xh6XSMGRZVVXFohES3HLAwnQGvUh4hfUEcBLduEdOa7XxYOGCJDTnpXORLFZ4lxDQMQDw5URQbkHkD2ciOi2HChFcpj1C2Ig4tzW6hrFDeTnTbRgHYdCeVTAhBd75cYQ0Lo4lu6xkWyq7M7s02OHAzzHSFVymP0OLfTgFLzs6HhdqaeTGMFTQXaqpY4ZIQg56sflzDweGafoUFt0wnwQGLR2hhT7dRRsK2rZm7hGJJTnI35QwLo2VYatcCZViG2DSO6SB4lfII6QtSMfBgcYud6JaN4+IJaaXGC2WU63bsHLB0Lj1Cw1IrCbEHC9OJ8CrlERKwpmLS0uwGO6dbyrqw6DZeUHBycqIovpbL8DnqVLqMGRb2YGE6EH4CekSIbtsow6JpWNjptl2gczY8WQtYEgqX7ToZY4aFPViYToSfgB5pR9GtaGu2KQnxYhgvSHR7sh6wdKWTUJT2ueYYf+muD0CktuaDnGFhOhBepTySa2fRrVmGhY3jYgmJbocnSwC4Q6jTkTMslaqKI6MkuuUMC9M58Crlkew0E90WWHQbS0jcfaquYWHTuM6mSzjdVnB8vIByVUVCAeb2sWkc0znwKuURWtiTbSi6zbOGpW2gAOWUVBJiOpeeDJWEysKDZV5/rq0ctxmmVfhq94jwYWkjDYs8TE9GVVUuCcWULhGwcEmIAbqzmjU/e7AwnQqvUh7RZgm1T8BCGZZyVUW5ogUt5aoKVa2/JskLYpyg64wyLFwS6my0DEtFZFiGBlm/wnQWHLB45B2nzcKKub24as2CqA/FNdQlBGgiW0CfceEMS7wg0S1pWLgk1NmQNf9EsSxNaeYMC9NZpKI+gHZj4WAXHvrCpVEfhifk4WiFUhXdmdr/FzlgiS3U1jwyVS8JccDS0ZBx3GShwh4sTMfCq1QHkEwouum/BAUsyYSCZBtpcjoBKgHVXflZw9LhUFtzsVLFvpM8+JDpTDhg6RBEa7M0sZlN4+JLV1p/TljD0tnQ8EMAeP3YOADOsDCdB69UHYLZPKFipZZtyab5MogbxgCFS0KdTSaVEFlScrsd4gwL02HwStUhaAGLVhIqcIYltjQELDz4sOORg9Z0UsHsHjaNYzoLfgp2COQfkzcrCbHgNnZwhoUx0pPVykLzB3JIsO6M6TB4peoQzNxuCxywxJYca1gYA92S8Jr1K0wnwitVhzDQlQYAnKz7egAsuo0zxowKdwkxcoaFPViYToRXqg5h8cxuAMC+k5Pia0UefBhbuCTEGJGvAXa5ZToRXqk6hMUzagHL/lNT4ms8Ryi+cMDCGOEMC9Pp8ErVISyaUduR7TtllmHhxTBuGAOUHJeEOh7WsDCdDgcsHYIoCZkELJxhiR9G0S1nWJgeyTyOPViYToRXqg5h8czajuzgcF5MbC5UWHQbV7JcEmIMdGe1a2ABZ1iYDoRXqg5hXl8OmWQClaoqpr0W6i3OnGGJH9wlxBihklAuncBgdzrio2GY8OGVqkNIJBQsNOhYWHQbX9JJBbIvGGdYGJontGCgC4rCpnFM58ErVQdBwtv99WmvrGGJL4qi6IIUNo5jaGIz61eYToVXqg7CKLxl47h4IwcpXBJiLl4xG8tmdeOaty2M+lAYJhJSzi9hpgtGLxbR1szTmmOJHLDkOAvW8ayc14cdf/SeqA+DYSKDn4IdBHUKkdstaViynGGJJdTanEkmkOJzxDBMh8NPwQ6CMiwNJSHevccSyrAYPVkYhmE6EX4SdhCkYTkyWkC+VOFpzTGHAhbWrzAMw3DA0lHM6E4LL4cDw1Msuo051CXELc0MwzAcsHQUiqJoZaGTk1KGhRfEOEKlIG5pZhiG8RiwbN26FWvWrEF/fz/6+/uxfv16PPDAA5av3717N6677josW7YMiqLgtttua3jNpk2bsG7dOvT19WHu3Lm49tpr8fLLL3t+I4w7hPD21BQbx8WcLJeEGIZhBJ5WqkWLFmHz5s145pln8PTTT+O9730vrrnmGuzevdv09ZOTk1i+fDk2b96M+fPnm77mkUcewc0334zHH38cP/nJT1AqlfD+978fExMT3t8N48giam0+OYliuWbNn+WAJZZwSYhhGEbDkw/L1Vdfrfv7V7/6VWzduhWPP/44Vq9e3fD6devWYd26dQCAL3/5y6Y/88EHH9T9/a677sLcuXPxzDPP4N3vfreXw2NcIJvHcZdQvKGSEAcsDMMwLRjHVSoV/PCHP8TExATWr1/v2wGNjIwAAGbOnOnbz2Q0FpM9/6kpVFUVAAcscYUClRyXhBiGYbwHLLt27cL69euRz+fR29uL++67D2effbYvB1OtVnHLLbfg4osvxjnnnGP72kKhgEKhIP4+OjrqyzFMd0SG5eQk5vRlAbBxXFzJcUmIYRhG4HmlWrVqFXbu3IknnngCN910E2688Ua8+OKLvhzMzTffjBdeeAHbtm1zfO2mTZswMDAg/ixevNiXY5juUMByarKEkxNFAJxhiSurF/QDAM6p/5dhGKaT8bxSZTIZrFixAhdccAE2bdqE8847D7fffnvLB/LZz34W//qv/4qHH34YixYtcnz9xo0bMTIyIv7s27ev5WPoBHqzKczoTgMAjo9zwBJnPnjOEHb+yQZ86uLToj4UhmGYyGl5+GG1WtWVZryiqir+4A/+APfddx927NiB005z93DOZrPIZrNN/95OZvHMbpyaHBF/54Alvgx2Z6I+BIZhmFjgKWDZuHEjrrjiCixZsgRjY2O45557sGPHDmzfvh0AcMMNN2DhwoXYtGkTAKBYLIpyUbFYxIEDB7Bz50709vZixYoVAGploHvuuQf3338/+vr6cPjwYQDAwMAAurq6fHujjMaiGV341X4pYGENC8MwDBNzPAUsR48exQ033IBDhw5hYGAAa9aswfbt27FhwwYAwN69e5FIaIvfwYMHsXbtWvH3LVu2YMuWLbj00kuxY8cOADUzOgC47LLLdL/rzjvvxKc+9akm3hLjBLndElkWdTIMwzAxx1PAcscdd9h+n4IQYtmyZVDrrbNWOH2f8Z9FM/UBC2dYGIZhmLjDK1UHQl4sBGtYGIZhmLjDK1UHstiQYWFrfoZhGCbu8ErVgSwcNGRYuCTEMAzDxBxeqTqQXDqJef21lvBUQkEioUR8RAzDMAxjDwcsHQp1CrF+hWEYhmkHeLXqUEjHwvoVhmEYph3g1apDoU4hzrAwDMMw7QCvVh0KebFwwMIwDMO0A7xadSgr5vYCAGbwrBqGYRimDWh5+CHTnqxdPIhvXLcGqxf2R30oDMMwDOMIBywdiqIo+PC6xVEfBsMwDMO4gktCDMMwDMPEHg5YGIZhGIaJPRywMAzDMAwTezhgYRiGYRgm9nDAwjAMwzBM7OGAhWEYhmGY2MMBC8MwDMMwsYcDFoZhGIZhYg8HLAzDMAzDxB4OWBiGYRiGiT0csDAMwzAME3s4YGEYhmEYJvZwwMIwDMMwTOyZNtOaVVUFAIyOjkZ8JAzDMAzDuIXWbVrHrZg2AcvY2BgAYPHixREfCcMwDMMwXhkbG8PAwIDl9xXVKaRpE6rVKg4ePIi+vj4oiuLbzx0dHcXixYuxb98+9Pf3+/Zz48R0f4/8/tqf6f4e+f21P9P9PQb5/lRVxdjYGBYsWIBEwlqpMm0yLIlEAosWLQrs5/f390/Li1Bmur9Hfn/tz3R/j/z+2p/p/h6Den92mRWCRbcMwzAMw8QeDlgYhmEYhok9HLA4kM1mceuttyKbzUZ9KIEx3d8jv7/2Z7q/R35/7c90f49xeH/TRnTLMAzDMMz0hTMsDMMwDMPEHg5YGIZhGIaJPRywMAzDMAwTezhgYRiGYRgm9nRkwPLtb38by5YtQy6Xw4UXXognn3zS9vU//OEPceaZZyKXy+Hcc8/Fj3/8Y933VVXFn/zJn2BoaAhdXV24/PLL8eqrrwb5Fmzx8v7+5m/+BpdccglmzJiBGTNm4PLLL294/ac+9SkoiqL788EPfjDot2GJl/d31113NRx7LpfTvSZu5w/w9h4vu+yyhveoKAquuuoq8Zo4ncOf//znuPrqq7FgwQIoioIf/ehHjv9mx44dOP/885HNZrFixQrcddddDa/xel8Hhdf3d++992LDhg2YM2cO+vv7sX79emzfvl33mj/90z9tOH9nnnlmgO/CHq/vcceOHabX6OHDh3Wva9dzaHZ/KYqC1atXi9fE6Rxu2rQJ69atQ19fH+bOnYtrr70WL7/8suO/i3ot7LiA5R//8R/xhS98AbfeeiueffZZnHfeefjABz6Ao0ePmr7+l7/8JT72sY/h05/+NJ577jlce+21uPbaa/HCCy+I13zjG9/AX/3VX+E73/kOnnjiCfT09OADH/gA8vl8WG9L4PX97dixAx/72Mfw8MMP47HHHsPixYvx/ve/HwcOHNC97oMf/CAOHTok/nz/+98P4+004PX9ATVnRvnY9+zZo/t+nM4f4P093nvvvbr398ILLyCZTOL666/XvS4u53BiYgLnnXcevv3tb7t6/ZtvvomrrroK73nPe7Bz507ccsst+MxnPqNb1Ju5LoLC6/v7+c9/jg0bNuDHP/4xnnnmGbznPe/B1Vdfjeeee073utWrV+vO33/8x38Ecfiu8PoeiZdffln3HubOnSu+187n8Pbbb9e9r3379mHmzJkN92BczuEjjzyCm2++GY8//jh+8pOfoFQq4f3vfz8mJiYs/00s1kK1w3jHO96h3nzzzeLvlUpFXbBggbpp0ybT13/4wx9Wr7rqKt3XLrzwQvX3fu/3VFVV1Wq1qs6fP1/95je/Kb4/PDysZrNZ9fvf/34A78Aer+/PSLlcVvv6+tS7775bfO3GG29Ur7nmGr8PtSm8vr8777xTHRgYsPx5cTt/qtr6OfzWt76l9vX1qePj4+JrcTqHMgDU++67z/Y1//2//3d19erVuq995CMfUT/wgQ+Iv7f6mQWFm/dnxtlnn61+5StfEX+/9dZb1fPOO8+/A/MRN+/x4YcfVgGop06dsnzNdDqH9913n6ooivrWW2+Jr8X5HB49elQFoD7yyCOWr4nDWthRGZZisYhnnnkGl19+ufhaIpHA5Zdfjscee8z03zz22GO61wPABz7wAfH6N998E4cPH9a9ZmBgABdeeKHlzwyKZt6fkcnJSZRKJcycOVP39R07dmDu3LlYtWoVbrrpJpw4ccLXY3dDs+9vfHwcS5cuxeLFi3HNNddg9+7d4ntxOn+AP+fwjjvuwEc/+lH09PTovh6Hc9gMTvegH59ZnKhWqxgbG2u4B1999VUsWLAAy5cvx8c//nHs3bs3oiNsnre97W0YGhrChg0b8Oijj4qvT7dzeMcdd+Dyyy/H0qVLdV+P6zkcGRkBgIZrTiYOa2FHBSzHjx9HpVLBvHnzdF+fN29eQy2VOHz4sO3r6b9efmZQNPP+jHzpS1/CggULdBfdBz/4Qfzd3/0dfvrTn+LrX/86HnnkEVxxxRWoVCq+Hr8Tzby/VatW4W//9m9x//3343vf+x6q1Souuugi7N+/H0C8zh/Q+jl88skn8cILL+Azn/mM7utxOYfNYHUPjo6OYmpqypfrPk5s2bIF4+Pj+PCHPyy+duGFF+Kuu+7Cgw8+iK1bt+LNN9/EJZdcgrGxsQiP1D1DQ0P4zne+g3/+53/GP//zP2Px4sW47LLL8OyzzwLw59kVFw4ePIgHHnig4R6M6zmsVqu45ZZbcPHFF+Occ86xfF0c1sJpM62ZaZ3Nmzdj27Zt2LFjh06Y+tGPflT8/7nnnos1a9bg9NNPx44dO/C+970vikN1zfr167F+/Xrx94suughnnXUW/vqv/xp/9md/FuGRBcMdd9yBc889F+94xzt0X2/nc9hJ3HPPPfjKV76C+++/X6fvuOKKK8T/r1mzBhdeeCGWLl2KH/zgB/j0pz8dxaF6YtWqVVi1apX4+0UXXYTXX38d3/rWt/D3f//3ER6Z/9x9990YHBzEtddeq/t6XM/hzTffjBdeeCFSTZRbOirDMnv2bCSTSRw5ckT39SNHjmD+/Pmm/2b+/Pm2r6f/evmZQdHM+yO2bNmCzZs349///d+xZs0a29cuX74cs2fPxmuvvdbyMXuhlfdHpNNprF27Vhx7nM4f0Np7nJiYwLZt21w9/KI6h81gdQ/29/ejq6vLl+siDmzbtg2f+cxn8IMf/KAh9W5kcHAQZ5xxRlucPyve8Y53iOOfLudQVVX87d/+LT75yU8ik8nYvjYO5/Czn/0s/vVf/xUPP/wwFi1aZPvaOKyFHRWwZDIZXHDBBfjpT38qvlatVvHTn/5UtwuXWb9+ve71APCTn/xEvP60007D/Pnzda8ZHR3FE088Yfkzg6KZ9wfUlN1/9md/hgcffBBvf/vbHX/P/v37ceLECQwNDfly3G5p9v3JVCoV7Nq1Sxx7nM4f0Np7/OEPf4hCoYBPfOITjr8nqnPYDE73oB/XRdR8//vfx2//9m/j+9//vq4d3Yrx8XG8/vrrbXH+rNi5c6c4/ulwDoFa981rr73matMQ5TlUVRWf/exncd999+FnP/sZTjvtNMd/E4u10Bfpbhuxbds2NZvNqnfddZf64osvqr/7u7+rDg4OqocPH1ZVVVU/+clPql/+8pfF6x999FE1lUqpW7ZsUV966SX11ltvVdPptLpr1y7xms2bN6uDg4Pq/fffr/7qV79Sr7nmGvW0005Tp6amYv/+Nm/erGYyGfWf/umf1EOHDok/Y2Njqqqq6tjYmPrFL35Rfeyxx9Q333xTfeihh9Tzzz9fXblypZrP52P//r7yla+o27dvV19//XX1mWeeUT/60Y+quVxO3b17t3hNnM6fqnp/j8S73vUu9SMf+UjD1+N2DsfGxtTnnntOfe6551QA6l/+5V+qzz33nLpnzx5VVVX1y1/+svrJT35SvP6NN95Qu7u71T/6oz9SX3rpJfXb3/62mkwm1QcffFC8xukzi/P7+4d/+Ac1lUqp3/72t3X34PDwsHjNf/tv/03dsWOH+uabb6qPPvqoevnll6uzZ89Wjx49Gvr7U1Xv7/Fb3/qW+qMf/Uh99dVX1V27dqmf+9zn1EQioT700EPiNe18DolPfOIT6oUXXmj6M+N0Dm+66SZ1YGBA3bFjh+6am5ycFK+J41rYcQGLqqrq//7f/1tdsmSJmslk1He84x3q448/Lr536aWXqjfeeKPu9T/4wQ/UM844Q81kMurq1avVf/u3f9N9v1qtqn/8x3+szps3T81ms+r73vc+9eWXXw7jrZji5f0tXbpUBdDw59Zbb1VVVVUnJyfV97///eqcOXPUdDqtLl26VP2d3/mdSB4ihJf3d8stt4jXzps3T73yyivVZ599Vvfz4nb+VNX7NfrrX/9aBaD++7//e8PPits5pBZX4x96TzfeeKN66aWXNvybt73tbWomk1GXL1+u3nnnnQ0/1+4zCxOv7+/SSy+1fb2q1tq4h4aG1Ewmoy5cuFD9yEc+or722mvhvjEJr+/x61//unr66aeruVxOnTlzpnrZZZepP/vZzxp+brueQ1WttfB2dXWp3/3ud01/ZpzOodl7A6C7r+K4Fir1g2cYhmEYhoktHaVhYRiGYRimPeGAhWEYhmGY2MMBC8MwDMMwsYcDFoZhGIZhYg8HLAzDMAzDxB4OWBiGYRiGiT0csDAMwzAME3s4YGEYhmEYJvZwwMIwDMMwTOzhgIVhGIZhmNjDAQvDMAzDMLGHAxaGYRiGYWLP/wcyJY1z9Kp/iAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}